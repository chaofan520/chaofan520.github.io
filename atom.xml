<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhangchaofan&#39;s blog</title>
  
  <subtitle>慢慢沉淀下来</subtitle>
  <link href="https://zhangchaofan01.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://zhangchaofan01.gitee.io/"/>
  <updated>2025-06-07T00:10:33.748Z</updated>
  <id>https://zhangchaofan01.gitee.io/</id>
  
  <author>
    <name>zhangchaofan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hzau_RNA-seq</title>
    <link href="https://zhangchaofan01.gitee.io/2025/06/02/hzau-rna-seq/"/>
    <id>https://zhangchaofan01.gitee.io/2025/06/02/hzau-rna-seq/</id>
    <published>2025-06-02T02:10:35.000Z</published>
    <updated>2025-06-07T00:10:33.748Z</updated>
    
    <content type="html"><![CDATA[<style>pre {  overflow-y: auto;  max-height: 900px;}</style><p>流程总览：</p><p><img src="/blog_pics/hzau_RNA-seq/pipeline_overview.png" alt="png"><br>本流程参考华中农业大学<a href="http://www.guolianglab.org/">李国亮老师</a>的<a href="https://github.com/chaofan520/Bioinformatics_Pipelines/hzau_RNA-seq">课程PPT</a>，旨在提供一个打包好的pipeline，一行命令进行转录组数据的分析。</p><h2 id="0-环境配置"><a href="#0-环境配置" class="headerlink" title="0. 环境配置"></a>0. 环境配置</h2><p>需要预安装的一些软件，包括：</p><ol><li><code>conda</code><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n hzau_RNA-seqconda activate hzau_RNA-seqconda install python&#x3D;3.10 fastqc fastp multiqc&#x3D;1.26 sra-tools&#x3D;3.1 samtools&#x3D;1.21 -c bioconda -c conda-forgeconda install hisat2&#x3D;2.2.1 STAR&#x3D;2.7.11b stringtie&#x3D;2.2.3 subread&#x3D;2.1.1 deeptools snakemake -c bioconda -c conda-forge# 大爷的 之前openssl版本有问题conda install r-base&#x3D;4.4.2 r-biocmanager r-ggplot2&#x3D;3.5.1 curl&#x3D;8.11.1 openssl&#x3D;3.4.0 -c bioconda -c conda-forge# 我这里通过conda安装bioconductor-deseq2老有问题，只能通过BiocManager。可能你直接conda装就成功了# conda install bioconductor-deseq2 -c bioconda -c conda-forge <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-R" data-language="R"><div class="caption"><span>install_DESeq2.R</span></div><code class="language-R"># 如DEseq2直接通过conda安装成功，则不需要运行 &quot;BiocManager::install(&quot;DESeq2&quot;)&quot;BiocManager::install(&quot;DESeq2&quot;)# 安装其它依赖install.packages(&quot;purrr&quot;)install.packages(&quot;tibble&quot;)library(DESeq2)# Done!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-原始数据下载"><a href="#1-原始数据下载" class="headerlink" title="1. 原始数据下载"></a>1. 原始数据下载</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 配置工作目录mkdir 00.raw_sra 01.raw_fastq 02.clean_fastq 03.alignment_file 04.count_matrix 05.DEseq2# 下载原始sra文件cat SRR_Acc_List.txt | awk &#39;&#123;print $1&#125;&#39; |while read line; do    prefetch $&#123;line&#125; -O 00.raw_sra &amp;done## 下载完需检查文件大小是否与原网页一致 # sra转fastq.gzcat SRR_Acc_List.txt | awk &#39;&#123;print $1&#125;&#39; | while read line; do    fastq-dump 00.raw_sra&#x2F;$&#123;line&#125;&#x2F;$&#123;line&#125;.sra --split-3 --gzip -O 01.raw_fastq &amp;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>SRR_Acc_List.txt</span></div><code class="language-txt">SRR15859987 # mature leaves Col-0 Repeat1SRR15859988 # mature leaves Col-0 Repeat2SRR15859989 # mature leaves Col-0 Repeat3SRR15859993 # mature leaves met1-3 Repeat1SRR15859994 # mature leaves met1-3 Repeat2SRR15859995 # mature leaves met1-3 Repeat3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-Shell命令行操作"><a href="#2-Shell命令行操作" class="headerlink" title="2. Shell命令行操作"></a>2. <code>Shell</code>命令行操作</h2>李老师这里介绍了几种常用的流程：<blockquote><ol><li>Fastp -&gt; HISAT2/STAR -&gt; featureCounts|htseq-count（基于gene Counts）  -&gt; DESeq2  </li><li>Fastp -&gt; HISAT2/STAR -&gt; StringTie（基于转录本） -&gt; EdgeR  </li></ol></blockquote></li></ol><p>我这个()注释位置与原PPT不同，放这里个人感觉更直观。</p><h3 id="2-1-数据质控"><a href="#2-1-数据质控" class="headerlink" title="2.1 数据质控"></a>2.1 数据质控</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># raw_data 测序数据质量检测fastqc 01.raw_fastq&#x2F;*.gz -o 01.raw_fastq&#x2F; -t 12multiqc 01.raw_fastq&#x2F; -o 01.raw_fastq&#x2F;multiqc # 可以看下multiqc_report.html，原始数据有点接头# fastq 测序数据质控for i in 87 88 89 93 94 95do    fastp -i 01.raw_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz -o 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz -I 01.raw_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz -O 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz -h 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;.fastp.html -j 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;.fastp.json --thread 16done # clean_data 测序数据质量检测fastqc 02.clean_fastq&#x2F;*.gz -o 02.clean_fastq&#x2F; -t 12multiqc 02.clean_fastq&#x2F; -o 02.clean_fastq&#x2F;multiqc # 对比下质控前后结果# 目前大部分情况下是不需要去除rRNA的<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-数据比对"><a href="#2-2-数据比对" class="headerlink" title="2.2 数据比对"></a>2.2 数据比对</h3><p>首先下载基因组数据</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># dna_sm 基因组softmask版本wget https:&#x2F;&#x2F;ftp.ensemblgenomes.ebi.ac.uk&#x2F;pub&#x2F;plants&#x2F;release-61&#x2F;fasta&#x2F;arabidopsis_thaliana&#x2F;dna&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa.gzwget https:&#x2F;&#x2F;ftp.ensemblgenomes.ebi.ac.uk&#x2F;pub&#x2F;plants&#x2F;release-61&#x2F;gtf&#x2F;arabidopsis_thaliana&#x2F;Arabidopsis_thaliana.TAIR10.61.gtf.gzgzip -d *.gz mkdir Referencemv Arabidopsis_thaliana.TAIR10.61.gtf Reference&#x2F;mv Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa Reference&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-1-HISAT2比对"><a href="#2-2-1-HISAT2比对" class="headerlink" title="2.2.1 HISAT2比对"></a>2.2.1 <code>HISAT2</code>比对</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir Reference&#x2F;hisat2_index# 构建HISAT2 基因组比对索引hisat2-build -p 20 Reference&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa Reference&#x2F;hisat2_index&#x2F;Arabidopsis_thaliana.TAIR10mkdir -p 03.alignment_file&#x2F;hisat2_resultfor i in 87 88 89 93 94 95do    hisat2 -x Reference&#x2F;hisat2_index&#x2F;Arabidopsis_thaliana.TAIR10 -1 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz -2 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz -S 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sam -p 20 --summary-file 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.summarydone <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-2-STAR比对"><a href="#2-2-2-STAR比对" class="headerlink" title="2.2.2 STAR比对"></a>2.2.2 <code>STAR</code>比对</h4><p>其实使用STAR比对这一步可以不做的，我个人一般也是直接使用<code>HISAT2</code>进行mapping。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir Reference&#x2F;STAR_index# 构建STAR 基因组比对索引STAR --runThreadN 16 --runMode genomeGenerate --genomeDir Reference&#x2F;STAR_index&#x2F; --genomeFastaFiles Reference&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa# 有个 WARNING啊，课件里只用了一条染色体应该也有WARNING的# !!!!! WARNING: --genomeSAindexNbases 14 is too large for the genome size&#x3D;119667750, which may cause seg-fault at the mapping step. Re-run genome generation with recommended --genomeSAindexNbases 12# 我们重新生成STAR --runThreadN 16 --runMode genomeGenerate --genomeDir Reference&#x2F;STAR_index&#x2F; --genomeFastaFiles Reference&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa --genomeSAindexNbases 12mkdir -p 03.alignment_file&#x2F;star_resultfor i in 87 88 89 93 94 95do    STAR --runThreadN 16 --runMode alignReads --readFilesCommand zcat --outSAMunmapped None --genomeDir Reference&#x2F;STAR_index&#x2F; --readFilesIn 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz --outFileNamePrefix 03.alignment_file&#x2F;star_result&#x2F;SRR158599$&#123;i&#125;_done <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-3-sam2bam"><a href="#2-2-3-sam2bam" class="headerlink" title="2.2.3 sam2bam"></a>2.2.3 sam2bam</h4><p><code>HISAT2</code>的输出<code>sam</code>是按照<code>readsname</code>进行排序的，可以直接用于<code>htseq-count</code>进行计数。但有些软件（比如：StringTie<sup><a name="ref1">1</a></sup>）的输入要求必须是按<code>position</code>进行排序，我们需要使用<code>samtools</code>进行转换。而且<code>sam</code>文件非常大，将<code>sam</code>转换为<code>bam</code>也能很好的缓解储存压力。<code>samtools sort</code>的输出默认是按照<code>position</code>进行排序，如果这样的<code>bam</code>用于<code>htseq-count</code>计数，需指定<code>-r pos</code>(default: name)。这里只是提一嘴，我们这里不使用<code>htseq-count</code>进行计数。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">for i in 87 88 89 93 94 95do    samtools view -@ 16 -bS 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sam &gt; 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.bam &amp;&amp; rm 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sam    samtools sort -@ 16 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.bam -o 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bam &amp;&amp; rm 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.bam    samtools index 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bamdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-计算基因表达量"><a href="#2-3-计算基因表达量" class="headerlink" title="2.3 计算基因表达量"></a>2.3 计算基因表达量</h3><h4 id="2-3-1-featureCounts-htseq-count"><a href="#2-3-1-featureCounts-htseq-count" class="headerlink" title="2.3.1 featureCounts|htseq-count"></a>2.3.1 featureCounts|htseq-count</h4><p>这里使用<code>featureCounts</code>或<code>htseq-count</code>都行，我们这里参照原PPT使用<code>featureCounts</code>。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p 04.count_matrix&#x2F;featureCountsfor i in 87 88 89 93 94 95do    featureCounts -a Reference&#x2F;Arabidopsis_thaliana.TAIR10.61.gtf -o 04.count_matrix&#x2F;featureCounts&#x2F;SRR158599$&#123;i&#125;.featurecount.txt -p 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bam   # 双端数据千万别忘了加 -pdone <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>featureCounts</code>的输出很简单，单个样本的情况下输出七列，第一列为基因ID，第六列为这个基因所有<code>exon</code>的长度（去掉了不同转录本间的冗余长度，可直接用来算<code>FPKM</code>），第7列为<code>mapping</code>到的<code>Fragments</code>数量（单端测序数据也称为<code>reads</code>数量）。</p><p><img src="/blog_pics/hzau_RNA-seq/featureCounts_ouf.png" alt="png"> </p><h4 id="2-3-2-Stringtie"><a href="#2-3-2-Stringtie" class="headerlink" title="2.3.2 Stringtie"></a>2.3.2 Stringtie</h4><p><code>Stringtie</code>可以用来鉴定新的转录本，挖掘可变剪切事件，也可以直接定量，参考简书教程<sup><a name="ref1">2</a></sup>。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p 04.count_matrix&#x2F;stringtiefor i in 87 88 89 93 94 95do    stringtie -p 16 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bam -G Reference&#x2F;Arabidopsis_thaliana.TAIR10.61.gtf -o 04.count_matrix&#x2F;stringtie&#x2F;SRR158599$&#123;i&#125;.gtf -e -A 04.count_matrix&#x2F;stringtie&#x2F;SRR158599$&#123;i&#125;.gene.tabdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意，<code>Stringtie</code>的输出直接为<code>FPKM</code>和<code>TPM</code>,没有<code>count</code>。后续的<code>DESeq2</code>差异表达分析的输入必须使用原始的<code>count</code>。其实我们用了<code>featureCounts|htseq-count</code>进行计数后没必要再用<code>Stringtie</code>，如果需要<code>FPKM</code>和<code>TPM</code>值，可以通过<code>count</code>进行转换。</p><p><img src="/blog_pics/hzau_RNA-seq/Stringtie_ouf.png" alt="png"> </p><h3 id="2-4-检查样本的重复性"><a href="#2-4-检查样本的重复性" class="headerlink" title="2.4 检查样本的重复性"></a>2.4 检查样本的重复性</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 计算每个bam文件的覆盖度情况multiBamSummary bins --bamfiles 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859987.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859988.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859989.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859993.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859994.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859995.hisat2.sort.bam --minMappingQuality 30 --labels Col_rep1 Col_rep2 Col_rep3 met_rep1 met_rep2 met_rep3 -out 03.alignment_file&#x2F;readCounts.npz --outRawCounts 03.alignment_file&#x2F;readCounts.tab -p 20# 基于覆盖度信息进行层次聚类plotCorrelation -in 03.alignment_file&#x2F;readCounts.npz --corMethod spearman --skipZeros --plotTitle &quot;Spearman Correlation of Read Counts&quot; --whatToPlot heatmap --colorMap RdYlBu --plotNumbers -o 03.alignment_file&#x2F;heatmap_SpearmanCorr_readCounts.png --outFileCorMatrix 03.alignment_file&#x2F;readCounts.tab<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>样本重复性不错：<br><img src="/blog_pics/hzau_RNA-seq/sample_cor.png" alt="png"></p><h3 id="2-5-DESeq2差异表达分析"><a href="#2-5-DESeq2差异表达分析" class="headerlink" title="2.5 DESeq2差异表达分析"></a>2.5 <code>DESeq2</code>差异表达分析</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Rscript DEseq2.R<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-R" data-language="R"><div class="caption"><span>DEseq2.R</span></div><code class="language-R">library(purrr)suppressMessages(library(DESeq2))library(ggplot2)library(tibble)################# Merge count table ##################samplelist &lt;- c(&quot;SRR15859987&quot;, &quot;SRR15859988&quot;, &quot;SRR15859989&quot;, &quot;SRR15859993&quot;, &quot;SRR15859994&quot;, &quot;SRR15859995&quot;)# 读取不同样本的基因表达量列表exprlist &lt;- lapply(samplelist, function(x)&#123;     expr &lt;- read.table(paste0(&quot;04.count_matrix&#x2F;featureCounts&#x2F;&quot;, x, &quot;.featurecount.txt&quot;), header&#x3D;T) ## 读取文件     expr&lt;- expr[,c(1,7)] ### 提取基因id和表达量值     colnames(expr) &lt;- c(&quot;GeneID&quot;, x) ## 重命名     expr&#125;)# 多个基因样本的基因表达量列表合并expr.mat &lt;- purrr::reduce(exprlist, function(x,y)&#123;merge(x,y, by&#x3D;&quot;GeneID&quot;, all.x&#x3D;T)&#125;)write.table(expr.mat,   file &#x3D; &quot;.&#x2F;05.DEseq2&#x2F;merged_count_matrix.txt&quot;,   sep &#x3D; &quot;\t&quot;,   quote &#x3D; FALSE,   row.names &#x3D; FALSE  )######################### DEG #########################group_info &lt;- data.frame(Sample&#x3D;samplelist, Group&#x3D;c(rep(&quot;Col&quot;,3), rep(&quot;met1&quot;,3))) print(group_info)expr &lt;- column_to_rownames(expr.mat, &quot;GeneID&quot;)  # 表达矩阵head(expr)colData &lt;- group_info # 分组信息colData$Group &lt;- factor(colData$Group, levels &#x3D; c(&quot;Col&quot;, &quot;met1&quot;))dds &lt;- DESeqDataSetFromMatrix(countData &#x3D; as.matrix(expr), colData &#x3D; colData, design &#x3D; ~Group)dds &lt;- dds[rowSums(counts(dds)) &gt; 10, ] # 过滤低表达基因dds &lt;- DESeq(dds) # 差异分析print(&quot;######## Compare groups&quot;)print(resultsNames(dds)) # 查看比较组别print(dds)# log2(met1 &#x2F; Col)res &lt;- results(dds) # 获取差异表达结果head(res) # 查看差异表达结果## 保存分析结果write.csv(res, &quot;.&#x2F;05.DEseq2&#x2F;deseq2.diff.csv&quot;)####################### Volcano #######################res.plot &lt;- data.frame(res, stringsAsFactors &#x3D; FALSE, check.names &#x3D; FALSE)res.plot &lt;- na.omit(res.plot)res.plot$gene &lt;- rownames(res.plot)res.plot$sig &lt;- &quot;Not Signaficant&quot;res.plot[res.plot$log2FoldChange &gt; 2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- &quot;Highly expression in met1&quot;res.plot[res.plot$log2FoldChange &lt; -2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- &quot;Highly expression in Col&quot;res.plot$label &lt;- ifelse(res.plot$padj &lt; 10e-100 &amp; abs(res.plot$log2FoldChange) &gt;&#x3D; 5,                        rownames(res.plot), &quot;&quot;)p &lt;- ggplot(data&#x3D;res.plot, aes(x&#x3D;log2FoldChange,y&#x3D; -log10(padj))) +  geom_point(aes(color&#x3D;sig)) +   geom_text(aes(label&#x3D;label),  nudge_x&#x3D;.5,nudge_y&#x3D;.5, size&#x3D;2.5) +  scale_color_manual(values&#x3D;c(&quot;#546de5&quot;, &quot;#ff4757&quot;, &quot;#d2dae2&quot;)) +   labs(x&#x3D;expression(log[2](FC)), y&#x3D;expression(-log[10](padj))) +  geom_hline(yintercept&#x3D;2, linetype&#x3D;4) +  geom_vline(xintercept&#x3D;c(-2, 2),linetype&#x3D;4) +  theme_bw() + theme(panel.grid &#x3D; element_blank(),   legend.position &#x3D; &quot;top&quot;, legend.title &#x3D; element_blank(), aspect.ratio&#x3D;1,        legend.background &#x3D; element_blank())## 保存ggsave(&quot;.&#x2F;05.DEseq2&#x2F;Volcano.plot.pdf&quot;, p, width&#x3D;5.5, height&#x3D;5.5)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与原PPT有点差异，不知道原PPT是比对到全基因组，还是只是<code>Chr1</code>。</p><p><img src="/blog_pics/hzau_RNA-seq/Volcano_plot.png" alt="png"></p><h2 id="3-snakemake-pipeline"><a href="#3-snakemake-pipeline" class="headerlink" title="3. snakemake pipeline"></a>3. <code>snakemake</code> pipeline</h2><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>Snakefile</span></div><code class="language-python"><span class="token comment"># Snakefile for RNA-seq analysis pipeline (with pre-provided reference)</span>configfile<span class="token punctuation">:</span> <span class="token string">"config.yaml"</span><span class="token comment"># --- 从配置文件读取参数 --- </span>WORK_DIR <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"work_dir"</span><span class="token punctuation">]</span>THREADS <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"threads"</span><span class="token punctuation">]</span>REF_FASTA <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"ref_fasta"</span><span class="token punctuation">]</span>  <span class="token comment"># 基因组fasta路径</span>REF_GTF <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"ref_gtf"</span><span class="token punctuation">]</span>      <span class="token comment"># 注释文件路径</span>REF_PREFIX <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"ref_prefix"</span><span class="token punctuation">]</span><span class="token comment"># 获取所有样本列表</span>ALL_SAMPLES <span class="token operator">=</span> <span class="token punctuation">[</span>sample <span class="token keyword">for</span> group <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> group<span class="token punctuation">]</span>SAMPLES_GROUP <span class="token operator">=</span> <span class="token punctuation">&#123;</span>sample<span class="token punctuation">:</span>group <span class="token keyword">for</span> group <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>group<span class="token punctuation">]</span><span class="token punctuation">&#125;</span>GROUP_OF_SAMPLES <span class="token operator">=</span> <span class="token punctuation">[</span>SAMPLES_GROUP<span class="token punctuation">[</span>sample<span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> ALL_SAMPLES<span class="token punctuation">]</span>GROUP_NAMES <span class="token operator">=</span> unique_groups <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span>GROUP_OF_SAMPLES<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>GROUP_NAMES<span class="token punctuation">)</span><span class="token comment"># --- 定义目录结构 --- </span>dirs <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">"00.raw_sra"</span><span class="token punctuation">,</span>    <span class="token string">"01.raw_fastq"</span><span class="token punctuation">,</span>    <span class="token string">"02.clean_fastq"</span><span class="token punctuation">,</span>    <span class="token string">"03.alignment_file/hisat2_result"</span><span class="token punctuation">,</span>    <span class="token string">"04.count_matrix/featureCounts"</span><span class="token punctuation">,</span>     <span class="token string">"05.DEseq2"</span><span class="token punctuation">,</span>    <span class="token string">"Reference/hisat2_index"</span><span class="token punctuation">]</span>rule <span class="token builtin">all</span><span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"05.DEseq2/&#123;plot&#125;"</span><span class="token punctuation">,</span> plot<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"merged_count_matrix.txt"</span><span class="token punctuation">,</span> <span class="token string">"deseq2.diff.csv"</span><span class="token punctuation">,</span> <span class="token string">"Volcano.plot.pdf"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">"03.alignment_file/heatmap_SpearmanCorr_readCounts.png"</span><span class="token comment"># --- 创建目录结构 --- </span>rule create_dirs<span class="token punctuation">:</span>    run<span class="token punctuation">:</span>        <span class="token keyword">import</span> os        <span class="token keyword">for</span> d <span class="token keyword">in</span> dirs<span class="token punctuation">:</span>            os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>WORK_DIR<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># --- 数据下载和质控部分保持不变 ---</span>rule download_sra<span class="token punctuation">:</span>    output<span class="token punctuation">:</span>        <span class="token string">"00.raw_sra/&#123;sample&#125;/&#123;sample&#125;.sra"</span>    params<span class="token punctuation">:</span>        outdir <span class="token operator">=</span> <span class="token string">"00.raw_sra"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][prefetch]&#125; &#123;wildcards.sample&#125; -O &#123;params.outdir&#125;"</span>rule sra_to_fastq<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        <span class="token string">"00.raw_sra/&#123;sample&#125;/&#123;sample&#125;.sra"</span>    output<span class="token punctuation">:</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_2.fastq.gz"</span>     shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastq-dump]&#125; &#123;input&#125; --split-3 --gzip -O 01.raw_fastq"</span><span class="token comment"># --- FastQC原始数据质控 --- </span>rule raw_fastqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        raw_fq1 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        raw_fq2 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_2.fastq.gz"</span>    output<span class="token punctuation">:</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_1_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_2_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_1_fastqc.zip"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_2_fastqc.zip"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.raw_fq1&#125; -o 01.raw_fastq -t 1;"</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.raw_fq2&#125; -o 01.raw_fastq -t 1"</span><span class="token comment"># --- MultiQC汇总报告 --- </span>rule raw_multiqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"01.raw_fastq/&#123;sample&#125;_&#123;pair&#125;_fastqc.html"</span><span class="token punctuation">,</span>                sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">,</span> pair<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        <span class="token string">"01.raw_fastq/multiqc_report.html"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][multiqc]&#125; 01.raw_fastq/ -o 01.raw_fastq"</span><span class="token comment"># --- Fastp数据清洗 --- </span>rule fastp_clean<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        r1 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        r2 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_2.fastq.gz"</span><span class="token punctuation">,</span>        raw_multiqc <span class="token operator">=</span> <span class="token string">"01.raw_fastq/multiqc_report.html"</span>    output<span class="token punctuation">:</span>        cr1 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        cr2 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_2.fastq.gz"</span><span class="token punctuation">,</span>        html <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;.fastp.html"</span><span class="token punctuation">,</span>        json <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;.fastp.json"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastp]&#125; -i &#123;input.r1&#125; -I &#123;input.r2&#125; "</span>        <span class="token string">"-o &#123;output.cr1&#125; -O &#123;output.cr2&#125; "</span>        <span class="token string">"-h &#123;output.html&#125; -j &#123;output.json&#125; "</span>        <span class="token string">"--thread 4"</span><span class="token comment"># --- 清洗后质控 --- </span>rule clean_fastqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        clean_fq1 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        clean_fq2 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_2.fastq.gz"</span>    output<span class="token punctuation">:</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_1_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_2_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_1_fastqc.zip"</span><span class="token punctuation">,</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_2_fastqc.zip"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.clean_fq1&#125; -o 02.clean_fastq -t 1;"</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.clean_fq2&#125; -o 02.clean_fastq -t 1"</span>rule clean_multiqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"02.clean_fastq/&#123;sample&#125;_&#123;pair&#125;_fastqc.html"</span><span class="token punctuation">,</span>                sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">,</span> pair<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        <span class="token string">"02.clean_fastq/multiqc_report.html"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][multiqc]&#125; 02.clean_fastq/ -o 02.clean_fastq"</span><span class="token comment"># --- 参考基因组处理 ---</span><span class="token keyword">print</span><span class="token punctuation">(</span>REF_FASTA<span class="token punctuation">)</span>rule hisat2_index<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        REF_FASTA    output<span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"Reference/hisat2_index/&#123;prefix&#125;.&#123;n&#125;.ht2"</span><span class="token punctuation">,</span>               prefix<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">"ref_prefix"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][hisat2]&#125;-build -p &#123;THREADS&#125; &#123;config[ref_fasta]&#125; Reference/hisat2_index/&#123;config[ref_prefix]&#125;"</span><span class="token comment"># --- 比对和定量 ---</span>rule hisat2_align<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        clean_multiqc <span class="token operator">=</span> <span class="token string">"02.clean_fastq/multiqc_report.html"</span><span class="token punctuation">,</span>        r1 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        r2 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_2.fastq.gz"</span><span class="token punctuation">,</span>        idx <span class="token operator">=</span> expand<span class="token punctuation">(</span><span class="token string">"Reference/hisat2_index/&#123;prefix&#125;.&#123;n&#125;.ht2"</span><span class="token punctuation">,</span>                   prefix<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">"ref_prefix"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        sam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sam"</span><span class="token punctuation">,</span>        summary <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.summary"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][hisat2]&#125; -x Reference/hisat2_index/&#123;config[ref_prefix]&#125; "</span>        <span class="token string">"-1 &#123;input.r1&#125; -2 &#123;input.r2&#125; "</span>        <span class="token string">"-S &#123;output.sam&#125; -p 4 "</span>        <span class="token string">"--summary-file &#123;output.summary&#125;"</span>rule sam_to_bam<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        sam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sam"</span>    output<span class="token punctuation">:</span>        bam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam"</span><span class="token punctuation">,</span>        bai <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam.bai"</span>  <span class="token comment"># 索引文件</span>    params<span class="token punctuation">:</span>        unsorted_bam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.bam"</span>  <span class="token comment"># 中间文件</span>    shell<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        # 1. SAM转BAM        &#123;config[tools][samtools]&#125; view -@ 4 -bS &#123;input.sam&#125; > &#123;params.unsorted_bam&#125;                # 2. 排序BAM        &#123;config[tools][samtools]&#125; sort -@ 4 &#123;params.unsorted_bam&#125; -o &#123;output.bam&#125;                # 3. 删除中间文件        rm -v &#123;params.unsorted_bam&#125; &#123;input.sam&#125;                # 4. 创建索引        &#123;config[tools][samtools]&#125; index &#123;output.bam&#125;        """</span>rule feature_counts<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        bam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam"</span><span class="token punctuation">,</span>        gtf <span class="token operator">=</span> REF_GTF    output<span class="token punctuation">:</span>        counts <span class="token operator">=</span> <span class="token string">"04.count_matrix/featureCounts/&#123;sample&#125;.featurecount.txt"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][featurecounts]&#125; -a &#123;input.gtf&#125; -o &#123;output.counts&#125; "</span>        <span class="token string">"-p &#123;input.bam&#125;"</span><span class="token comment"># --- 样本相关性分析 ---</span>rule sample_correlation<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        bams <span class="token operator">=</span> expand<span class="token punctuation">(</span><span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam"</span><span class="token punctuation">,</span> sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        <span class="token string">"03.alignment_file/heatmap_SpearmanCorr_readCounts.png"</span><span class="token punctuation">,</span>        <span class="token string">"03.alignment_file/readCounts.npz"</span><span class="token punctuation">,</span>        <span class="token string">"03.alignment_file/readCounts.tab"</span>    params<span class="token punctuation">:</span>        labels <span class="token operator">=</span> <span class="token keyword">lambda</span> wildcards<span class="token punctuation">:</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>            <span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group<span class="token punctuation">&#125;</span></span><span class="token string">_rep</span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>              <span class="token keyword">for</span> group <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span>              <span class="token keyword">for</span> i<span class="token punctuation">,</span> sample <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>group<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token punctuation">)</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][multiBamSummary]&#125; bins --bamfiles &#123;input.bams&#125; "</span>        <span class="token string">"--minMappingQuality 30 --labels &#123;params.labels&#125; "</span>        <span class="token string">"-out &#123;output[1]&#125; --outRawCounts &#123;output[2]&#125; "</span>        <span class="token string">"-p &#123;THREADS&#125; \n"</span>        <span class="token string">"&#123;config[tools][plotCorrelation]&#125; -in &#123;output[1]&#125; --corMethod spearman "</span>        <span class="token string">"--skipZeros --plotTitle 'Spearman Correlation of Read Counts' "</span>        <span class="token string">"--whatToPlot heatmap --colorMap RdYlBu --plotNumbers "</span>        <span class="token string">"-o &#123;output[0]&#125;"</span><span class="token comment"># --- DESeq2差异分析 --- </span>rule merged_deseq2_analysis<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        counts <span class="token operator">=</span> expand<span class="token punctuation">(</span><span class="token string">"04.count_matrix/featureCounts/&#123;sample&#125;.featurecount.txt"</span><span class="token punctuation">,</span> sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">)</span><span class="token punctuation">,</span>        gtf <span class="token operator">=</span> REF_GTF    output<span class="token punctuation">:</span>        merged_count_txt <span class="token operator">=</span> <span class="token string">"05.DEseq2/merged_count_matrix.txt"</span><span class="token punctuation">,</span>        diff_csv <span class="token operator">=</span> <span class="token string">"05.DEseq2/deseq2.diff.csv"</span><span class="token punctuation">,</span>        volcano <span class="token operator">=</span> <span class="token string">"05.DEseq2/Volcano.plot.pdf"</span>    run<span class="token punctuation">:</span>        <span class="token comment"># 准备分组信息</span>        group_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> group_name<span class="token punctuation">,</span> samples <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            group_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>s<span class="token punctuation">&#125;</span></span><span class="token string">':'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group_name<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> s <span class="token keyword">in</span> samples<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token comment"># 将列表转换为字符串</span>        sample_str <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>s<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> s <span class="token keyword">in</span> ALL_SAMPLES<span class="token punctuation">]</span><span class="token punctuation">)</span>        group_str <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>g<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> g <span class="token keyword">in</span> GROUP_OF_SAMPLES<span class="token punctuation">]</span><span class="token punctuation">)</span>        group_class_str <span class="token operator">=</span>  <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>c<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> c <span class="token keyword">in</span> GROUP_NAMES<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token comment"># 生成R脚本</span>        script <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""library(purrr)suppressMessages(library(DESeq2))library(ggplot2)library(tibble)samplelist &lt;- c(</span><span class="token interpolation"><span class="token punctuation">&#123;</span>sample_str<span class="token punctuation">&#125;</span></span><span class="token string">)grouplist &lt;- c(</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group_str<span class="token punctuation">&#125;</span></span><span class="token string">)exprlist &lt;- lapply(samplelist, function(x)&#123;&#123;     expr &lt;- read.table(paste0('04.count_matrix/featureCounts/', x, '.featurecount.txt'), header=T)     expr&lt;- expr[,c(1,7)]      colnames(expr) &lt;- c('GeneID', x)      expr&#125;&#125;)expr.mat &lt;- purrr::reduce(exprlist, function(x,y)&#123;&#123;merge(x,y, by="GeneID", all.x=T)&#125;&#125;)write.table(expr.mat,     file = "</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>merged_count_txt<span class="token punctuation">&#125;</span></span><span class="token string">",     sep = "\t",     quote = FALSE,     row.names = FALSE)group_info &lt;- data.frame(Sample=samplelist, Group=grouplist) print(group_info)expr &lt;- column_to_rownames(expr.mat, "GeneID")head(expr)colData &lt;- group_info colData$Group &lt;- factor(colData$Group, levels = c(</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group_class_str<span class="token punctuation">&#125;</span></span><span class="token string">))dds &lt;- DESeqDataSetFromMatrix(countData = as.matrix(expr), colData = colData, design = ~Group)dds &lt;- dds[rowSums(counts(dds)) > 10, ] dds &lt;- DESeq(dds) print(resultsNames(dds)) print(dds)res &lt;- results(dds) head(res) write.csv(res, "</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>diff_csv<span class="token punctuation">&#125;</span></span><span class="token string">")res.plot &lt;- data.frame(res, stringsAsFactors = FALSE, check.names = FALSE)res.plot &lt;- na.omit(res.plot)res.plot$gene &lt;- rownames(res.plot)res.plot$sig &lt;- "Not Signaficant"res.plot[res.plot$log2FoldChange > 2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- "Highly expression in met1"res.plot[res.plot$log2FoldChange &lt; -2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- "Highly expression in CK"res.plot$label &lt;- ifelse(res.plot$padj &lt; 10e-100 &amp; abs(res.plot$log2FoldChange) >= 5,                        rownames(res.plot), "")p &lt;- ggplot(data=res.plot, aes(x=log2FoldChange,y= -log10(padj))) +  geom_point(aes(color=sig)) +   geom_text(aes(label=label),  nudge_x=.5,nudge_y=.5, size=2.5) +  scale_color_manual(values=c("#546de5", "#ff4757", "#d2dae2")) +   labs(x=expression(log[2](FC)), y=expression(-log[10](padj))) +  geom_hline(yintercept=2, linetype=4) +  geom_vline(xintercept=c(-2, 2),linetype=4) +  theme_bw() + theme(panel.grid = element_blank(),   legend.position = "top", legend.title = element_blank(), aspect.ratio=1,        legend.background = element_blank())ggsave("</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>volcano<span class="token punctuation">&#125;</span></span><span class="token string">", p, width=8, height=6)"""</span></span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"merged_analysis.R"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>script<span class="token punctuation">)</span>        shell<span class="token punctuation">(</span><span class="token string">"Rscript merged_analysis.R"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-yaml" data-language="yaml"><div class="caption"><span>config.yaml</span></div><code class="language-yaml"><span class="token comment"># config.yaml</span><span class="token key atrule">samples</span><span class="token punctuation">:</span>  <span class="token key atrule">CK</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> SRR15859987    <span class="token punctuation">-</span> SRR15859988     <span class="token punctuation">-</span> SRR15859989  <span class="token key atrule">met1</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> SRR15859993    <span class="token punctuation">-</span> SRR15859994    <span class="token punctuation">-</span> SRR15859995<span class="token comment"># 参考文件配置</span><span class="token key atrule">ref_fasta</span><span class="token punctuation">:</span> <span class="token string">"../Reference/Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa"</span><span class="token key atrule">ref_gtf</span><span class="token punctuation">:</span> <span class="token string">"../Reference/Arabidopsis_thaliana.TAIR10.61.gtf"</span><span class="token key atrule">ref_prefix</span><span class="token punctuation">:</span> <span class="token string">"Arabidopsis_thaliana.TAIR10"</span><span class="token key atrule">work_dir</span><span class="token punctuation">:</span> <span class="token string">"."</span><span class="token key atrule">threads</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token comment"># 工具路径配置</span><span class="token key atrule">tools</span><span class="token punctuation">:</span>  <span class="token key atrule">fastqc</span><span class="token punctuation">:</span> <span class="token string">"fastqc"</span>  <span class="token key atrule">multiqc</span><span class="token punctuation">:</span> <span class="token string">"multiqc"</span>  <span class="token key atrule">fastp</span><span class="token punctuation">:</span> <span class="token string">"fastp"</span>  <span class="token key atrule">hisat2</span><span class="token punctuation">:</span> <span class="token string">"hisat2"</span>  <span class="token key atrule">samtools</span><span class="token punctuation">:</span> <span class="token string">"samtools"</span>  <span class="token key atrule">featurecounts</span><span class="token punctuation">:</span> <span class="token string">"featureCounts"</span>  <span class="token key atrule">prefetch</span><span class="token punctuation">:</span> <span class="token string">"prefetch"</span>  <span class="token key atrule">fastq-dump</span><span class="token punctuation">:</span> <span class="token string">"fastq-dump"</span>  <span class="token key atrule">multiBamSummary</span><span class="token punctuation">:</span> <span class="token string">"multiBamSummary"</span>  <span class="token key atrule">plotCorrelation</span><span class="token punctuation">:</span> <span class="token string">"plotCorrelation"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">snakemake -j 20<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/blog_pics/hzau_RNA-seq/Snakemake_volcano.png" alt="png"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual">StringTie Manual</a>  </li><li><a href="https://www.jianshu.com/p/c9434353b648">StringTie 简书教程</a>  </li><li><a href="https://github.com/chaofan520/Bioinformatics_Pipelines/tree/main/hzau_RNA-seq">PPT 地址</a></li></ol><center><span style="color:#ff0000;">本人能力有限，难免出现错误，恳请批评指正</span></center>]]></content>
    
    
      
      
    <summary type="html">&lt;style&gt;
pre {
  overflow-y: auto;
  max-height: 900px;
}
&lt;/style&gt;

&lt;p&gt;流程总览：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog_pics/hzau_RNA-seq/pipeline_overview.png&quot; </summary>
      
    
    
    
    
    <category term="linux" scheme="https://zhangchaofan01.gitee.io/tags/linux/"/>
    
    <category term="Pipeline" scheme="https://zhangchaofan01.gitee.io/tags/Pipeline/"/>
    
    <category term="RNA-seq" scheme="https://zhangchaofan01.gitee.io/tags/RNA-seq/"/>
    
  </entry>
  
  <entry>
    <title>EvolvePro-directed evolution</title>
    <link href="https://zhangchaofan01.gitee.io/2025/04/15/evolvepro-directed-evolution/"/>
    <id>https://zhangchaofan01.gitee.io/2025/04/15/evolvepro-directed-evolution/</id>
    <published>2025-04-15T10:48:07.000Z</published>
    <updated>2025-05-18T10:51:30.606Z</updated>
    
    <content type="html"><![CDATA[<style>pre {  overflow-y: auto;  max-height: 300px;}</style><h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>进化（演化）是生物种群在遗传变异、自然选择、遗传漂变等因素作用下，随时间累积而发生的适应性变化过程。进化的结果在宏观上可以体现在生物体与祖先的表型差异，微观上则是分子水平的基因频率改变。自然界中的进化有几个重要性的因素：1）变异的多样性；2）变异可遗传；3）选择压力适中。<br>&emsp;&emsp;而定向进化则是人为地模拟自然界中选择作用，可以对物种的表型进行选择，也可以对具体的某个分子（蛋白）进行选择。我们首先从原始序列（也称为野生型）人工构建大量的突变体文库，然后衡量突变体的表型（如植株的高度，果实大小、蛋白分子的稳定性|溶解度|酶活性等）。选择最优表型的突变体，作为下一次突变的起始序列，迭代这一过程。这一过程可以理解为于爬山，理想表型的突变体在山顶，每迭代一次相当于向山顶靠近一步。<br>&emsp;&emsp;20世纪中叶小麦的绿色革命可以作为一个宏观定向进化的例子，我们想获得一个抗倒伏的矮杆品种，初始情况下我们有一个性状优良的小麦群体，但是这个群体的小麦都比较高。我们人为选取该群体中较矮的植株进行诱变，对后代的植株高度进行观察，选择后代中较矮的植株再进行诱变，如此迭代几轮，直到后代整体的植株高度符合要求。分子的定向进化也类似于这个过程。<br>&emsp;&emsp;前言部分只是简单的介绍了下背景，感兴趣的同学可以去深入了解。大家可以想一下为什么<code>酶定向进化</code>和<code>肽和抗体噬菌体展示</code>一起获得2018年诺贝尔化学奖。</p><p><a href="https://www.nature.shu.edu.cn/CN/10.3969/j.issn.0253-9608.2018.06.004"><img src="https://s21.ax1x.com/2025/05/18/pEv672q.png" alt="pEv672q.png"></a></p><h2 id="1-EvolvePro环境安装"><a href="#1-EvolvePro环境安装" class="headerlink" title="1. EvolvePro环境安装"></a>1. EvolvePro环境安装</h2><p>需要预安装的一些软件，包括：</p><ol><li><code>conda</code></li><li><code>CUDA驱动</code></li><li><code>Slurm</code>作业提交系统</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">## 1. EvolvePro的安装</span>git clone https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>mat10d<span class="token operator">/</span>EvolvePro<span class="token punctuation">.</span>gitcd EvolveProconda env create <span class="token operator">-</span>f environment<span class="token punctuation">.</span>ymlconda activate evolvepro<span class="token comment">## 2. 安装依赖</span><span class="token comment">### 感觉不是必须</span><span class="token comment">### 众所周知的原因，大陆地区这里可能会失败，多试几次就好了（雾</span>sh setup_plm<span class="token punctuation">.</span>shconda activate plm<span class="token comment"># 切换回evolvepro</span>conda activate evolvepro<span class="token comment">## 3. Download Pretrained models</span><span class="token comment"># wget https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt</span>cd  data<span class="token operator">/</span>chaofan<span class="token operator">/</span>projects<span class="token operator">/</span><span class="token number">08</span><span class="token punctuation">.</span>Directed_evolution<span class="token operator">/</span><span class="token number">00</span><span class="token punctuation">.</span>EVOLVEpro <span class="token comment"># 工作文件夹</span>wget https<span class="token punctuation">:</span><span class="token operator">//</span>dl<span class="token punctuation">.</span>fbaipublicfiles<span class="token punctuation">.</span>com<span class="token operator">/</span>fair<span class="token operator">-</span>esm<span class="token operator">/</span>models<span class="token operator">/</span>esm1b_t33_650M_UR50S<span class="token punctuation">.</span>ptwget https<span class="token punctuation">:</span><span class="token operator">//</span>dl<span class="token punctuation">.</span>fbaipublicfiles<span class="token punctuation">.</span>com<span class="token operator">/</span>fair<span class="token operator">-</span>esm<span class="token operator">/</span>regression<span class="token operator">/</span>esm1b_t33_650M_UR50S<span class="token operator">-</span>contact<span class="token operator">-</span>regression<span class="token punctuation">.</span>pt<span class="token comment"># wget https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt</span><span class="token comment"># wget https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt</span><span class="token comment">### esm2用在下游任务上会比esm1b好一点</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;有两条路，一条是多轮实验迭代，每轮实验加入新测量的表型值；另一条是基于深度突变扫描的数据。</p><h2 id="2-代码实现-Experimental-Workflow"><a href="#2-代码实现-Experimental-Workflow" class="headerlink" title="2. 代码实现 (Experimental Workflow)"></a>2. 代码实现 (Experimental Workflow)</h2><h3 id="2-1-构建单氨基酸突变文库"><a href="#2-1-构建单氨基酸突变文库" class="headerlink" title="2.1 构建单氨基酸突变文库"></a>2.1 构建单氨基酸突变文库</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>process <span class="token keyword">import</span> generate_wt<span class="token punctuation">,</span> generate_single_aa_mutantsgenerate_wt<span class="token punctuation">(</span><span class="token string">'MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR'</span><span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">'./kelsic_WT.fasta'</span><span class="token punctuation">)</span>generate_single_aa_mutants<span class="token punctuation">(</span><span class="token string">'./kelsic_WT.fasta'</span><span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">'./kelsic.fasta'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Number of mutants: 1369<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>process <span class="token keyword">import</span> suggest_initial_mutantssuggest_initial_mutants<span class="token punctuation">(</span><span class="token string">'./kelsic.fasta'</span><span class="token punctuation">,</span> num_mutants<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span> random_seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Suggested 12 mutants for testing:1. R23K2. T58E3. I36D4. V31C5. I7A6. K3F7. Q10P8. G38E9. E4M10. D61W11. E4Y12. R23N<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们随机的从单突变体文库中挑选这12条突变序列进行模型初始的训练，这12条序列与后续的Round1.xlsx文件是对应的。</p><h3 id="2-2-获取Protein-Language-model的编码矩阵"><a href="#2-2-获取Protein-Language-model的编码矩阵" class="headerlink" title="2.2 获取Protein Language model的编码矩阵"></a>2.2 获取Protein Language model的编码矩阵</h3><p><code>BERT</code>语言模型能很好的将离散的文本序列转换为数值型的特征矩阵，广泛运用于文本分类任务</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">!mkdir <span class="token operator">-</span>p Single_mutation_concatenate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 如提前下好了预训练模型，通过 .pt 结尾文件代表本地加载权重，如没有 .pt后缀，默认会重新下载权重文件。</span>!python <span class="token operator">/</span>data<span class="token operator">/</span>chaofan<span class="token operator">/</span>software<span class="token operator">/</span>EvolvePro<span class="token operator">/</span>evolvepro<span class="token operator">/</span>plm<span class="token operator">/</span>esm<span class="token operator">/</span>extract<span class="token punctuation">.</span>py esm1b_t33_650M_UR50S<span class="token punctuation">.</span>pt <span class="token punctuation">.</span><span class="token operator">/</span>kelsic<span class="token punctuation">.</span>fasta <span class="token punctuation">.</span><span class="token operator">/</span>kelsic_esm1b_t33_650M_UR50S <span class="token operator">-</span><span class="token operator">-</span>toks_per_batch <span class="token number">512</span> <span class="token operator">-</span><span class="token operator">-</span>include mean <span class="token operator">-</span><span class="token operator">-</span>concatenate_dir <span class="token punctuation">.</span><span class="token operator">/</span>Single_mutation_concatenate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Transferred model to GPURead kelsic.fasta with 1369 sequencesProcessing 1 of 196 batches (7 sequences)Device: cuda:0Processing 2 of 196 batches (7 sequences)Device: cuda:0Processing 3 of 196 batches (7 sequences)Device: cuda:0Processing 4 of 196 batches (7 sequences)Device: cuda:0Processing 5 of 196 batches (7 sequences)Device: cuda:0Processing 6 of 196 batches (7 sequences)Device: cuda:0Processing 7 of 196 batches (7 sequences)Device: cuda:0Processing 8 of 196 batches (7 sequences)Device: cuda:0Processing 9 of 196 batches (7 sequences)Device: cuda:0Processing 10 of 196 batches (7 sequences)Device: cuda:0Processing 11 of 196 batches (7 sequences)Device: cuda:0Processing 12 of 196 batches (7 sequences)Device: cuda:0Processing 13 of 196 batches (7 sequences)Device: cuda:0Processing 14 of 196 batches (7 sequences)Device: cuda:0Processing 15 of 196 batches (7 sequences)Device: cuda:0Processing 16 of 196 batches (7 sequences)Device: cuda:0Processing 17 of 196 batches (7 sequences)Device: cuda:0Processing 18 of 196 batches (7 sequences)Device: cuda:0Processing 19 of 196 batches (7 sequences)Device: cuda:0Processing 20 of 196 batches (7 sequences)Device: cuda:0Processing 21 of 196 batches (7 sequences)Device: cuda:0Processing 22 of 196 batches (7 sequences)Device: cuda:0Processing 23 of 196 batches (7 sequences)Device: cuda:0Processing 24 of 196 batches (7 sequences)Device: cuda:0Processing 25 of 196 batches (7 sequences)Device: cuda:0Processing 26 of 196 batches (7 sequences)Device: cuda:0Processing 27 of 196 batches (7 sequences)Device: cuda:0Processing 28 of 196 batches (7 sequences)Device: cuda:0Processing 29 of 196 batches (7 sequences)Device: cuda:0Processing 30 of 196 batches (7 sequences)Device: cuda:0Processing 31 of 196 batches (7 sequences)Device: cuda:0Processing 32 of 196 batches (7 sequences)Device: cuda:0Processing 33 of 196 batches (7 sequences)Device: cuda:0Processing 34 of 196 batches (7 sequences)Device: cuda:0Processing 35 of 196 batches (7 sequences)Device: cuda:0Processing 36 of 196 batches (7 sequences)Device: cuda:0Processing 37 of 196 batches (7 sequences)Device: cuda:0Processing 38 of 196 batches (7 sequences)Device: cuda:0Processing 39 of 196 batches (7 sequences)Device: cuda:0Processing 40 of 196 batches (7 sequences)Device: cuda:0Processing 41 of 196 batches (7 sequences)Device: cuda:0Processing 42 of 196 batches (7 sequences)Device: cuda:0Processing 43 of 196 batches (7 sequences)Device: cuda:0Processing 44 of 196 batches (7 sequences)Device: cuda:0Processing 45 of 196 batches (7 sequences)Device: cuda:0Processing 46 of 196 batches (7 sequences)Device: cuda:0Processing 47 of 196 batches (7 sequences)Device: cuda:0Processing 48 of 196 batches (7 sequences)Device: cuda:0Processing 49 of 196 batches (7 sequences)Device: cuda:0Processing 50 of 196 batches (7 sequences)Device: cuda:0Processing 51 of 196 batches (7 sequences)Device: cuda:0Processing 52 of 196 batches (7 sequences)Device: cuda:0Processing 53 of 196 batches (7 sequences)Device: cuda:0Processing 54 of 196 batches (7 sequences)Device: cuda:0Processing 55 of 196 batches (7 sequences)Device: cuda:0Processing 56 of 196 batches (7 sequences)Device: cuda:0Processing 57 of 196 batches (7 sequences)Device: cuda:0Processing 58 of 196 batches (7 sequences)Device: cuda:0Processing 59 of 196 batches (7 sequences)Device: cuda:0Processing 60 of 196 batches (7 sequences)Device: cuda:0Processing 61 of 196 batches (7 sequences)Device: cuda:0Processing 62 of 196 batches (7 sequences)Device: cuda:0Processing 63 of 196 batches (7 sequences)Device: cuda:0Processing 64 of 196 batches (7 sequences)Device: cuda:0Processing 65 of 196 batches (7 sequences)Device: cuda:0Processing 66 of 196 batches (7 sequences)Device: cuda:0Processing 67 of 196 batches (7 sequences)Device: cuda:0Processing 68 of 196 batches (7 sequences)Device: cuda:0Processing 69 of 196 batches (7 sequences)Device: cuda:0Processing 70 of 196 batches (7 sequences)Device: cuda:0Processing 71 of 196 batches (7 sequences)Device: cuda:0Processing 72 of 196 batches (7 sequences)Device: cuda:0Processing 73 of 196 batches (7 sequences)Device: cuda:0Processing 74 of 196 batches (7 sequences)Device: cuda:0Processing 75 of 196 batches (7 sequences)Device: cuda:0Processing 76 of 196 batches (7 sequences)Device: cuda:0Processing 77 of 196 batches (7 sequences)Device: cuda:0Processing 78 of 196 batches (7 sequences)Device: cuda:0Processing 79 of 196 batches (7 sequences)Device: cuda:0Processing 80 of 196 batches (7 sequences)Device: cuda:0Processing 81 of 196 batches (7 sequences)Device: cuda:0Processing 82 of 196 batches (7 sequences)Device: cuda:0Processing 83 of 196 batches (7 sequences)Device: cuda:0Processing 84 of 196 batches (7 sequences)Device: cuda:0Processing 85 of 196 batches (7 sequences)Device: cuda:0Processing 86 of 196 batches (7 sequences)Device: cuda:0Processing 87 of 196 batches (7 sequences)Device: cuda:0Processing 88 of 196 batches (7 sequences)Device: cuda:0Processing 89 of 196 batches (7 sequences)Device: cuda:0Processing 90 of 196 batches (7 sequences)Device: cuda:0Processing 91 of 196 batches (7 sequences)Device: cuda:0Processing 92 of 196 batches (7 sequences)Device: cuda:0Processing 93 of 196 batches (7 sequences)Device: cuda:0Processing 94 of 196 batches (7 sequences)Device: cuda:0Processing 95 of 196 batches (7 sequences)Device: cuda:0Processing 96 of 196 batches (7 sequences)Device: cuda:0Processing 97 of 196 batches (7 sequences)Device: cuda:0Processing 98 of 196 batches (7 sequences)Device: cuda:0Processing 99 of 196 batches (7 sequences)Device: cuda:0Processing 100 of 196 batches (7 sequences)Device: cuda:0Processing 101 of 196 batches (7 sequences)Device: cuda:0Processing 102 of 196 batches (7 sequences)Device: cuda:0Processing 103 of 196 batches (7 sequences)Device: cuda:0Processing 104 of 196 batches (7 sequences)Device: cuda:0Processing 105 of 196 batches (7 sequences)Device: cuda:0Processing 106 of 196 batches (7 sequences)Device: cuda:0Processing 107 of 196 batches (7 sequences)Device: cuda:0Processing 108 of 196 batches (7 sequences)Device: cuda:0Processing 109 of 196 batches (7 sequences)Device: cuda:0Processing 110 of 196 batches (7 sequences)Device: cuda:0Processing 111 of 196 batches (7 sequences)Device: cuda:0Processing 112 of 196 batches (7 sequences)Device: cuda:0Processing 113 of 196 batches (7 sequences)Device: cuda:0Processing 114 of 196 batches (7 sequences)Device: cuda:0Processing 115 of 196 batches (7 sequences)Device: cuda:0Processing 116 of 196 batches (7 sequences)Device: cuda:0Processing 117 of 196 batches (7 sequences)Device: cuda:0Processing 118 of 196 batches (7 sequences)Device: cuda:0Processing 119 of 196 batches (7 sequences)Device: cuda:0Processing 120 of 196 batches (7 sequences)Device: cuda:0Processing 121 of 196 batches (7 sequences)Device: cuda:0Processing 122 of 196 batches (7 sequences)Device: cuda:0Processing 123 of 196 batches (7 sequences)Device: cuda:0Processing 124 of 196 batches (7 sequences)Device: cuda:0Processing 125 of 196 batches (7 sequences)Device: cuda:0Processing 126 of 196 batches (7 sequences)Device: cuda:0Processing 127 of 196 batches (7 sequences)Device: cuda:0Processing 128 of 196 batches (7 sequences)Device: cuda:0Processing 129 of 196 batches (7 sequences)Device: cuda:0Processing 130 of 196 batches (7 sequences)Device: cuda:0Processing 131 of 196 batches (7 sequences)Device: cuda:0Processing 132 of 196 batches (7 sequences)Device: cuda:0Processing 133 of 196 batches (7 sequences)Device: cuda:0Processing 134 of 196 batches (7 sequences)Device: cuda:0Processing 135 of 196 batches (7 sequences)Device: cuda:0Processing 136 of 196 batches (7 sequences)Device: cuda:0Processing 137 of 196 batches (7 sequences)Device: cuda:0Processing 138 of 196 batches (7 sequences)Device: cuda:0Processing 139 of 196 batches (7 sequences)Device: cuda:0Processing 140 of 196 batches (7 sequences)Device: cuda:0Processing 141 of 196 batches (7 sequences)Device: cuda:0Processing 142 of 196 batches (7 sequences)Device: cuda:0Processing 143 of 196 batches (7 sequences)Device: cuda:0Processing 144 of 196 batches (7 sequences)Device: cuda:0Processing 145 of 196 batches (7 sequences)Device: cuda:0Processing 146 of 196 batches (7 sequences)Device: cuda:0Processing 147 of 196 batches (7 sequences)Device: cuda:0Processing 148 of 196 batches (7 sequences)Device: cuda:0Processing 149 of 196 batches (7 sequences)Device: cuda:0Processing 150 of 196 batches (7 sequences)Device: cuda:0Processing 151 of 196 batches (7 sequences)Device: cuda:0Processing 152 of 196 batches (7 sequences)Device: cuda:0Processing 153 of 196 batches (7 sequences)Device: cuda:0Processing 154 of 196 batches (7 sequences)Device: cuda:0Processing 155 of 196 batches (7 sequences)Device: cuda:0Processing 156 of 196 batches (7 sequences)Device: cuda:0Processing 157 of 196 batches (7 sequences)Device: cuda:0Processing 158 of 196 batches (7 sequences)Device: cuda:0Processing 159 of 196 batches (7 sequences)Device: cuda:0Processing 160 of 196 batches (7 sequences)Device: cuda:0Processing 161 of 196 batches (7 sequences)Device: cuda:0Processing 162 of 196 batches (7 sequences)Device: cuda:0Processing 163 of 196 batches (7 sequences)Device: cuda:0Processing 164 of 196 batches (7 sequences)Device: cuda:0Processing 165 of 196 batches (7 sequences)Device: cuda:0Processing 166 of 196 batches (7 sequences)Device: cuda:0Processing 167 of 196 batches (7 sequences)Device: cuda:0Processing 168 of 196 batches (7 sequences)Device: cuda:0Processing 169 of 196 batches (7 sequences)Device: cuda:0Processing 170 of 196 batches (7 sequences)Device: cuda:0Processing 171 of 196 batches (7 sequences)Device: cuda:0Processing 172 of 196 batches (7 sequences)Device: cuda:0Processing 173 of 196 batches (7 sequences)Device: cuda:0Processing 174 of 196 batches (7 sequences)Device: cuda:0Processing 175 of 196 batches (7 sequences)Device: cuda:0Processing 176 of 196 batches (7 sequences)Device: cuda:0Processing 177 of 196 batches (7 sequences)Device: cuda:0Processing 178 of 196 batches (7 sequences)Device: cuda:0Processing 179 of 196 batches (7 sequences)Device: cuda:0Processing 180 of 196 batches (7 sequences)Device: cuda:0Processing 181 of 196 batches (7 sequences)Device: cuda:0Processing 182 of 196 batches (7 sequences)Device: cuda:0Processing 183 of 196 batches (7 sequences)Device: cuda:0Processing 184 of 196 batches (7 sequences)Device: cuda:0Processing 185 of 196 batches (7 sequences)Device: cuda:0Processing 186 of 196 batches (7 sequences)Device: cuda:0Processing 187 of 196 batches (7 sequences)Device: cuda:0Processing 188 of 196 batches (7 sequences)Device: cuda:0Processing 189 of 196 batches (7 sequences)Device: cuda:0Processing 190 of 196 batches (7 sequences)Device: cuda:0Processing 191 of 196 batches (7 sequences)Device: cuda:0Processing 192 of 196 batches (7 sequences)Device: cuda:0Processing 193 of 196 batches (7 sequences)Device: cuda:0Processing 194 of 196 batches (7 sequences)Device: cuda:0Processing 195 of 196 batches (7 sequences)Device: cuda:0Processing 196 of 196 batches (4 sequences)Device: cuda:0Saved representations to kelsic_esm1b_t33_650M_UR50SShape of concatenated DataFrame: (1369, 1280)Saved concatenated representations to Single_mutation_concatenate/kelsic_esm1b_t33_650M_UR50S.pt.csv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因为频繁出现注入攻击，现pytorch强制要求加载权重时是否相信来源，此处需要修改<code>/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/esm/pretrained.py</code>代码， 在第70行调用函数处加上<code>weights_only=False</code>。<br><a href="https://imgse.com/i/pEj78Ds"><img src="https://s21.ax1x.com/2025/05/15/pEj78Ds.png" alt="pEj78Ds.png"></a></p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">Number <span class="token keyword">of</span> <span class="token literal-property property">mutants</span><span class="token operator">:</span> <span class="token number">1369</span><span class="token function">Traceback</span> <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token operator">:</span>  File <span class="token string">"/data/chaofan/software/EvolvePro/evolvepro/plm/esm/extract.py"</span><span class="token punctuation">,</span> line <span class="token number">193</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/data/chaofan/software/EvolvePro/evolvepro/plm/esm/extract.py"</span><span class="token punctuation">,</span> line <span class="token number">181</span><span class="token punctuation">,</span> <span class="token keyword">in</span> main    <span class="token function">run</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>  File <span class="token string">"/data/chaofan/software/EvolvePro/evolvepro/plm/esm/extract.py"</span><span class="token punctuation">,</span> line <span class="token number">73</span><span class="token punctuation">,</span> <span class="token keyword">in</span> run    model<span class="token punctuation">,</span> alphabet <span class="token operator">=</span> pretrained<span class="token punctuation">.</span><span class="token function">load_model_and_alphabet</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_location<span class="token punctuation">)</span>                      <span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>  File <span class="token string">"/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/esm/pretrained.py"</span><span class="token punctuation">,</span> line <span class="token number">26</span><span class="token punctuation">,</span> <span class="token keyword">in</span> load_model_and_alphabet    <span class="token keyword">return</span> <span class="token function">load_model_and_alphabet_local</span><span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>           <span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>  File <span class="token string">"/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/esm/pretrained.py"</span><span class="token punctuation">,</span> line <span class="token number">70</span><span class="token punctuation">,</span> <span class="token keyword">in</span> load_model_and_alphabet_local    model_data <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token function">str</span><span class="token punctuation">(</span>model_location<span class="token punctuation">)</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>                 <span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>  File <span class="token string">"/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/torch/serialization.py"</span><span class="token punctuation">,</span> line <span class="token number">1470</span><span class="token punctuation">,</span> <span class="token keyword">in</span> load    raise pickle<span class="token punctuation">.</span><span class="token function">UnpicklingError</span><span class="token punctuation">(</span><span class="token function">_get_wo_message</span><span class="token punctuation">(</span><span class="token function">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> from None_pickle<span class="token punctuation">.</span>UnpicklingError<span class="token operator">:</span> Weights only load failed<span class="token punctuation">.</span> This file can still be loaded<span class="token punctuation">,</span> to <span class="token keyword">do</span> so you have two options<span class="token punctuation">,</span> <span class="token keyword">do</span> those steps only <span class="token keyword">if</span> you trust the source <span class="token keyword">of</span> the checkpoint<span class="token punctuation">.</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> In PyTorch <span class="token number">2.6</span><span class="token punctuation">,</span> we changed the <span class="token keyword">default</span> value <span class="token keyword">of</span> the <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">weights_only</span><span class="token template-punctuation string">`</span></span> argument <span class="token keyword">in</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.load</span><span class="token template-punctuation string">`</span></span> <span class="token keyword">from</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">False</span><span class="token template-punctuation string">`</span></span> to <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">True</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">.</span> Re<span class="token operator">-</span>running <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.load</span><span class="token template-punctuation string">`</span></span> <span class="token keyword">with</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">weights_only</span><span class="token template-punctuation string">`</span></span> <span class="token keyword">set</span> to <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">False</span><span class="token template-punctuation string">`</span></span> will likely succeed<span class="token punctuation">,</span> but it can result <span class="token keyword">in</span> arbitrary code execution<span class="token punctuation">.</span> Do it only <span class="token keyword">if</span> you got the file from a trusted source<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> Alternatively<span class="token punctuation">,</span> to load <span class="token keyword">with</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">weights_only=True</span><span class="token template-punctuation string">`</span></span> please check the recommended steps <span class="token keyword">in</span> the following error message<span class="token punctuation">.</span>WeightsUnpickler error<span class="token operator">:</span> Unsupported global<span class="token operator">:</span> <span class="token constant">GLOBAL</span> argparse<span class="token punctuation">.</span>Namespace was not an allowed global by <span class="token keyword">default</span><span class="token punctuation">.</span> Please use <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.serialization.add_safe_globals([Namespace])</span><span class="token template-punctuation string">`</span></span> or the <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.serialization.safe_globals([Namespace])</span><span class="token template-punctuation string">`</span></span> context manager to allowlist <span class="token keyword">this</span> global <span class="token keyword">if</span> you trust <span class="token keyword">this</span> <span class="token keyword">class</span><span class="token operator">/</span><span class="token keyword">function</span><span class="token punctuation">.</span>Check the documentation <span class="token keyword">of</span> torch<span class="token punctuation">.</span>load to learn more about types accepted by <span class="token keyword">default</span> <span class="token keyword">with</span> weights_only https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>pytorch<span class="token punctuation">.</span>org<span class="token operator">/</span>docs<span class="token operator">/</span>stable<span class="token operator">/</span>generated<span class="token operator">/</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">.</span>html<span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>经过上述步骤，每条文本的氨基酸序列被一个长为1280的数值向量代替，表格中一共有1369条序列，分别是一条野生型+1368条(19*野生型序列长度)单氨基酸变异序列</p><h3 id="2-3-对模型进行多轮few-shot训练"><a href="#2-3-对模型进行多轮few-shot训练" class="headerlink" title="2.3 对模型进行多轮few-shot训练"></a>2.3 对模型进行多轮few-shot训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>evolve <span class="token keyword">import</span> evolve_experimentalprotein_name <span class="token operator">=</span> <span class="token string">'kelsic'</span>embeddings_base_path <span class="token operator">=</span> <span class="token string">'Single_mutation_concatenate'</span>embeddings_file_name <span class="token operator">=</span> <span class="token string">'kelsic_esm1b_t33_650M_UR50S.pt.csv'</span>round_base_path <span class="token operator">=</span> <span class="token string">'/data/chaofan/software/EvolvePro/colab/rounds_data'</span>wt_fasta_path <span class="token operator">=</span> <span class="token string">"./kelsic_WT.fasta"</span>number_of_variants <span class="token operator">=</span> <span class="token number">12</span>output_dir <span class="token operator">=</span> <span class="token string">'./'</span>rename_WT <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-1-Round1"><a href="#2-3-1-Round1" class="headerlink" title="2.3.1 Round1"></a>2.3.1 Round1</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round1'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round1    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    iteration shape: (12, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1357,)        Tested variants in this round: 12    43       K3F    67       E4M    76       E4Y    115      I7A    184     Q10P    427     R23K    430     R23N    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    Name: variant, dtype: object        Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary dist_metric  \    74      E4V  0.954787       NaN              NaN              NaN        None       225    T12S  0.952057       NaN              NaN              NaN        None       5       M1F  0.951310       NaN              NaN              NaN        None       63      E4H  0.950540       NaN              NaN              NaN        None       15      M1S  0.947988       NaN              NaN              NaN        None       19      M1Y  0.944838       NaN              NaN              NaN        None       18      M1W  0.944590       NaN              NaN              NaN        None       249    L14C  0.942195       NaN              NaN              NaN        None       61      E4F  0.942045       NaN              NaN              NaN        None       10      M1L  0.941873       NaN              NaN              NaN        None       142     E8L  0.941533       NaN              NaN              NaN        None       135     E8C  0.941173       NaN              NaN              NaN        None                std_predictions      74               0.0      225              0.0      5                0.0      63               0.0      15               0.0      19               0.0      18               0.0      249              0.0      61               0.0      10               0.0      142              0.0      135              0.0          Data saved to ./kelsic/Round1    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;模型的设计非常简单，主要是用预训练的BERT模型去抽特征，然后用传统的机器学习方法(随机森林，XGBoost等)对特征进行回归分析。第一轮使用<code>12</code>条随机数据进行训练，第二列使用<code>12 * 2</code>条数据重新训练，以此类推，第N轮使用<code>12 * N</code>条数据进行训练。每轮只训练顶层的传统机器学习模型。<br>&emsp;&emsp;训练后的模型先对整个突变体库扫一遍，对每个突变体进行表型值打分并排序，取预测表型值最好的<code>12</code>个突变体（且没有真实表型值）进行真实表型值验证。将新测量的真实表型值加入到下一轮的模型训练中，也就是每一轮过后，训练数据集会多出<code>12</code>条。按道理来说，<code>Round2.xlsx</code>的数据应该是上一轮预测的Top12突变体的真实表型值，但因为不同软件版本的差异，这里展示的结果可能会与原文有一定的差异，这是正常现象。</p><p><a href="https://www.science.org/cms/10.1126/science.adr6006/asset/65d73316-daa4-4525-93cf-b07d2f0254b2/assets/images/large/science.adr6006-f1.jpg"><img src="https://s21.ax1x.com/2025/05/15/pEjbkTI.png" alt="pEjbkTI.png"></a></p><h4 id="2-3-2-Round2"><a href="#2-3-2-Round2" class="headerlink" title="2.3.2 Round2"></a>2.3.2 Round2</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round2'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round2    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    Loaded experimental data for kelsic_Round2.xlsx: (12, 3)    iteration shape: (24, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1345,)        Tested variants in this round: 24    43       K3F    61       E4F    63       E4H    66       E4L    67       E4M    68       E4N    70       E4Q    74       E4V    76       E4Y    86       D5M    115      I7A    135      E8C    146      E8Q    184     Q10P    211     T12C    220     T12M    427     R23K    430     R23N    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    1332    S71C    Name: variant, dtype: object        Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary dist_metric  \    80      D5F  1.000372       NaN              NaN              NaN        None       75      E4W  0.990040       NaN              NaN              NaN        None       64      E4I  0.982857       NaN              NaN              NaN        None       83      D5I  0.977915       NaN              NaN              NaN        None       95      D5Y  0.974122       NaN              NaN              NaN        None       85      D5L  0.971400       NaN              NaN              NaN        None       93      D5V  0.970972       NaN              NaN              NaN        None       62      E4G  0.970870       NaN              NaN              NaN        None       469    E25Q  0.969735       NaN              NaN              NaN        None       7       M1H  0.967748       NaN              NaN              NaN        None       94      D5W  0.967325       NaN              NaN              NaN        None       578    V31I  0.967287       NaN              NaN              NaN        None                std_predictions      80               0.0      75               0.0      64               0.0      83               0.0      95               0.0      85               0.0      93               0.0      62               0.0      469              0.0      7                0.0      94               0.0      578              0.0          Data saved to ./kelsic/Round2    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-3-Round3"><a href="#2-3-3-Round3" class="headerlink" title="2.3.3 Round3"></a>2.3.3 Round3</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round3'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round3    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    Loaded experimental data for kelsic_Round2.xlsx: (12, 3)    Loaded experimental data for kelsic_Round3.xlsx: (12, 3)    iteration shape: (36, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1333,)        Tested variants in this round: 36    18       M1W    43       K3F    59       E4C    61       E4F    63       E4H    64       E4I    66       E4L    67       E4M    68       E4N    70       E4Q    74       E4V    75       E4W    76       E4Y    78       D5C    80       D5F    83       D5I    85       D5L    86       D5M    87       D5N    93       D5V    95       D5Y    115      I7A    135      E8C    146      E8Q    184     Q10P    211     T12C    220     T12M    427     R23K    430     R23N    469     E25Q    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    1332    S71C    Name: variant, dtype: object        Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary dist_metric  \    82      D5H  0.985537       NaN              NaN              NaN        None       77      D5A  0.974578       NaN              NaN              NaN        None       91      D5S  0.973428       NaN              NaN              NaN        None       89      D5Q  0.972064       NaN              NaN              NaN        None       504    E27M  0.964911       NaN              NaN              NaN        None       496    E27C  0.959024       NaN              NaN              NaN        None       500    E27H  0.958966       NaN              NaN              NaN        None       71      E4R  0.957292       NaN              NaN              NaN        None       92      D5T  0.956897       NaN              NaN              NaN        None       137     E8F  0.953024       NaN              NaN              NaN        None       505    E27N  0.952960       NaN              NaN              NaN        None       143     E8M  0.952932       NaN              NaN              NaN        None                std_predictions      82               0.0      77               0.0      91               0.0      89               0.0      504              0.0      496              0.0      500              0.0      71               0.0      92               0.0      137              0.0      505              0.0      143              0.0          Data saved to ./kelsic/Round3    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-4-Round4"><a href="#2-3-4-Round4" class="headerlink" title="2.3.4 Round4"></a>2.3.4 Round4</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round4'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round4.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round4    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    Loaded experimental data for kelsic_Round2.xlsx: (12, 3)    Loaded experimental data for kelsic_Round3.xlsx: (12, 3)    Loaded experimental data for kelsic_Round4.xlsx: (12, 3)    iteration shape: (48, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1321,)        Tested variants in this round: 48    18       M1W    43       K3F    59       E4C    61       E4F    63       E4H    64       E4I    66       E4L    67       E4M    68       E4N    70       E4Q    73       E4T    74       E4V    75       E4W    76       E4Y    77       D5A    78       D5C    80       D5F    82       D5H    83       D5I    85       D5L    86       D5M    87       D5N    89       D5Q    91       D5S    92       D5T    93       D5V    95       D5Y    115      I7A    135      E8C    146      E8Q    184     Q10P    211     T12C    220     T12M    390     M21L    427     R23K    430     R23N    445     V24I    469     E25Q    496     E27C    503     E27L    504     E27M    507     E27Q    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    1332    S71C    Name: variant, dtype: object        Top 12 variants predicted by the model:         variant    y_pred  y_actual  y_actual_scaled  y_actual_binary  \    72       E4S  0.978078       NaN              NaN              NaN       94       D5W  0.977183       NaN              NaN              NaN       69       E4P  0.973912       NaN              NaN              NaN       1281    V68I  0.962484       NaN              NaN              NaN       90       D5R  0.951873       NaN              NaN              NaN       71       E4R  0.948736       NaN              NaN              NaN       88       D5P  0.947673       NaN              NaN              NaN       144      E8N  0.947493       NaN              NaN              NaN       141      E8K  0.947032       NaN              NaN              NaN       1034    V55I  0.945509       NaN              NaN              NaN       616     T33I  0.944996       NaN              NaN              NaN       470     E25R  0.944632       NaN              NaN              NaN                dist_metric  std_predictions      72          None              0.0      94          None              0.0      69          None              0.0      1281        None              0.0      90          None              0.0      71          None              0.0      88          None              0.0      144         None              0.0      141         None              0.0      1034        None              0.0      616         None              0.0      470         None              0.0          Data saved to ./kelsic/Round4    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-5-Round5"><a href="#2-3-5-Round5" class="headerlink" title="2.3.5 Round5"></a>2.3.5 Round5</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round5'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round4.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round5.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round5   Embeddings loaded: (1369, 1280)   Loaded experimental data for kelsic_Round1.xlsx: (12, 3)   Loaded experimental data for kelsic_Round2.xlsx: (12, 3)   Loaded experimental data for kelsic_Round3.xlsx: (12, 3)   Loaded experimental data for kelsic_Round4.xlsx: (12, 3)   Loaded experimental data for kelsic_Round5.xlsx: (12, 3)   iteration shape: (60, 2)   Labels shape: (1369, 5)   Embeddings and labels are aligned   (1309,)      Tested variants in this round: 60   18       M1W   43       K3F   58       E4A   59       E4C   61       E4F   63       E4H   64       E4I   66       E4L   67       E4M   68       E4N   69       E4P   70       E4Q   72       E4S   73       E4T   74       E4V   75       E4W   76       E4Y   77       D5A   78       D5C   80       D5F   82       D5H   83       D5I   85       D5L   86       D5M   87       D5N   88       D5P   89       D5Q   91       D5S   92       D5T   93       D5V   94       D5W   95       D5Y   115      I7A   135      E8C   137      E8F   139      E8H   141      E8K   146      E8Q   178     Q10H   184     Q10P   211     T12C   220     T12M   368     T20H   390     M21L   427     R23K   430     R23N   445     V24I   469     E25Q   496     E27C   503     E27L   504     E27M   507     E27Q   572     V31C   668     I36D   707     G38E   1034    V55I   1087    T58E   1158    D61W   1332    S71C   1339    S71K   Name: variant, dtype: object      Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary  \   114      N6Y  0.954242       NaN              NaN              NaN      373     T20N  0.950471       NaN              NaN              NaN      65       E4K  0.950415       NaN              NaN              NaN      226     T12V  0.949447       NaN              NaN              NaN      1281    V68I  0.947393       NaN              NaN              NaN      464     E25K  0.947118       NaN              NaN              NaN      71       E4R  0.946143       NaN              NaN              NaN      144      E8N  0.940163       NaN              NaN              NaN      628     A34C  0.937827       NaN              NaN              NaN      1349    S71Y  0.936767       NaN              NaN              NaN      1169    L62M  0.934671       NaN              NaN              NaN      370     T20K  0.934475       NaN              NaN              NaN              dist_metric  std_predictions     114         None              0.0     373         None              0.0     65          None              0.0     226         None              0.0     1281        None              0.0     464         None              0.0     71          None              0.0     144         None              0.0     628         None              0.0     1349        None              0.0     1169        None              0.0     370         None              0.0        Data saved to ./kelsic/Round5   /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.     df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-6-plot"><a href="#2-3-6-plot" class="headerlink" title="2.3.6 plot"></a>2.3.6 plot</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>plot <span class="token keyword">import</span> read_exp_data<span class="token punctuation">,</span> plot_variants_by_iterationround_base_path <span class="token operator">=</span> <span class="token string">'/data/chaofan/software/EvolvePro/colab/rounds_data'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round4.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round5.xlsx'</span><span class="token punctuation">]</span>wt_fasta_path <span class="token operator">=</span> <span class="token string">"./kelsic_WT.fasta"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> read_exp_data<span class="token punctuation">(</span>round_base_path<span class="token punctuation">,</span> round_file_names<span class="token punctuation">,</span> wt_fasta_path<span class="token punctuation">)</span>plot_variants_by_iteration<span class="token punctuation">(</span>df<span class="token punctuation">,</span> activity_column<span class="token operator">=</span><span class="token string">'activity'</span><span class="token punctuation">,</span> output_dir<span class="token operator">=</span>output_dir<span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">"kelsic"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pEv2D54"><img src="https://s21.ax1x.com/2025/05/18/pEv2D54.png" alt="pEv2D54.png"></a></p><h2 id="3-代码实现-Deep-Mutational-Scanning-Workflow"><a href="#3-代码实现-Deep-Mutational-Scanning-Workflow" class="headerlink" title="3. 代码实现 (Deep Mutational Scanning Workflow)"></a>3. 代码实现 (Deep Mutational Scanning Workflow)</h2><p>DMS数据集包含具体的突变位点和表型数据，我们需要生成突变体文库对应的fasta和embedding特征矩阵，才能进行下游的迭代训练。</p><h3 id="3-1-生成突变体序列和对应表型表格"><a href="#3-1-生成突变体序列和对应表型表格" class="headerlink" title="3.1 生成突变体序列和对应表型表格"></a>3.1 生成突变体序列和对应表型表格</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">!cp <span class="token operator">-</span>r <span class="token operator">/</span>data<span class="token operator">/</span>chaofan<span class="token operator">/</span>software<span class="token operator">/</span>EvolvePro<span class="token operator">/</span>data <span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对<code>scripts/process/dms_process.py</code>代码的<code>project_root</code>进行修改</p><p><a href="https://imgse.com/i/pEvAZlQ"><img src="https://s21.ax1x.com/2025/05/16/pEvAZlQ.png" alt="pEvAZlQ.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">!python <span class="token operator">/</span>data<span class="token operator">/</span>chaofan<span class="token operator">/</span>software<span class="token operator">/</span>EvolvePro<span class="token operator">/</span>scripts<span class="token operator">/</span>process<span class="token operator">/</span>dms_process<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="https://imgse.com/i/pEvAmOs"><img src="https://s21.ax1x.com/2025/05/16/pEvAmOs.png" alt="pEvAmOs.png"></a></p><h3 id="3-2-获取氨基酸序列的embedding特征矩阵"><a href="#3-2-获取氨基酸序列的embedding特征矩阵" class="headerlink" title="3.2 获取氨基酸序列的embedding特征矩阵"></a>3.2 获取氨基酸序列的embedding特征矩阵</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">!sbatch esm2_650M_dms<span class="token punctuation">.</span>sh<span class="token comment"># 运行时大概占3G显存</span><span class="token comment"># 这一步运行时间非常长</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>esm2_650M_dms.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;bash# Configuration values for SLURM job submission.# One leading hash ahead of the word SBATCH is not a comment, but two are.#SBATCH --job-name&#x3D;esm#SBATCH --gres&#x3D;gpu:1#SBATCH --cpus-per-task&#x3D;1   #SBATCH --mem&#x3D;200gb  #SBATCH --output out&#x2F;esm-%j.out study_names&#x3D;(&quot;brenan&quot; &quot;jones&quot; &quot;stiffler&quot; &quot;haddox&quot; &quot;doud&quot; &quot;giacomelli&quot; &quot;kelsic&quot; &quot;lee&quot; &quot;markin&quot; &quot;cas12f&quot; &quot;cov2_S&quot; &quot;zikv_E&quot;)model_names&#x3D;(&quot;esm2_t33_650M_UR50D&quot;)fasta_path&#x3D;&quot;output&#x2F;dms&#x2F;&quot;results_path&#x3D;&quot;output&#x2F;plm&#x2F;esm&#x2F;&quot;repr_layers&#x3D;33toks_per_batch&#x3D;2000mkdir -p $&#123;results_path&#125;for model_name in &quot;$&#123;model_names[@]&#125;&quot;; do  for study in &quot;$&#123;study_names[@]&#125;&quot;; do    command&#x3D;&quot;python3 &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;EvolvePro&#x2F;evolvepro&#x2F;plm&#x2F;esm&#x2F;extract.py $&#123;model_name&#125;.pt $&#123;fasta_path&#125;$&#123;study&#125;.fasta $&#123;results_path&#125;$&#123;study&#125;&#x2F;$&#123;model_name&#125; --toks_per_batch $&#123;toks_per_batch&#125; --include mean --concatenate_dir $&#123;results_path&#125;&quot;    echo &quot;Running command: $&#123;command&#125;&quot;    eval &quot;$&#123;command&#125;&quot;  donedone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pEvuqRP"><img src="https://s21.ax1x.com/2025/05/17/pEvuqRP.png" alt="pEvuqRP.png"></a></p><h3 id="3-3-DMS数据验证定向进化"><a href="#3-3-DMS数据验证定向进化" class="headerlink" title="3.3 DMS数据验证定向进化"></a>3.3 DMS数据验证定向进化</h3><p>因为我们输入的是<code>$&#123;model_name&#125;.pt</code>文件，会导致输出文件名都变为<code>$&#123;dataset_name&#125;_esm2_t33_650M_UR50D.pt.csv</code>，但是后续文件的输入又要求是<code>$&#123;dataset_name&#125;_esm2_t33_650M_UR50D.csv</code>，需要进行文件名的批量修改再进行下一步。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">!ls output<span class="token operator">/</span>plm<span class="token operator">/</span>esm<span class="token operator">/</span><span class="token operator">*</span><span class="token punctuation">.</span>csv <span class="token operator">|</span> <span class="token keyword">while</span> read line<span class="token punctuation">;</span> do re_name<span class="token operator">=</span>`echo $line<span class="token operator">|</span>cut <span class="token operator">-</span>d <span class="token string">"/"</span> <span class="token operator">-</span>f4<span class="token operator">|</span>cut <span class="token operator">-</span>d <span class="token string">"."</span> <span class="token operator">-</span>f1`<span class="token punctuation">;</span> mv $<span class="token punctuation">&#123;</span>line<span class="token punctuation">&#125;</span> output<span class="token operator">/</span>plm<span class="token operator">/</span>esm<span class="token operator">/</span>$<span class="token punctuation">&#123;</span>re_name<span class="token punctuation">&#125;</span><span class="token punctuation">.</span>csv<span class="token punctuation">;</span> done<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">!sbatch esm2_650M<span class="token punctuation">.</span>sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>esm2_650M.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;bash# Configuration values for SLURM job submission.# One leading hash ahead of the word SBATCH is not a comment, but two are.#SBATCH --time&#x3D;12:00:00 #SBATCH --job-name&#x3D;esm2_650M_optimal#SBATCH -n 12#SBATCH -N 1   #SBATCH --cpus-per-task&#x3D;5  #SBATCH --mem&#x3D;20gb  #SBATCH --output out&#x2F;esm2_650M_optimal-%j.out source ~&#x2F;.bashrcconda activate evolvepro# module load openmind8&#x2F;gnu-parallel&#x2F;20240222datasets&#x3D;(&quot;brenan&quot; &quot;stiffler&quot; &quot;doud&quot; &quot;haddox&quot; &quot;giacomelli&quot; &quot;jones&quot; &quot;kelsic&quot; &quot;lee&quot; &quot;markin&quot; &quot;zikv_E&quot; &quot;cas12f&quot; &quot;cov2_S&quot;)# Function to run dms_main for a given datasetrun_dms_main() &#123;    dataset_name&#x3D;$1    output_file&#x3D;&quot;out&#x2F;$&#123;dataset_name&#125;-esm2_650M_optimal.out&quot;    echo &quot;Running $&#123;dataset_name&#125; dataset:&quot; &gt; $&#123;output_file&#125;    python3 -u &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;EvolvePro&#x2F;scripts&#x2F;dms&#x2F;dms_main.py \        --dataset_name $&#123;dataset_name&#125; \        --experiment_name &quot;esm2_650M_optimal&quot; \        --model_name &quot;esm2_t33_650M_UR50D&quot; \        --embeddings_path &quot;.&#x2F;output&#x2F;plm&#x2F;esm&quot; \        --labels_path &quot;.&#x2F;output&#x2F;dms&quot; \        --num_simulations 10 \        --num_iterations 10 \        --measured_var &quot;activity&quot; \        --learning_strategies &quot;topn&quot; \        --num_mutants_per_round 16 \        --num_final_round_mutants 16 \        --first_round_strategies &quot;random&quot; \        --embedding_types &quot;embeddings&quot; \        --regression_types &quot;randomforest&quot; \        --embeddings_file_type &quot;csv&quot; \        --output_dir &quot;.&#x2F;output&#x2F;dms_results&quot; \        &gt;&gt; $&#123;output_file&#125; 2&gt;&amp;1    echo &quot;Done running $&#123;dataset_name&#125; dataset:&quot; &gt;&gt; $&#123;output_file&#125;&#125;# Export the function so it&#39;s available to GNU Parallelexport -f run_dms_main# Use GNU Parallel to run the dms_main function in parallel for each datasetparallel -j12 run_dms_main ::: &quot;$&#123;datasets[@]&#125;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pEvKno9"><img src="https://s21.ax1x.com/2025/05/17/pEvKno9.png" alt="pEvKno9.png"></a></p><p>这是其中一个结果表格，还是很清晰的。原文主要利用DMS数据集中大量的突变体和对应的表型数据进行方法可行性的验证，当然也可以从DMS大量的数据基础上去探索更广阔的突变空间。</p><p><a href="https://imgse.com/i/pEv1RBT"><img src="https://s21.ax1x.com/2025/05/17/pEv1RBT.png" alt="pEv1RBT.png"></a></p><p>&emsp;&emsp;好了，你已经学会了目前最热门的借助深度学习辅助定向进化进行蛋白分子的理性设计。</p><center><span style="color:#ff0000;">本人能力有限，难免出现错误，恳请批评指正</span></center>]]></content>
    
    
      
      
    <summary type="html">&lt;style&gt;
pre {
  overflow-y: auto;
  max-height: 300px;
}
&lt;/style&gt;

&lt;h2 id=&quot;0-前言&quot;&gt;&lt;a href=&quot;#0-前言&quot; class=&quot;headerlink&quot; title=&quot;0. 前言&quot;&gt;&lt;/a&gt;0. 前言&lt;</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="https://zhangchaofan01.gitee.io/tags/Deep-Learning/"/>
    
    <category term="Directed evolution" scheme="https://zhangchaofan01.gitee.io/tags/Directed-evolution/"/>
    
    <category term="Molecular design" scheme="https://zhangchaofan01.gitee.io/tags/Molecular-design/"/>
    
  </entry>
  
  <entry>
    <title>Read Fasta File</title>
    <link href="https://zhangchaofan01.gitee.io/2025/01/09/read-fasta-file/"/>
    <id>https://zhangchaofan01.gitee.io/2025/01/09/read-fasta-file/</id>
    <published>2025-01-09T13:34:42.000Z</published>
    <updated>2025-01-09T13:48:23.964Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;我们在平时的工作中经常会遇到对生物序列进行提取或修改，不管是基因组DNA序列还是编码蛋白序列，它们都是fasta格式。一般都是将fasta序列存储为dict格式再进行操作，下面就介绍下我常用或遇到的一些处理方式：</p><h3 id="1-比较原始的逐行处理"><a href="#1-比较原始的逐行处理" class="headerlink" title="1.比较原始的逐行处理"></a>1.比较原始的逐行处理</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#read a fasta file and return a dictionary, the key is entry id and the value is the sequence in upcase</span><span class="token keyword">def</span> <span class="token function">readFasta</span><span class="token punctuation">(</span>fastaFile<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">import</span> gzip    f1 <span class="token operator">=</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>fastaFile<span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> fastaFile<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'gz'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fastaFile<span class="token punctuation">)</span>    line <span class="token operator">=</span> f1<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    sequence <span class="token operator">=</span> <span class="token string">""</span>    fasta_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    header <span class="token operator">=</span> <span class="token string">""</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">:</span>            <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'>'</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sequence<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>                    fasta_dict<span class="token punctuation">[</span>header<span class="token punctuation">]</span> <span class="token operator">=</span> sequence                    sequence <span class="token operator">=</span> <span class="token string">""</span>                header <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                sequence <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>         line <span class="token operator">=</span> f1<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    f1<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> header <span class="token keyword">and</span> sequence<span class="token punctuation">:</span>        fasta_dict<span class="token punctuation">[</span>header<span class="token punctuation">]</span> <span class="token operator">=</span> sequence    <span class="token keyword">return</span> fasta_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-比较优雅的借助Biopython-API"><a href="#2-比较优雅的借助Biopython-API" class="headerlink" title="2.比较优雅的借助Biopython API"></a>2.比较优雅的借助Biopython API</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_fasta</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> subset_chroms<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> Bio <span class="token keyword">import</span> SeqIO    <span class="token keyword">import</span> gzip    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">"rt"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> path<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">".gz"</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span> <span class="token keyword">as</span> handle<span class="token punctuation">:</span>        genome <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>            <span class="token punctuation">&#123;</span>                rec<span class="token punctuation">.</span><span class="token builtin">id</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>rec<span class="token punctuation">.</span>seq<span class="token punctuation">)</span>                <span class="token keyword">for</span> rec <span class="token keyword">in</span> SeqIO<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>handle<span class="token punctuation">,</span> <span class="token string">"fasta"</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> subset_chroms <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> rec<span class="token punctuation">.</span><span class="token builtin">id</span> <span class="token keyword">in</span> subset_chroms            <span class="token punctuation">&#125;</span>        <span class="token punctuation">)</span>    <span class="token keyword">return</span> genome<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（未完待续）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&amp;emsp;&amp;emsp;我们在平时的工作中经常会遇到对生物序列进行提取或修改，不管是基因组DNA序列还是编码蛋白序列，它们都是fasta格式。一般都是将fasta序列存储为dict格式再进行操作，下面就介绍下我常用或遇到的一些处理方式：&lt;/p&gt;
&lt;h3 id=&quot;1-比较原始</summary>
      
    
    
    
    
    <category term="Bioinformatics" scheme="https://zhangchaofan01.gitee.io/tags/Bioinformatics/"/>
    
    <category term="python" scheme="https://zhangchaofan01.gitee.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>GATK_time_compare</title>
    <link href="https://zhangchaofan01.gitee.io/2024/12/14/gatk-time-compare/"/>
    <id>https://zhangchaofan01.gitee.io/2024/12/14/gatk-time-compare/</id>
    <published>2024-12-14T01:27:00.000Z</published>
    <updated>2025-02-14T11:45:26.819Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;事情的起因主要是群里有老哥说INTEL的CPU(有avx512指令集）在用GATK call SNP的时候比AMD(EPYC3代 没有avx512指令集)快8-15倍，直接把我震惊到了。买INTEL，赢在起跑线.jpg<br>&emsp;&emsp;我们现在来测试下</p><h3 id="1-工具下载"><a href="#1-工具下载" class="headerlink" title="1.工具下载"></a>1.工具下载</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir Softwares &amp;&amp; cd Softwares# sra-tools 89.20M # 我们服务器是centos系统，自己下载自己服务器对应的版本wget https:&#x2F;&#x2F;ftp-trace.ncbi.nlm.nih.gov&#x2F;sra&#x2F;sdk&#x2F;3.1.1&#x2F;sratoolkit.3.1.1-centos_linux64.tar.gztar -zxvf sratoolkit.3.1.1-centos_linux64.tar.gz# bwa-mem2curl -L https:&#x2F;&#x2F;github.com&#x2F;bwa-mem2&#x2F;bwa-mem2&#x2F;releases&#x2F;download&#x2F;v2.2.1&#x2F;bwa-mem2-2.2.1_x64-linux.tar.bz2 \  | tar jxf -# fastpwget http:&#x2F;&#x2F;opengene.org&#x2F;fastp&#x2F;fastpchmod a+x .&#x2F;fastp# samtoolsconda activate gatkconda install samtools -c bioconda python <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-原始数据下载"><a href="#2-原始数据下载" class="headerlink" title="2.原始数据下载"></a>2.原始数据下载</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 下载参考基因组文件# https:&#x2F;&#x2F;doi.org&#x2F;10.1126&#x2F;science.adq8191 数据来源mkdir Reference &amp;&amp; cd Referencewget https:&#x2F;&#x2F;github.com&#x2F;yulab-ql&#x2F;mhaESC_genome&#x2F;releases&#x2F;download&#x2F;upd_rmvector&#x2F;mouse.241018.v1.1.0.combined.fasta.gzwget https:&#x2F;&#x2F;github.com&#x2F;yulab-ql&#x2F;mhaESC_genome&#x2F;releases&#x2F;download&#x2F;upd_rmvector&#x2F;mhaESC.annotation.v1.1.0.20241018.gff3.gz# 下载原始测序文件cd ..mdkir 00.raw_data &amp;&amp; cd 00.raw_data# 94GB ..&#x2F;Softwares&#x2F;sratoolkit.3.1.1-centos_linux64&#x2F;bin&#x2F;prefetch SRR28702443 -O .&#x2F; --max-size 1000G..&#x2F;Softwares&#x2F;sratoolkit.3.1.1-centos_linux64&#x2F;bin&#x2F;fastq-dump --gzip --split-files SRR28702443&#x2F;SRR28702443.sra# 原始文件太大了，截取一部分来做测试seqkit sample -n 10000000 00.raw_data&#x2F;SRR28702443_1.fastq.gz | seqkit seq -ni &gt; selected_ids.txt# 过滤 input_1.fastqseqkit grep -f selected_ids.txt input_1.fastq -o output_1.fastq# 过滤 input_2.fastqseqkit grep -f selected_ids.txt input_2.fastq -o output_2.fastq<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-数据前处理"><a href="#3-数据前处理" class="headerlink" title="3.数据前处理"></a>3.数据前处理</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">bwa-mem2-2.2.1_x64-linux&#x2F;bwa-mem2 index ref.fabwa-mem2-2.2.1_x64-linux&#x2F;bwa-mem2 mem ref.fa read1.fq read2.fq &gt; out.sam<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&amp;emsp;&amp;emsp;事情的起因主要是群里有老哥说INTEL的CPU(有avx512指令集）在用GATK call SNP的时候比AMD(EPYC3代 没有avx512指令集)快8-15倍，直接把我震惊到了。买INTEL，赢在起跑线.jpg&lt;br&gt;&amp;emsp;&amp;emsp;</summary>
      
    
    
    
    
    <category term="Bioinformatics" scheme="https://zhangchaofan01.gitee.io/tags/Bioinformatics/"/>
    
  </entry>
  
  <entry>
    <title>Variational_AutoEncoders</title>
    <link href="https://zhangchaofan01.gitee.io/2024/12/12/variational-autoencoders/"/>
    <id>https://zhangchaofan01.gitee.io/2024/12/12/variational-autoencoders/</id>
    <published>2024-12-12T12:10:50.000Z</published>
    <updated>2024-12-12T12:55:09.166Z</updated>
    
    <content type="html"><![CDATA[<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pickle<span class="token keyword">import</span> datasets<span class="token comment"># windows 本地下载并保存</span><span class="token comment"># minist = load_dataset("mnist")</span><span class="token comment"># with open("minist_dataset.pkl", "wb") as f:</span><span class="token comment">#     pickle.dump(minist, f)</span>mnist <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">"./mnist/"</span><span class="token punctuation">)</span>mnist<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>   DatasetDict({<br>       train: Dataset({<br>           features: [‘image’, ‘label’],<br>           num_rows: 60000<br>       })<br>       test: Dataset({<br>           features: [‘image’, ‘label’],<br>           num_rows: 10000<br>       })<br>   })</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> genaibook<span class="token punctuation">.</span>core <span class="token keyword">import</span> show_images show_images<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdqX9"><img src="https://s21.ax1x.com/2024/12/12/pAbdqX9.png" alt="pAbdqX9.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib <span class="token keyword">as</span> mpl mpl<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"image.cmap"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"gray_r"</span>show_images<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdOmR"><img src="https://s21.ax1x.com/2024/12/12/pAbdOmR.png" alt="pAbdOmR.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">def</span> <span class="token function">mnist_to_tensor</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span><span class="token punctuation">:</span>    t <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    samples<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>t<span class="token punctuation">(</span>image<span class="token punctuation">)</span> <span class="token keyword">for</span> image <span class="token keyword">in</span> samples<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> samples mnist <span class="token operator">=</span> mnist<span class="token punctuation">.</span>with_transform<span class="token punctuation">(</span>mnist_to_tensor<span class="token punctuation">)</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span> <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">1337</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>x<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdX01"><img src="https://s21.ax1x.com/2024/12/12/pAbdX01.png" alt="pAbdX01.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader bs <span class="token operator">=</span> <span class="token number">64</span> train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>     batch_size<span class="token operator">=</span>bs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="1-AutoEncoders"><a href="#1-AutoEncoders" class="headerlink" title="1 | AutoEncoders"></a><div style="padding: 30px;color:white;margin:30;font-size:70%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1 |</span></b> <b>AutoEncoders</b></div></h1><p><a href="https://imgse.com/i/pAbZsud"><img src="https://s21.ax1x.com/2024/12/12/pAbZsud.png" alt="pAbZsud.png"></a></p><h1 id="1-1-Encoder-model"><a href="#1-1-Encoder-model" class="headerlink" title="1.1 | Encoder model"></a><div style="padding: 20px;color:white;margin:10;font-size:50%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1.1 |</span></b> <b>Encoder model</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn <span class="token keyword">def</span> <span class="token function">conv_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernal_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>               stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>            in_channels<span class="token punctuation">,</span>            out_channels<span class="token punctuation">,</span>            kernel_size<span class="token operator">=</span>kernal_size<span class="token punctuation">,</span>            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>            padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>        <span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv4 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>               x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>torch.Size([1, 28, 28])</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">in_channels <span class="token operator">=</span> <span class="token number">1</span> x <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>encoded <span class="token operator">=</span> encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>encoded<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>torch.Size([1, 16])</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">encoded<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>   tensor([[-0.0048, -0.0199,  0.0006,  0.0168,  0.0034, -0.0012, -0.0046,  0.0108,<br>            -0.0039, -0.0243,  0.0268, -0.0117, -0.0271, -0.0337, -0.0243, -0.0285]],<br>          grad_fn=<AddmmBackward0>)</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>encoded <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span>batch<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> encoded<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>(torch.Size([64, 1, 28, 28]), torch.Size([64, 16]))</p></blockquote><h1 id="1-2-Decoder-model"><a href="#1-2-Decoder-model" class="headerlink" title="1.2 | Decoder model"></a><div style="padding: 20px;color:white;margin:10;font-size:50%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1.2 |</span></b> <b>Decoder model</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">conv_transpose_block</span><span class="token punctuation">(</span>    in_channels<span class="token punctuation">,</span>    out_channels<span class="token punctuation">,</span>    kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>    stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>    output_padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>    with_act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    modules <span class="token operator">=</span> <span class="token punctuation">[</span>        nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>            in_channels<span class="token punctuation">,</span>            out_channels<span class="token punctuation">,</span>            kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>            padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>            output_padding<span class="token operator">=</span>output_padding<span class="token punctuation">,</span>        <span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span>    <span class="token keyword">if</span> with_act<span class="token punctuation">:</span>        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>            <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv1 <span class="token operator">=</span> conv_transpose_block<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv2 <span class="token operator">=</span> conv_transpose_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span>                                            output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv3 <span class="token operator">=</span> conv_transpose_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span>                                            output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x     decoded_batch <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>encoded<span class="token punctuation">)</span>decoded_batch<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>torch.Size([64, 1, 28, 28])</p></blockquote><h1 id="1-3-AutoEncoder-training"><a href="#1-3-AutoEncoder-training" class="headerlink" title="1.3 | AutoEncoder training"></a><div style="padding: 20px;color:white;margin:10;font-size:50%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1.3 |</span></b> <b>AutoEncoder training</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> AutoEncoder<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchsummarytorchsummary<span class="token punctuation">.</span>summary<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>   -—————————————————————<br>           Layer (type)               Output Shape         Param #<br>   ================================================================<br>               Conv2d-1          [-1, 128, 14, 14]           2,176<br>          BatchNorm2d-2          [-1, 128, 14, 14]             256<br>                 ReLU-3          [-1, 128, 14, 14]               0<br>               Conv2d-4            [-1, 256, 7, 7]         524,544<br>          BatchNorm2d-5            [-1, 256, 7, 7]             512<br>                 ReLU-6            [-1, 256, 7, 7]               0<br>               Conv2d-7            [-1, 512, 3, 3]       2,097,664<br>          BatchNorm2d-8            [-1, 512, 3, 3]           1,024<br>                 ReLU-9            [-1, 512, 3, 3]               0<br>              Conv2d-10           [-1, 1024, 1, 1]       8,389,632<br>         BatchNorm2d-11           [-1, 1024, 1, 1]           2,048<br>                ReLU-12           [-1, 1024, 1, 1]               0<br>              Linear-13                   [-1, 16]          16,400<br>             Encoder-14                   [-1, 16]               0<br>              Linear-15                [-1, 16384]         278,528<br>     ConvTranspose2d-16            [-1, 512, 7, 7]       4,719,104<br>         BatchNorm2d-17            [-1, 512, 7, 7]           1,024<br>                ReLU-18            [-1, 512, 7, 7]               0<br>     ConvTranspose2d-19          [-1, 256, 14, 14]       1,179,904<br>         BatchNorm2d-20          [-1, 256, 14, 14]             512<br>                ReLU-21          [-1, 256, 14, 14]               0<br>     ConvTranspose2d-22            [-1, 1, 28, 28]           2,305<br>         BatchNorm2d-23            [-1, 1, 28, 28]               2<br>                ReLU-24            [-1, 1, 28, 28]               0<br>             Decoder-25            [-1, 1, 28, 28]               0<br>   ================================================================<br>   Total params: 17,215,635<br>   Trainable params: 17,215,635<br>   Non-trainable params: 0  </p><hr><p>   Input size (MB): 0.00<br>   Forward/backward pass size (MB): 2.86<br>   Params size (MB): 65.67<br>   Estimated Total Size (MB): 68.54  </p><hr></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt <span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F <span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>notebook <span class="token keyword">import</span> tqdm<span class="token punctuation">,</span> trange <span class="token keyword">from</span> genaibook<span class="token punctuation">.</span>core <span class="token keyword">import</span> get_device num_epochs <span class="token operator">=</span> <span class="token number">10</span>lr <span class="token operator">=</span> <span class="token number">1e-4</span>device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>     eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span>losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token punctuation">(</span>process <span class="token operator">:=</span> trange<span class="token punctuation">(</span>num_epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> _<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token punctuation">(</span>        inner <span class="token operator">:=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>                      total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token punctuation">:</span>        batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        preds <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>        inner<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>        losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    process<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>lr<span class="token punctuation">:</span><span class="token format-spec">.0e</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>  Training:   0%|          | 0/10 [00:00&lt;?, ?it/s]</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Step"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"AutoEncoder - Training Loss Curve"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdjTx"><img src="https://s21.ax1x.com/2024/12/12/pAbdjTx.png" alt="pAbdjTx.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">eval_bs <span class="token operator">=</span> <span class="token number">16</span>eval_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>eval_bs<span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 只需要获取数据集的第一个批次，而不是遍历整个数据集</span>    eval_batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>eval_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>    batch_vs_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>eval_batch<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span><span class="token punctuation">)</span>    show_images<span class="token punctuation">(</span>batch_vs_preds<span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdxk6"><img src="https://s21.ax1x.com/2024/12/12/pAbdxk6.png" alt="pAbdxk6.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x     <span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dims<span class="token punctuation">,</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            conv_transpose_block<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_transpose_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_transpose_block<span class="token punctuation">(</span>                <span class="token number">256</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> with_act<span class="token operator">=</span><span class="token boolean">False</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x <span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>                                  eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token punctuation">(</span>process <span class="token operator">:=</span> trange<span class="token punctuation">(</span>num_epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> _<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token punctuation">(</span>            inner <span class="token operator">:=</span> tqdm<span class="token punctuation">(</span>                <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token punctuation">:</span>            batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            preds <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>            inner<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>            losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        process<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>lr<span class="token punctuation">:</span><span class="token format-spec">.0e</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> losses     ae_model <span class="token operator">=</span> AutoEncoder<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> latent_dims<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>ae_model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>losses <span class="token operator">=</span> train<span class="token punctuation">(</span>ae_model<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Step"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Training Loss Curve (two latent dimensions)"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training:   0%|          | 0/10 [00:00&lt;?, ?it/s]</p></blockquote><p><img src="/blog_pics/VAE/VAE_22_11.png" alt="png">    </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ae_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    predicted <span class="token operator">=</span> ae_model<span class="token punctuation">(</span>eval_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>    batch_vs_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>eval_batch<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>batch_vs_preds<span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_23_0.png" alt="png"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images_labels_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>    <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>    <span class="token builtin">iter</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>     total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded <span class="token operator">=</span> ae_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>    new_items <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> encoded<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> encoded<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> batch<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>new_items<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    points <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span><span class="token string">"y"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>0%|          | 0/20 [00:00&lt;?, ?it/s]</p></blockquote><p><img src="/blog_pics/VAE/VAE_24_1.png" alt="png">    </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">N <span class="token operator">=</span> <span class="token number">16</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">8</span> <span class="token operator">-</span> <span class="token number">4</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    points <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span><span class="token string">"y"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"z"</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"s"</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"black"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_25_0.png" alt="png"> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ae_decoded <span class="token operator">=</span> ae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>ae_decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> suptitle<span class="token operator">=</span><span class="token string">"AutoEncoder"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_26_0.png" alt="png"> </p><h1 id="2-Variational-AutoEncoders"><a href="#2-Variational-AutoEncoders" class="headerlink" title="2 | Variational AutoEncoders"></a><div style="padding: 30px;color:white;margin:30;font-size:70%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>2 |</span></b> <b>Variational AutoEncoders</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">VAEEncoeder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mu <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>logvar <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        mu <span class="token operator">=</span> self<span class="token punctuation">.</span>mu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        logvar <span class="token operator">=</span> self<span class="token punctuation">.</span>logvar<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>mu<span class="token punctuation">,</span> logvar<span class="token punctuation">)</span>        <span class="token keyword">class</span> <span class="token class-name">VAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> VAEEncoeder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mu<span class="token punctuation">,</span> logvar <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        std <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">*</span> logvar<span class="token punctuation">)</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> std<span class="token punctuation">)</span>        reconstructed <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token keyword">return</span> reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar        <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> std<span class="token punctuation">)</span><span class="token punctuation">:</span>        eps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>std<span class="token punctuation">)</span>        <span class="token keyword">return</span> mu <span class="token operator">+</span> eps <span class="token operator">*</span> std     <span class="token keyword">def</span> <span class="token function">vae_loss</span><span class="token punctuation">(</span>batch<span class="token punctuation">,</span> reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar<span class="token punctuation">)</span><span class="token punctuation">:</span>    bs <span class="token operator">=</span> batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    reconstruction_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>        reconstructed<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        batch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        reduction<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        kl_loss <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>logvar<span class="token operator">-</span>mu<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">-</span>logvar<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>reconstruction_loss<span class="token operator">+</span>kl_loss<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>loss<span class="token punctuation">,</span> reconstruction_loss<span class="token punctuation">,</span> kl_loss<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">train_vae</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"loss"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"reconstruction_loss"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"kl_loss"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>        eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token punctuation">(</span>progress <span class="token operator">:=</span> trange<span class="token punctuation">(</span>num_epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> _<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token punctuation">(</span>            inner <span class="token operator">:=</span> tqdm<span class="token punctuation">(</span>                <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>                total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token punctuation">:</span>            batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>            loss<span class="token punctuation">,</span> reconstruction_loss<span class="token punctuation">,</span> kl_loss <span class="token operator">=</span> vae_loss<span class="token punctuation">(</span>                batch<span class="token punctuation">,</span> reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar            <span class="token punctuation">)</span>            inner<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>            losses<span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            losses<span class="token punctuation">[</span><span class="token string">"reconstruction_loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>                reconstruction_loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>            losses<span class="token punctuation">[</span><span class="token string">"kl_loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>kl_loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        process<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>lr<span class="token punctuation">:</span><span class="token format-spec">.0e</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> losses vae_model <span class="token operator">=</span> VAE<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> latent_dims<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>losses <span class="token operator">=</span> train_vae<span class="token punctuation">(</span>vae_model<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> losses<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>v<span class="token punctuation">,</span> label<span class="token operator">=</span>k<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training:   0%|          | 0/10 [00:00&lt;?, ?it/s]</p></blockquote><p><img src="/blog_pics/VAE/VAE_28_11.png" alt="png"> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">vae_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    predicted<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar <span class="token operator">=</span> <span class="token punctuation">(</span>v<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> \        vae_model<span class="token punctuation">(</span>eval_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>batch_vs_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>eval_batch<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>batch_vs_preds<span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_29_0.png" alt="png">   </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>    <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>    <span class="token builtin">iter</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    mu<span class="token punctuation">,</span> _ <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>    mu <span class="token operator">=</span> mu<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>    new_items <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> mu<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> mu<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> batch<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>new_items<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    points <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span><span class="token string">"y"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_30_1.png" alt="png">   </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">z <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ae_decoded <span class="token operator">=</span> ae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>vae_decoded <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>ae_decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>vae_decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_31_0.png" alt="png">       </p><p><img src="/blog_pics/VAE/VAE_31_1.png" alt="png">       </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> y <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>    z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    decoded <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_32_0.png" alt="png"> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> x <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> y <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>decoded <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_33_0.png" alt="png"> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;pre class=&quot;line-numbers language-python&quot; data-language=&quot;python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; pic</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="https://zhangchaofan01.gitee.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>GROMACS_complex_system</title>
    <link href="https://zhangchaofan01.gitee.io/2024/11/02/gromacs-complex-system/"/>
    <id>https://zhangchaofan01.gitee.io/2024/11/02/gromacs-complex-system/</id>
    <published>2024-11-02T02:02:56.000Z</published>
    <updated>2024-11-02T02:07:00.298Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在一般的分子动力学模拟体系中，都是在研究相互作用，比如蛋白-蛋白，蛋白-分子和蛋白-细胞膜等。所以我们会将不同的分子组合到一起。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># raw_data wget http:&#x2F;&#x2F;www.mdtutorials.com&#x2F;gmx&#x2F;biphasic&#x2F;Files&#x2F;chx.growget http:&#x2F;&#x2F;www.mdtutorials.com&#x2F;gmx&#x2F;biphasic&#x2F;Files&#x2F;chx.top# 512 (8^3) cyclohexane moleculesgmx genconf -f chx.gro -nbox 8 8 8 -o chx_box.gro# build box 同时指定chx_10ns的中心位置http:&#x2F;&#x2F;www.mdtutorials.com&#x2F;gmx&#x2F;biphasic&#x2F;Files&#x2F;chx_10ns.grogmx editconf -f chx_10ns.gro -o chx_newbox.gro -box 4.30795 4.30795 8.6159 -center 2.153975 2.153975 2.153975# add watergmx solvate -cp chx_newbox.gro -cs spc216.gro -p chx.top -o chx_solv.gro# 创建一样大小盒子，并将蛋白放置到指定位置wget https:&#x2F;&#x2F;files.rcsb.org&#x2F;view&#x2F;1AL1.pdb# pdb2grogmx editconf -f 1AL1.pdb -o 1AL1.grogmx editconf -f 1AL1.gro -o peptide_newbox.gro -box 4.30795 4.30795 8.6159 -center 2.153975 2.153975 6.461925# 将蛋白和环己烷分子层结合在一个box里gmx solvate -cp peptide_newbox.gro -cs chx_newbox.gro -o peptide_chx.gro# Expanding the Boxgmx genconf -f chx_10ns.gro -nbox 2 2 2 -o chx_bigbox.gro# an expanded layer can be created along the x-y plane with a slightly different commandgmx genconf -f chx_10ns.gro -nbox 2 2 1 -o chx_biglayer.gro<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pADL2ZV"><img src="https://s21.ax1x.com/2024/11/02/pADL2ZV.png" alt="pADL2ZV.png"></a><br><strong>Reference：</strong><br><a href="http://www.mdtutorials.com/gmx/biphasic/">http://www.mdtutorials.com/gmx/biphasic/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&amp;emsp;&amp;emsp;在一般的分子动力学模拟体系中，都是在研究相互作用，比如蛋白-蛋白，蛋白-分子和蛋白-细胞膜等。所以我们会将不同的分子组合到一起。&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-shell&quot; data-language=&quot;</summary>
      
    
    
    
    
    <category term="GROMACS" scheme="https://zhangchaofan01.gitee.io/tags/GROMACS/"/>
    
  </entry>
  
  <entry>
    <title>GROMACS_files</title>
    <link href="https://zhangchaofan01.gitee.io/2024/11/01/gromacs-files/"/>
    <id>https://zhangchaofan01.gitee.io/2024/11/01/gromacs-files/</id>
    <published>2024-11-01T13:35:40.000Z</published>
    <updated>2024-11-05T02:47:16.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-GROMACS-TOP文件"><a href="#1-GROMACS-TOP文件" class="headerlink" title="1.GROMACS TOP文件"></a>1.GROMACS <strong>TOP</strong>文件</h2><p><code>TOP</code>文件（也称为拓扑文件），用于定义分子系统的拓扑结构和力场参数。<code>TOP</code>文件包含了分子系统的原子类型、键合类型、非键合相互作用参数等信息，是进行分子动力学模拟的基础。<code>TOP</code>文件由多个部分组成，每个部分定义了不同的信息。<br>你可以发现文件头除了一些注释信息外，还有一行<code>#include &quot;gromos43a1.ff/forcefield.itp&quot;</code>,表明当前体系基于该力场。</p><h3 id="1-1-moleculetype"><a href="#1-1-moleculetype" class="headerlink" title="1.1 [ moleculetype ]"></a>1.1 <strong>[ moleculetype ]</strong></h3><p>定义分子类型及其名称，以及非键合相互作用的处理方式。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ moleculetype ]; Name            nrexclProtein_chain_A     3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>molname：分子类型的名称(这里的蛋白名称)。</li><li>nrexcl：决定了在计算非键合相互作用时，哪些原子对之间的相互作用会被忽略。<br>通常为 3，可以避免短程相互作用，减少计算量和避免重复计算。</li><li>qtot N端到当前pos肽段所带电荷<h3 id="1-2-atoms"><a href="#1-2-atoms" class="headerlink" title="1.2 [ atoms ]"></a>1.2 <strong>[ atoms ]</strong></h3>定义了分子系统中每个原子的详细信息, 如原子类型、电荷、质量等。</li></ul><p><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ atoms ];   nr       type  resnr residue  atom   cgnr     charge       mass  typeB    chargeB      massB; residue   4 CYS rtp NCYX q +1.0     1         N3      4    CYS      N      1     0.2069      14.01     2          H      4    CYS     H1      2     0.1815      1.008     3          H      4    CYS     H2      3     0.1815      1.008     4          H      4    CYS     H3      4     0.1815      1.008     5         CT      4    CYS     CA      5     0.1055      12.01     6         HP      4    CYS     HA      6     0.0922      1.008     7         CT      4    CYS     CB      7    -0.0277      12.01     8         H1      4    CYS    HB1      8      0.068      1.008     9         H1      4    CYS    HB2      9      0.068      1.008    10          S      4    CYS     SG     10    -0.0984      32.06    11          C      4    CYS      C     11     0.6123      12.01    12          O      4    CYS      O     12    -0.5713         16   ; qtot 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>nr: 原子编号</li><li>type: 原子类型</li><li>resnr: 残基编号</li><li>residue: 氨基酸残基名称</li><li>atom: 原子名称</li><li>cgnr: 电荷组编号</li><li>charge: 原子电荷</li><li>mass: 原子质量</li><li>typeB: 备用原子类型（通常用于双力场设置）</li><li>chargeB: 备用原子电荷（通常用于双力场设置）</li><li>massB: 备用原子质量（通常用于双力场设置）</li></ul><h3 id="1-3-bonds"><a href="#1-3-bonds" class="headerlink" title="1.3 [ bonds ]"></a>1.3 <strong>[ bonds ]</strong></h3><p>定义分子中的键及其参数，如键长、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ bonds ];  ai    aj funct            c0            c1            c2            c3    1     2     1     1     3     1     1     4     1     1     5     1     5     6     1     5     7     1     5    11     1     7     8     1     7     9     1     7    10     1    10   234     1 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai: 第一个原子的编号</li><li>aj: 第二个原子的编号</li><li>func: 键的函数类型，通常为 1（谐振势）或 2（Morse势）</li><li>c0: 键长（单位：nm）</li><li>c1: 力常数（单位：kJ/mol/nm²）</li><li>c2: 其它</li><li>c3: 其它</li></ul><h3 id="1-4-pairs"><a href="#1-4-pairs" class="headerlink" title="1.4 [ pairs ]"></a>1.4 <strong>[ pairs ]</strong></h3><p>定义分子中的键及其参数，如键长、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ pairs ];  ai    aj funct            c0            c1            c2            c3    1     8     1     1     9     1     1    10     1     1    12     1     1    13     1     2     6     1     2     7     1     2    11     1     3     6     1     3     7     1     3    11     1     4     6     1     4     7     1     4    11     1     5    14     1     5    15     1     5   234     1     6     8     1     6     9     1     6    10     1     6    12     1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai: 第一个原子编号 </li><li>aj: 第二个原子编号</li><li>func: 1（Lennard-Jones 12-6 势能）；2（Buckingham 势能）；3（Morse 势能）</li><li>c0: 其它（通常在 funct 为 1 时省略）</li><li>c1: 其它（通常在 funct 为 1 时省略）</li><li>c2: 其它（通常在 funct 为 1 时省略）</li><li>c3: 其它（通常在 funct 为 1 时省略）</li></ul><h3 id="1-5-angles"><a href="#1-5-angles" class="headerlink" title="1.5 [ angles ]"></a>1.5 <strong>[ angles ]</strong></h3><p>定义分子中的键角及其参数，如角度、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ angles ];  ai    aj    ak funct            c0            c1            c2            c3    2     1     3     1     2     1     4     1     2     1     5     1     3     1     4     1     3     1     5     1     4     1     5     1     1     5     6     1     1     5     7     1     1     5    11     1     6     5     7     1     6     5    11     1     7     5    11     1     5     7     8     1     5     7     9     1     5     7    10     1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai：第一个原子的编号，用于标识键角的起始原子</li><li>aj：中心原子的编号，用于标识键角的中心原子</li><li>ak：第三个原子的编号，用于标识键角的终止原子</li><li>funct：键角的函数类型，通常为 1（谐振势）</li><li>c0：键角（单位：度），通常在 funct 为 1 时省略</li><li>c1：力常数（单位：kJ/mol/rad²），通常在 funct 为 1 时省略</li><li>c2 和 c3：其他参数，通常在 funct 为 1 时省略</li></ul><h3 id="1-6-dihedrals"><a href="#1-6-dihedrals" class="headerlink" title="1.6 [ dihedrals ]"></a>1.6 <strong>[ dihedrals ]</strong></h3><p>定义分子中的二面角（扭转角）及其参数，如角度、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ dihedrals ];  ai    aj    ak    al funct            c0            c1            c2            c3            c4            c5    2     1     5     6     9     2     1     5     7     9     2     1     5    11     9     3     1     5     6     9     3     1     5     7     9     3     1     5    11     9     4     1     5     6     9     4     1     5     7     9     4     1     5    11     9     1     5     7     8     9     1     5     7     9     9     1     5     7    10     9 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai：第一个原子的编号，用于标识二面角的起始原子</li><li>aj：第二个原子的编号，用于标识二面角的第二个原子</li><li>ak：第三个原子的编号，用于标识二面角的第三个原子</li><li>al：第四个原子的编号，用于标识二面角的终止原子</li><li>funct：二面角的函数类型，通常为 1（周期性势能）或 3（Ryckaert-Bellemans 势能）,这里是周期性势能（Periodic potential）</li><li>c0、c1、c2、c3、c4 和 c5：其他参数，通常在 funct 为 1 或 3 时省略</li></ul><h3 id="1-7-system"><a href="#1-7-system" class="headerlink" title="1.7 [ system ]"></a>1.7 <strong>[ system ]</strong></h3><p>系统的名称。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ system ]; NameOMEGA-AGA-IVB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="1-8-molecules"><a href="#1-8-molecules" class="headerlink" title="1.8 [ molecules ]"></a>1.8 <strong>[ molecules ]</strong></h3><p>定义系统中包含的分子类型及其数量。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ molecules ]; Compound        #molsProtein_chain_A     1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>Compound：分子类型的名称</li><li>#mols：分子类型的数量</li></ul><h3 id="1-9-文件末尾的其它定义"><a href="#1-9-文件末尾的其它定义" class="headerlink" title="1.9 文件末尾的其它定义"></a>1.9 <strong>文件末尾的其它定义</strong></h3><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">## 定义了一个力常数，用来在平衡过程中使原子保持在原位; Include Position restraint file#ifdef POSRES#include &quot;posre.itp&quot;#endif## 溶剂 其它水：SPCE, TIP3P, and TIP4P; include water#include &quot;spc.itp&quot;## 离子参数; Include generic topology for ions#include &quot;oplsaa.ff&#x2F;ions.itp&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-GROMACS-GRO文件"><a href="#2-GROMACS-GRO文件" class="headerlink" title="2.GROMACS GRO文件"></a>2.GROMACS <strong>GRO</strong>文件</h2><p>gro格式的输出结构。结果是一个坐标文件，其中结构的每个原子都有x、y和z坐标，很像一个简单的PDB文件。</p><h2 id="3-GROMACS-ITP文件"><a href="#3-GROMACS-ITP文件" class="headerlink" title="3.GROMACS ITP文件"></a>3.GROMACS <strong>ITP</strong>文件</h2><p>一个位置约束文件，将在我们模拟的平衡步骤中有用。</p><h2 id="4-GROMACS-TPR文件"><a href="#4-GROMACS-TPR文件" class="headerlink" title="4.GROMACS TPR文件"></a>4.GROMACS <strong>TPR</strong>文件</h2><p><strong>References:</strong><br><a href="https://www.compchems.com/gromacs-file-formats-understanding-topology-itp-and-gro-files/#gro-file-format">https://www.compchems.com/gromacs-file-formats-understanding-topology-itp-and-gro-files/#gro-file-format</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-GROMACS-TOP文件&quot;&gt;&lt;a href=&quot;#1-GROMACS-TOP文件&quot; class=&quot;headerlink&quot; title=&quot;1.GROMACS TOP文件&quot;&gt;&lt;/a&gt;1.GROMACS &lt;strong&gt;TOP&lt;/strong&gt;文件&lt;/h2&gt;&lt;p&gt;&lt;</summary>
      
    
    
    
    
    <category term="GROMACS" scheme="https://zhangchaofan01.gitee.io/tags/GROMACS/"/>
    
  </entry>
  
  <entry>
    <title>Install_GROMACS_GPU</title>
    <link href="https://zhangchaofan01.gitee.io/2024/11/01/install-gromacs-gpu/"/>
    <id>https://zhangchaofan01.gitee.io/2024/11/01/install-gromacs-gpu/</id>
    <published>2024-11-01T01:06:10.000Z</published>
    <updated>2024-11-01T01:12:49.321Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GROMACS的安装"><a href="#GROMACS的安装" class="headerlink" title="GROMACS的安装"></a>GROMACS的安装</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n GROMACSconda activate GROMACSconda install cmake -yconda install gcc&#x3D;12 gxx&#x3D;12 -c conda-forge -y conda install -c conda-forge openmpi fftw# install GROMACSwget https:&#x2F;&#x2F;ftp.gromacs.org&#x2F;gromacs&#x2F;gromacs-2022.6.tar.gztar xfz gromacs-2022.6.tar.gzcd gromacs-2022.6mkdir buildcd buildcmake .. -DGMX_MPI&#x3D;OFF \-DGMX_GPU&#x3D;CUDA \-DCUDA_TOOLKIT_ROOT_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda \-DCUDA_INCLUDE_DIRS&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include \-DCUDA_CUDART_LIBRARY&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64 \-DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;GROMACS22 \-DCMAKE_C_COMPILER&#x3D;&#x2F;data&#x2F;chaofan&#x2F;miniconda3&#x2F;envs&#x2F;GROMACS&#x2F;bin&#x2F;gcc \-DCMAKE_CXX_COMPILER&#x3D;&#x2F;data&#x2F;chaofan&#x2F;miniconda3&#x2F;envs&#x2F;GROMACS&#x2F;bin&#x2F;g++make -j 40 make checkmake installsource &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;GROMACS&#x2F;bin&#x2F;GMXRC<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;GROMACS的安装&quot;&gt;&lt;a href=&quot;#GROMACS的安装&quot; class=&quot;headerlink&quot; title=&quot;GROMACS的安装&quot;&gt;&lt;/a&gt;GROMACS的安装&lt;/h2&gt;&lt;pre class=&quot;line-numbers language-shell&quot; </summary>
      
    
    
    
    
    <category term="GROMACS" scheme="https://zhangchaofan01.gitee.io/tags/GROMACS/"/>
    
  </entry>
  
  <entry>
    <title>GPT_fine_tuning</title>
    <link href="https://zhangchaofan01.gitee.io/2024/10/29/gpt-fine-tuning/"/>
    <id>https://zhangchaofan01.gitee.io/2024/10/29/gpt-fine-tuning/</id>
    <published>2024-10-29T06:09:32.000Z</published>
    <updated>2024-10-29T06:09:48.212Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Downloading-and-unzipping-the-dataset"><a href="#1-Downloading-and-unzipping-the-dataset" class="headerlink" title="1 | Downloading and unzipping the dataset"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>1 |</span></b> <b><span style='color:#95cf92'>Downloading and unzipping the dataset</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os <span class="token keyword">import</span> json <span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request<span class="token keyword">import</span> zipfile <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">url <span class="token operator">=</span> <span class="token string">"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip"</span>zip_path <span class="token operator">=</span> <span class="token string">"sms_spam_collection.zip"</span>extracted_path <span class="token operator">=</span> <span class="token string">"sms_spam_collection"</span> data_file_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>extracted_path<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"SMSSpamCollection.tsv"</span>data_file_path<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>WindowsPath(‘sms_spam_collection/SMSSpamCollection.tsv’)</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">download_and_unzip_spam_data</span><span class="token punctuation">(</span>    url<span class="token punctuation">,</span> zip_path<span class="token punctuation">,</span> extracted_path<span class="token punctuation">,</span> data_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> data_file_path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>data_file_path<span class="token punctuation">&#125;</span></span><span class="token string"> already exists. Skipping download "</span></span>            <span class="token string">"and extraction."</span><span class="token punctuation">)</span>        <span class="token keyword">return</span>    <span class="token keyword">with</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">as</span> response<span class="token punctuation">:</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>zip_path<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> out_file<span class="token punctuation">:</span>            out_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">with</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>zip_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> zip_ref<span class="token punctuation">:</span>        zip_ref<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span>extracted_path<span class="token punctuation">)</span>        original_file_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>extracted_path<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"SMSSpamCollection"</span>    os<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>original_file_path<span class="token punctuation">,</span> data_file_path<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"File download and saved as </span><span class="token interpolation"><span class="token punctuation">&#123;</span>data_file_path<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    download_and_unzip_spam_data<span class="token punctuation">(</span>url<span class="token punctuation">,</span> zip_path<span class="token punctuation">,</span> extracted_path<span class="token punctuation">,</span> data_file_path<span class="token punctuation">)</span>        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>sms_spam_collection\SMSSpamCollection.tsv already exists. Skipping download and extraction.</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>    data_file_path<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">,</span> <span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>df<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Label</th>      <th>Text</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>ham</td>      <td>Go until jurong point, crazy.. Available only ...</td>    </tr>    <tr>      <th>1</th>      <td>ham</td>      <td>Ok lar... Joking wif u oni...</td>    </tr>    <tr>      <th>2</th>      <td>spam</td>      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>    </tr>    <tr>      <th>3</th>      <td>ham</td>      <td>U dun say so early hor... U c already then say...</td>    </tr>    <tr>      <th>4</th>      <td>ham</td>      <td>Nah I don't think he goes to usf, he lives aro...</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>5567</th>      <td>spam</td>      <td>This is the 2nd time we have tried 2 contact u...</td>    </tr>    <tr>      <th>5568</th>      <td>ham</td>      <td>Will ü b going to esplanade fr home?</td>    </tr>    <tr>      <th>5569</th>      <td>ham</td>      <td>Pity, * was in mood for that. So...any other s...</td>    </tr>    <tr>      <th>5570</th>      <td>ham</td>      <td>The guy did some bitching but I acted like i'd...</td>    </tr>    <tr>      <th>5571</th>      <td>ham</td>      <td>Rofl. Its true to its name</td>    </tr>  </tbody></table><p>5572 rows × 2 columns</p></div><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>Label<br>ham     4825<br>spam     747<br>Name: count, dtype: int64</p></blockquote><h1 id="2-Creating-a-balanced-dataset"><a href="#2-Creating-a-balanced-dataset" class="headerlink" title="2 | Creating a balanced dataset"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>2 |</span></b> <b><span style='color:#95cf92'>Creating a balanced dataset</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_balanced_dataset</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>    num_spam <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"spam"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    ham_subset <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"ham"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span>        num_spam<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">123</span>    <span class="token punctuation">)</span>    balanced_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>ham_subset<span class="token punctuation">,</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"spam"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> balanced_dfbalanced_df <span class="token operator">=</span> create_balanced_dataset<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>balanced_df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Label<br>ham     747<br>spam    747<br>Name: count, dtype: int64  </p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">balanced_df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">=</span> balanced_df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"ham"</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"spam"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">random_split</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> train_frac<span class="token punctuation">,</span> validation_frac<span class="token punctuation">)</span><span class="token punctuation">:</span>    df <span class="token operator">=</span> df<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">123</span>        <span class="token punctuation">)</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    train_end <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">*</span> train_frac<span class="token punctuation">)</span>    validation_end <span class="token operator">=</span> train_end <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">*</span> validation_frac<span class="token punctuation">)</span>    train_df <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">:</span>train_end<span class="token punctuation">]</span>    validation_df <span class="token operator">=</span> df<span class="token punctuation">[</span>train_end<span class="token punctuation">:</span>validation_end<span class="token punctuation">]</span>    test_df <span class="token operator">=</span> df<span class="token punctuation">[</span>validation_end<span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> train_df<span class="token punctuation">,</span> validation_df<span class="token punctuation">,</span> test_dftrain_df<span class="token punctuation">,</span> validation_df<span class="token punctuation">,</span> test_df <span class="token operator">=</span> random_split<span class="token punctuation">(</span>    balanced_df<span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"train.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>validation_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"validation.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>test_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"test.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tiktokentokenizer <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"&lt;|endoftext|>"</span><span class="token punctuation">,</span> allowed_special<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">"&lt;|endoftext|>"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>[50256]</p></blockquote><h1 id="3-Setting-up-a-Pytorch-Dataset-class"><a href="#3-Setting-up-a-Pytorch-Dataset-class" class="headerlink" title="3 | Setting up a Pytorch Dataset class"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>3 |</span></b> <b><span style='color:#95cf92'>Setting up a Pytorch Dataset class</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">class</span> <span class="token class-name">SpamDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> csv_file<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                pad_token_id<span class="token operator">=</span><span class="token number">50256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoded_texts <span class="token operator">=</span> <span class="token punctuation">[</span>            tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span>        <span class="token punctuation">]</span>        <span class="token keyword">if</span> max_length <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> self<span class="token punctuation">.</span>_longest_encoded_length<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> max_length            self<span class="token punctuation">.</span>encoded_texts <span class="token operator">=</span> <span class="token punctuation">[</span>                encoded_text<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>max_length<span class="token punctuation">]</span>                <span class="token keyword">for</span> encoded_text <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoded_texts            <span class="token punctuation">]</span>        self<span class="token punctuation">.</span>encoded_texts <span class="token operator">=</span> <span class="token punctuation">[</span>            encoded_text <span class="token operator">+</span> <span class="token punctuation">[</span>pad_token_id<span class="token punctuation">]</span> <span class="token operator">*</span>             <span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_length <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>encoded_text<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> encoded_text <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoded_texts        <span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        encoded <span class="token operator">=</span> self<span class="token punctuation">.</span>encoded_texts<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        label <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>encoded<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">_longest_encoded_length</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        max_length <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> encoded_text <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoded_texts<span class="token punctuation">:</span>            encoded_length <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>encoded_text<span class="token punctuation">)</span>            <span class="token keyword">if</span> encoded_length <span class="token operator">></span> max_length<span class="token punctuation">:</span>                max_length <span class="token operator">=</span> encoded_length        <span class="token keyword">return</span> max_length    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_dataset <span class="token operator">=</span> SpamDataset<span class="token punctuation">(</span>    csv_file<span class="token operator">=</span><span class="token string">"train.csv"</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>120</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">val_dataset <span class="token operator">=</span> SpamDataset<span class="token punctuation">(</span>    csv_file<span class="token operator">=</span><span class="token string">"validation.csv"</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> SpamDataset<span class="token punctuation">(</span>    csv_file<span class="token operator">=</span><span class="token string">"test.csv"</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-Creating-PyTorch-data-loaders"><a href="#4-Creating-PyTorch-data-loaders" class="headerlink" title="4 | Creating PyTorch data loaders"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>4 |</span></b> <b><span style='color:#95cf92'>Creating PyTorch data loaders</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoadernum_workers <span class="token operator">=</span> <span class="token number">0</span>batch_size <span class="token operator">=</span> <span class="token number">8</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>val_dataset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">False</span> <span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span>     batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="5-Initializing-a-model-with-pretrained-weights"><a href="#5-Initializing-a-model-with-pretrained-weights" class="headerlink" title="5 | Initializing a model with pretrained weights"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>5 |</span></b> <b><span style='color:#95cf92'>Initializing a model with pretrained weights</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">CHOOSE_MODEL <span class="token operator">=</span> <span class="token string">"gpt2-small (124M)"</span>INPUT_PROMPT <span class="token operator">=</span> <span class="token string">"Every effort moves"</span>BASE_CONFIG <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"vocab_size"</span><span class="token punctuation">:</span> <span class="token number">50257</span><span class="token punctuation">,</span>    <span class="token string">"context_length"</span><span class="token punctuation">:</span> <span class="token number">1024</span><span class="token punctuation">,</span>    <span class="token string">"drop_rate"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>    <span class="token string">"qkv_bias"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span>model_configs <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"gpt2-small (124M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"gpt2-medium (355M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"gpt2-large (774M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">1280</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"gpt2-xl (1558M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">1600</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span>BASE_CONFIG<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_configs<span class="token punctuation">[</span>CHOOSE_MODEL<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="6-Loading-pretrained-GPT-model"><a href="#6-Loading-pretrained-GPT-model" class="headerlink" title="6 | Loading pretrained GPT model"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>6 |</span></b> <b><span style='color:#95cf92'>Loading pretrained GPT model</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LayerNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> <span class="token number">1e-5</span>        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shift <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        var <span class="token operator">=</span> x<span class="token punctuation">.</span>var<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>scale <span class="token operator">*</span> norm_x <span class="token operator">+</span> self<span class="token punctuation">.</span>shift <span class="token keyword">class</span> <span class="token class-name">GELU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> x <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>pi<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span>            <span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token number">0.44715</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">FeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span>        context_length<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token punctuation">(</span>d_out <span class="token operator">%</span> num_heads <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \            <span class="token string">'d_out must divisible by num_heads'</span>        self<span class="token punctuation">.</span>d_out <span class="token operator">=</span> d_out        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        self<span class="token punctuation">.</span>head_dim <span class="token operator">=</span> d_out <span class="token operator">//</span> num_heads        self<span class="token punctuation">.</span>W_query <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_out<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span>            <span class="token string">"mask"</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>context_length<span class="token punctuation">,</span> context_length<span class="token punctuation">)</span><span class="token punctuation">,</span>                diagonal<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> d_in <span class="token operator">=</span> x<span class="token punctuation">.</span>shape         queries <span class="token operator">=</span> self<span class="token punctuation">.</span>W_query<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        keys <span class="token operator">=</span> self<span class="token punctuation">.</span>W_key<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        values <span class="token operator">=</span> self<span class="token punctuation">.</span>W_value<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        attn_scores <span class="token operator">=</span> queries @ keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        mask_bool <span class="token operator">=</span> self<span class="token punctuation">.</span>mask<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>num_tokens<span class="token punctuation">,</span> <span class="token punctuation">:</span>num_tokens<span class="token punctuation">]</span>        attn_scores<span class="token punctuation">.</span>masked_fill_<span class="token punctuation">(</span>mask_bool<span class="token punctuation">,</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>inf<span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>            attn_scores <span class="token operator">/</span> keys<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attn_weights<span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> <span class="token punctuation">(</span>attn_weights @ values<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> context_vec<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>            b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_out<span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>out_proj<span class="token punctuation">(</span>context_vec<span class="token punctuation">)</span>        <span class="token keyword">return</span> context_vec<span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>att <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>            d_in<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            d_out<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            context_length<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            num_heads<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"n_heads"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            dropout<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            qkv_bias<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"qkv_bias"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ff <span class="token operator">=</span> FeedForward<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        shortcut <span class="token operator">=</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>att<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut        shortcut <span class="token operator">=</span> x         x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ff<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">GPTModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>tok_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>trf_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span><span class="token punctuation">[</span>TransformerBlock<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"n_layers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>final_norm <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>            cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch_size<span class="token punctuation">,</span> seq_len <span class="token operator">=</span> in_idx<span class="token punctuation">.</span>shape        tok_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>tok_emb<span class="token punctuation">(</span>in_idx<span class="token punctuation">)</span>        pos_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_emb<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> device<span class="token operator">=</span>in_idx<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tok_embeds <span class="token operator">+</span> pos_embeds        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_emb<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>final_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>out_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py#L17-L44</span><span class="token keyword">def</span> <span class="token function">download_and_load_gpt2</span><span class="token punctuation">(</span>model_size<span class="token punctuation">,</span> models_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># Validate model size</span>    allowed_sizes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"124M"</span><span class="token punctuation">,</span> <span class="token string">"355M"</span><span class="token punctuation">,</span> <span class="token string">"774M"</span><span class="token punctuation">,</span> <span class="token string">"1558M"</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> model_size <span class="token keyword">not</span> <span class="token keyword">in</span> allowed_sizes<span class="token punctuation">:</span>        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Model size not in </span><span class="token interpolation"><span class="token punctuation">&#123;</span>allowed_sizes<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token comment"># Define paths</span>    model_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>models_dir<span class="token punctuation">,</span> model_size<span class="token punctuation">)</span>    base_url <span class="token operator">=</span> <span class="token string">"https://openaipublic.blob.core.windows.net/gpt-2/models"</span>    filenames <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token string">"checkpoint"</span><span class="token punctuation">,</span> <span class="token string">"encoder.json"</span><span class="token punctuation">,</span> <span class="token string">"hparams.json"</span><span class="token punctuation">,</span>        <span class="token string">"model.ckpt.data-00000-of-00001"</span><span class="token punctuation">,</span> <span class="token string">"model.ckpt.index"</span><span class="token punctuation">,</span>        <span class="token string">"model.ckpt.meta"</span><span class="token punctuation">,</span> <span class="token string">"vocab.bpe"</span>    <span class="token punctuation">]</span>    <span class="token comment"># Download files</span>    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> filename <span class="token keyword">in</span> filenames<span class="token punctuation">:</span>        file_url <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_url<span class="token punctuation">,</span> model_size<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>        file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>        download_file<span class="token punctuation">(</span>file_url<span class="token punctuation">,</span> file_path<span class="token punctuation">)</span>    <span class="token comment"># Load settings and params</span>    tf_ckpt_path <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>latest_checkpoint<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>    settings <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> <span class="token string">"hparams.json"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    params <span class="token operator">=</span> load_gpt2_params_from_tf_ckpt<span class="token punctuation">(</span>tf_ckpt_path<span class="token punctuation">,</span> settings<span class="token punctuation">)</span>    <span class="token keyword">return</span> settings<span class="token punctuation">,</span> params<span class="token comment"># https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py#L47-L82</span><span class="token keyword">def</span> <span class="token function">download_file</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> destination<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># Send a GET request to download the file</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">as</span> response<span class="token punctuation">:</span>            <span class="token comment"># Get the total file size from headers, defaulting to 0 if not present</span>            file_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>headers<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"Content-Length"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># Check if file exists and has the same size</span>            <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>destination<span class="token punctuation">)</span><span class="token punctuation">:</span>                file_size_local <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>getsize<span class="token punctuation">(</span>destination<span class="token punctuation">)</span>                <span class="token keyword">if</span> file_size <span class="token operator">==</span> file_size_local<span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"File already exists and is up-to-date: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>destination<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>                    <span class="token keyword">return</span>            <span class="token comment"># Define the block size for reading the file</span>            block_size <span class="token operator">=</span> <span class="token number">1024</span>  <span class="token comment"># 1 Kilobyte</span>            <span class="token comment"># Initialize the progress bar with total file size</span>            progress_bar_description <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>url<span class="token punctuation">)</span>  <span class="token comment"># Extract filename from URL</span>            <span class="token keyword">with</span> tqdm<span class="token punctuation">(</span>total<span class="token operator">=</span>file_size<span class="token punctuation">,</span> unit<span class="token operator">=</span><span class="token string">"iB"</span><span class="token punctuation">,</span> unit_scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> desc<span class="token operator">=</span>progress_bar_description<span class="token punctuation">)</span> <span class="token keyword">as</span> progress_bar<span class="token punctuation">:</span>                <span class="token comment"># Open the destination file in binary write mode</span>                <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>destination<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>                    <span class="token comment"># Read the file in chunks and write to destination</span>                    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                        chunk <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span>block_size<span class="token punctuation">)</span>                        <span class="token keyword">if</span> <span class="token keyword">not</span> chunk<span class="token punctuation">:</span>                            <span class="token keyword">break</span>                        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>                        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Update progress bar</span>    <span class="token keyword">except</span> urllib<span class="token punctuation">.</span>error<span class="token punctuation">.</span>HTTPError<span class="token punctuation">:</span>        s <span class="token operator">=</span> <span class="token punctuation">(</span>            <span class="token string-interpolation"><span class="token string">f"The specified URL (</span><span class="token interpolation"><span class="token punctuation">&#123;</span>url<span class="token punctuation">&#125;</span></span><span class="token string">) is incorrect, the internet connection cannot be established,"</span></span>            <span class="token string">"\nor the requested file is temporarily unavailable.\nPlease visit the following website"</span>            <span class="token string">" for help: https://github.com/rasbt/LLMs-from-scratch/discussions/273"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token comment"># https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py#L116-L142</span><span class="token keyword">def</span> <span class="token function">load_gpt2_params_from_tf_ckpt</span><span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> settings<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># Initialize parameters dictionary with empty blocks for each layer</span>    params <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"blocks"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>settings<span class="token punctuation">[</span><span class="token string">"n_layer"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span>    <span class="token comment"># Iterate over each variable in the checkpoint</span>    <span class="token keyword">for</span> name<span class="token punctuation">,</span> _ <span class="token keyword">in</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>list_variables<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Load the variable and remove singleton dimensions</span>        variable_array <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>load_variable<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># Process the variable name to extract relevant parts</span>        variable_name_parts <span class="token operator">=</span> name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># Skip the 'model/' prefix</span>        <span class="token comment"># Identify the target dictionary for the variable</span>        target_dict <span class="token operator">=</span> params        <span class="token keyword">if</span> variable_name_parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            layer_number <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>variable_name_parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            target_dict <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>layer_number<span class="token punctuation">]</span>        <span class="token comment"># Recursively access or create nested dictionaries</span>        <span class="token keyword">for</span> key <span class="token keyword">in</span> variable_name_parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            target_dict <span class="token operator">=</span> target_dict<span class="token punctuation">.</span>setdefault<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        <span class="token comment"># Assign the variable array to the last key</span>        last_key <span class="token operator">=</span> variable_name_parts<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        target_dict<span class="token punctuation">[</span>last_key<span class="token punctuation">]</span> <span class="token operator">=</span> variable_array    <span class="token keyword">return</span> params<span class="token keyword">def</span> <span class="token function">assign</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span> right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> left<span class="token punctuation">.</span>shape <span class="token operator">!=</span> right<span class="token punctuation">.</span>shape<span class="token punctuation">:</span>        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Shape mismatch. left: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>left<span class="token punctuation">.</span>shape<span class="token punctuation">&#125;</span></span><span class="token string">, "</span></span>                        <span class="token string">"Right: &#123;right.shape&#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>right<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">load_weights_into_gpt</span><span class="token punctuation">(</span>gpt<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>    gpt<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'wpe'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>tok_emb<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>tok_emb<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'wte'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        q_w<span class="token punctuation">,</span> k_w<span class="token punctuation">,</span> v_w <span class="token operator">=</span> np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>        <span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_attn"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> q_w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> k_w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> v_w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>        q_b<span class="token punctuation">,</span> k_b<span class="token punctuation">,</span> v_b <span class="token operator">=</span> np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>        <span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_attn"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> q_b<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> k_b<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> v_b<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>bias<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_fc"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_fc"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>scale <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>scale<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_1"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"g"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>shift <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>shift<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_1"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>scale <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>scale<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_2"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"g"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>shift <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>shift<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_2"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>scale <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>scale<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">"g"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>shift <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>shift<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>out_head<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>out_head<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">"wte"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">generate_text_simple</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> idx<span class="token punctuation">,</span>    max_new_tokens<span class="token punctuation">,</span> context_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_new_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>        idx_cond <span class="token operator">=</span> idx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>context_size<span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            logits <span class="token operator">=</span> model<span class="token punctuation">(</span>idx_cond<span class="token punctuation">)</span>        logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>        probas <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        idx_next <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>probas<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> idx_next<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> idx <span class="token keyword">def</span> <span class="token function">text_to_token_ids</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> allowed_special<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'&lt;|endoftext|>'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>    encoded_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>encoded<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> encoded_tensor<span class="token keyword">def</span> <span class="token function">token_ids_to_text</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    flat <span class="token operator">=</span> token_ids<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>flat<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model_size <span class="token operator">=</span> CHOOSE_MODEL<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">"("</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">")"</span><span class="token punctuation">)</span>settings<span class="token punctuation">,</span> params <span class="token operator">=</span> download_and_load_gpt2<span class="token punctuation">(</span>    model_size<span class="token operator">=</span>model_size<span class="token punctuation">,</span> models_dir<span class="token operator">=</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span>model <span class="token operator">=</span> GPTModel<span class="token punctuation">(</span>BASE_CONFIG<span class="token punctuation">)</span>load_weights_into_gpt<span class="token punctuation">(</span>model<span class="token punctuation">,</span> params<span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>File already exists and is up-to-date: gpt2\124M\checkpoint<br>    File already exists and is up-to-date: gpt2\124M\encoder.json<br>    File already exists and is up-to-date: gpt2\124M\hparams.json<br>    File already exists and is up-to-date: gpt2\124M\model.ckpt.data-00000-of-00001<br>    File already exists and is up-to-date: gpt2\124M\model.ckpt.index<br>    File already exists and is up-to-date: gpt2\124M\model.ckpt.meta<br>    File already exists and is up-to-date: gpt2\124M\vocab.bpe  </p></blockquote><pre class="line-numbers language-text" data-language="text"><code class="language-text">GPTModel(  (tok_emb): Embedding(50257, 768)  (pos_emb): Embedding(1024, 768)  (drop_emb): Dropout(p=0.0, inplace=False)  (trf_blocks): Sequential(    (0): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (1): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (2): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (3): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (4): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (5): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (6): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (7): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (8): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (9): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (10): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (11): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )  )  (final_norm): LayerNorm()  (out_head): Linear(in_features=768, out_features=50257, bias=False))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">text_1 <span class="token operator">=</span> <span class="token string">"Every effort moves you"</span>token_ids <span class="token operator">=</span> generate_text_simple<span class="token punctuation">(</span>    model<span class="token operator">=</span>model<span class="token punctuation">,</span>    idx <span class="token operator">=</span> text_to_token_ids<span class="token punctuation">(</span>text_1<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>    max_new_tokens<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span>    context_size <span class="token operator">=</span> BASE_CONFIG<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>token_ids_to_text<span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Every effort moves you to the point of the &quot;I-don-it-from-the</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">text_2 <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token string">"Is the following text 'spam'? Answer the 'yes' or 'no':"</span>    <span class="token string">" 'You are a winner you have been specially"</span>    <span class="token string">" selected to receive $1000 cash or a $2000 award."</span><span class="token punctuation">)</span>token_ids <span class="token operator">=</span> generate_text_simple<span class="token punctuation">(</span>    model<span class="token operator">=</span>model<span class="token punctuation">,</span>    idx<span class="token operator">=</span>text_to_token_ids<span class="token punctuation">(</span>text_2<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>    max_new_tokens<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">,</span>    context_size<span class="token operator">=</span>BASE_CONFIG<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>token_ids_to_text<span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Is the following text ‘spam’? Answer the ‘yes’ or ‘no’: ‘You are a winner you have   been specially selected to receive $1000 cash or a $2000 award.’’’’’’’</p></blockquote><h1 id="7-Adding-a-classification-head"><a href="#7-Adding-a-classification-head" class="headerlink" title="7 | Adding a classification head"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>7 |</span></b> <b><span style='color:#95cf92'>Adding a classification head</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>required_grad <span class="token operator">=</span> <span class="token boolean">False</span>     torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>num_classes <span class="token operator">=</span> <span class="token number">2</span> model<span class="token punctuation">.</span>out_head <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>    in_features<span class="token operator">=</span>BASE_CONFIG<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    out_features<span class="token operator">=</span>num_classes<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>required_grad <span class="token operator">=</span> <span class="token boolean">True</span>     <span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>required_grad <span class="token operator">=</span> <span class="token boolean">True</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="8-Calculating-the-classification-accuracy"><a href="#8-Calculating-the-classification-accuracy" class="headerlink" title="8 | Calculating the classification accuracy"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>8 |</span></b> <b><span style='color:#95cf92'>Calculating the classification accuracy</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_accuracy_loader</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    correct_predictions<span class="token punctuation">,</span> num_examples <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>         <span class="token keyword">if</span> num_batches <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> num_batches<span class="token punctuation">:</span>            input_batch <span class="token operator">=</span> input_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            target_batch <span class="token operator">=</span> target_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>            predicted_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            num_examples <span class="token operator">+=</span> predicted_labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            correct_predictions <span class="token operator">+=</span> <span class="token punctuation">(</span>                <span class="token punctuation">(</span>predicted_labels <span class="token operator">==</span> target_batch<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> correct_predictions <span class="token operator">/</span> num_examples            <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>train_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>val_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>test_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training accuracy: 45.31%<br>    Validation accuracy: 45.31%<br>    Test accuracy: 53.12% </p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_loss_batch</span><span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_batch <span class="token operator">=</span> input_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    target_batch <span class="token operator">=</span> target_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token keyword">def</span> <span class="token function">calc_loss_loader</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>     <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">"nan"</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> num_batches <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> num_batches<span class="token punctuation">:</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device            <span class="token punctuation">)</span>            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> num_batches    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>        train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">5</span>    <span class="token punctuation">)</span>    val_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    test_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training loss: 2.991<br>    Validation loss: 2.955<br>    Test loss: 2.877 </p></blockquote><h1 id="9-Fine-tuning-the-model-to-classify-spam"><a href="#9-Fine-tuning-the-model-to-classify-spam" class="headerlink" title="9 | Fine-tuning the model to classify spam"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>9 |</span></b> <b><span style='color:#95cf92'>Fine-tuning the model to classify spam</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_classifier_simple</span><span class="token punctuation">(</span>    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span>    num_epochs<span class="token punctuation">,</span> eval_freq<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    examples_seen<span class="token punctuation">,</span> global_step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span>     <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> input_batch<span class="token punctuation">,</span> target_batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device            <span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            examples_seen <span class="token operator">+=</span> input_batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            global_step <span class="token operator">+=</span> <span class="token number">1</span>                        <span class="token keyword">if</span> global_step <span class="token operator">%</span> eval_freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                train_loss<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>                    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span>                train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>                val_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ep </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string"> (step </span><span class="token interpolation"><span class="token punctuation">&#123;</span>global_step<span class="token punctuation">:</span><span class="token format-spec">06d</span><span class="token punctuation">&#125;</span></span><span class="token string">) :"</span></span>                    <span class="token string-interpolation"><span class="token string">f"Train loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">, "</span></span>                    <span class="token string-interpolation"><span class="token string">f"Val loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>        train_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>            train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>        val_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>            val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">% | "</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span>        train_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_accuracy<span class="token punctuation">)</span>        val_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_accuracy<span class="token punctuation">)</span>    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs<span class="token punctuation">,</span> examples_seen<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>        val_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> train_loss<span class="token punctuation">,</span> val_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">%</span><span class="token operator">%</span>time<span class="token keyword">import</span> time start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">5e-5</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>num_epochs <span class="token operator">=</span> <span class="token number">5</span>train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs<span class="token punctuation">,</span> examples_seen <span class="token operator">=</span> \    train_classifier_simple<span class="token punctuation">(</span>        model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span>        num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_freq<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>        eval_iter<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>execution_time_minutes <span class="token operator">=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training completed in </span><span class="token interpolation"><span class="token punctuation">&#123;</span>execution_time_minutes<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string"> minutes."</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Ep 1 (step 000000) :Train loss 0.850, Val loss 0.963<br>    Ep 1 (step 000050) :Train loss 0.390, Val loss 0.375<br>    Ep 1 (step 000100) :Train loss 0.167, Val loss 0.609<br>    Training accuracy: 95.00% | Validation accuracy: 95.00%<br>    Ep 2 (step 000150) :Train loss 0.136, Val loss 0.135<br>    Ep 2 (step 000200) :Train loss 0.032, Val loss 0.047<br>    Ep 2 (step 000250) :Train loss 0.018, Val loss 0.081<br>    Training accuracy: 100.00% | Validation accuracy: 92.50%<br>    Ep 3 (step 000300) :Train loss 0.117, Val loss 0.030<br>    Ep 3 (step 000350) :Train loss 0.013, Val loss 0.102<br>    Training accuracy: 100.00% | Validation accuracy: 97.50%<br>    Ep 4 (step 000400) :Train loss 0.019, Val loss 0.023<br>    Ep 4 (step 000450) :Train loss 0.023, Val loss 0.173<br>    Ep 4 (step 000500) :Train loss 0.108, Val loss 0.104<br>    Training accuracy: 100.00% | Validation accuracy: 95.00%<br>    Ep 5 (step 000550) :Train loss 0.075, Val loss 0.009<br>    Ep 5 (step 000600) :Train loss 0.001, Val loss 0.007<br>    Training accuracy: 97.50% | Validation accuracy: 97.50%<br>    Training completed in 14.45 minutes.<br>    CPU times: total: 6min 58s<br>    Wall time: 14min 26s  </p></blockquote><h1 id="10-Plotting-the-classification-loss"><a href="#10-Plotting-the-classification-loss" class="headerlink" title="10 | Plotting the classification loss"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>10 |</span></b> <b><span style='color:#95cf92'>Plotting the classification loss</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">def</span> <span class="token function">plot_values</span><span class="token punctuation">(</span>    epochs_seen<span class="token punctuation">,</span> examples_seen<span class="token punctuation">,</span> train_values<span class="token punctuation">,</span> val_values<span class="token punctuation">,</span>    label<span class="token operator">=</span><span class="token string">"loss"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    fig<span class="token punctuation">,</span> axl <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_seen<span class="token punctuation">,</span> train_values<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"Training </span><span class="token interpolation"><span class="token punctuation">&#123;</span>label<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>        epochs_seen<span class="token punctuation">,</span> val_values<span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">"-."</span><span class="token punctuation">,</span>        label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"Validation </span><span class="token interpolation"><span class="token punctuation">&#123;</span>label<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>    <span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"Epochs"</span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>label<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>        ax2 <span class="token operator">=</span> axl<span class="token punctuation">.</span>twiny<span class="token punctuation">(</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>examples_seen<span class="token punctuation">,</span> train_values<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"Examples seen"</span><span class="token punctuation">)</span>        fig<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>label<span class="token punctuation">&#125;</span></span><span class="token string">-plot.pdf"</span></span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 假设你已经定义了 num_epochs, examples_seen, train_losses, val_losses</span>epochs_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_losses<span class="token punctuation">)</span><span class="token punctuation">)</span>examples_seen_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> examples_seen<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_losses<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 调用 plot_values 函数</span>plot_values<span class="token punctuation">(</span>epochs_tensor<span class="token punctuation">,</span> examples_seen_tensor<span class="token punctuation">,</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pA0qutJ"><img src="https://s21.ax1x.com/2024/10/29/pA0qutJ.png" alt="pA0qutJ.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">epochs_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_accs<span class="token punctuation">)</span><span class="token punctuation">)</span>examples_seen_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> examples_seen<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_accs<span class="token punctuation">)</span><span class="token punctuation">)</span>plot_values<span class="token punctuation">(</span>    epochs_tensor<span class="token punctuation">,</span> examples_seen_tensor<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs<span class="token punctuation">,</span>    label<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pA0qKh9"><img src="https://s21.ax1x.com/2024/10/29/pA0qKh9.png" alt="pA0qKh9.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>val_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>test_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training accuracy: 98.27%<br>    Validation accuracy: 97.32%<br>    Test accuracy: 94.67%</p></blockquote><h1 id="11-Using-the-model-to-classify-new-texts"><a href="#11-Using-the-model-to-classify-new-texts" class="headerlink" title="11 | Using the model to classify new texts"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>11 |</span></b> <b><span style='color:#95cf92'>Using the model to classify new texts</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">classify_review</span><span class="token punctuation">(</span>    text<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    pad_token_id<span class="token operator">=</span><span class="token number">50256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        input_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    supprted_context_length <span class="token operator">=</span> model<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        input_ids <span class="token operator">=</span> input_ids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">min</span><span class="token punctuation">(</span>        max_length<span class="token punctuation">,</span> supprted_context_length    <span class="token punctuation">)</span><span class="token punctuation">]</span>        input_ids <span class="token operator">+=</span> <span class="token punctuation">[</span>pad_token_id<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>max_length <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">)</span>    input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>        input_ids<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    predicted_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">"spam"</span> <span class="token keyword">if</span> predicted_label <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">"not spam"</span>text_1 <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token string">"You are a winner you have been specially"</span>    <span class="token string">" selected to receive $1000 cash or $200 award."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>classify_review<span class="token punctuation">(</span>    text_1<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> max_length<span class="token operator">=</span>train_dataset<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>spam</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">text_2 <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"Hey, just wanted to check if we're still on"</span><span class="token string">" for dinner tonight? Let me know!"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>classify_review<span class="token punctuation">(</span>text_2<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> max_length<span class="token operator">=</span>train_dataset<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>not spam</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"review_classifier.pth"</span><span class="token punctuation">)</span>model_state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"review_classifier.pth"</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_state_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>&lt;All keys matched successfully&gt;</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Downloading-and-unzipping-the-dataset&quot;&gt;&lt;a href=&quot;#1-Downloading-and-unzipping-the-dataset&quot; class=&quot;headerlink&quot; title=&quot;1 | Downloadin</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="https://zhangchaofan01.gitee.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>GPT_model</title>
    <link href="https://zhangchaofan01.gitee.io/2024/10/23/gpt-model/"/>
    <id>https://zhangchaofan01.gitee.io/2024/10/23/gpt-model/</id>
    <published>2024-10-23T13:42:25.000Z</published>
    <updated>2025-05-18T10:37:45.681Z</updated>
    
    <content type="html"><![CDATA[<p><strong>GPT架构总览</strong>如下图所示，我们这里简单创建了一个GPT模型，它是ChatGPT的基础架构。</p><p><a href="https://imgse.com/i/pAdEp40"><img src="https://s21.ax1x.com/2024/10/22/pAdEp40.png" alt="pAdEp40.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tiktoken<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MultiHeadAttention"><a href="#MultiHeadAttention" class="headerlink" title="MultiHeadAttention"></a>MultiHeadAttention</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span>        context_length<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token punctuation">(</span>d_out <span class="token operator">%</span> num_heads <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \            <span class="token string">"d_out must divisible by num_heads"</span>        self<span class="token punctuation">.</span>d_out <span class="token operator">=</span> d_out         self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        self<span class="token punctuation">.</span>head_dim <span class="token operator">=</span> d_out <span class="token operator">//</span> num_heads        self<span class="token punctuation">.</span>W_query <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_out<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span>            <span class="token string">"mask"</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>context_length<span class="token punctuation">,</span> context_length<span class="token punctuation">)</span><span class="token punctuation">,</span>                diagonal<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> d_in <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        queries <span class="token operator">=</span> self<span class="token punctuation">.</span>W_query<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        keys <span class="token operator">=</span> self<span class="token punctuation">.</span>W_key<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        values <span class="token operator">=</span> self<span class="token punctuation">.</span>W_value<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        <span class="token comment"># (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># attn_scores: (b, num_heads, num_tokens, num_tokens)</span>        attn_scores <span class="token operator">=</span> queries @ keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        mask_bool <span class="token operator">=</span> self<span class="token punctuation">.</span>mask<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>num_tokens<span class="token punctuation">,</span> <span class="token punctuation">:</span>num_tokens<span class="token punctuation">]</span>        attn_scores<span class="token punctuation">.</span>masked_fill_<span class="token punctuation">(</span>mask_bool<span class="token punctuation">,</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>inf<span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>            attn_scores <span class="token operator">/</span> keys<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attn_weights<span class="token punctuation">)</span>        <span class="token comment"># (b, num_heads, num_tokens, num_tokens) * (b, num_heads, num_tokens, head_dim)</span>        <span class="token comment"># (b, num_heads, num_tokens, head_dim) -> (b, num_tokens, num_heads, head_dim)</span>        context_vec <span class="token operator">=</span> <span class="token punctuation">(</span>attn_weights @ values<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> context_vec<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>            b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_out        <span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>out_proj<span class="token punctuation">(</span>context_vec<span class="token punctuation">)</span>        <span class="token keyword">return</span> context_vec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="GELU激活函数"><a href="#GELU激活函数" class="headerlink" title="GELU激活函数"></a>GELU激活函数</h3><p>GELU激活函数在大模型中运用较多，相比RELU，GELU更平滑，有利于减少梯度爆炸或梯度消失的情况。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GELU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> x <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>pi<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span>             <span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token number">0.44715</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="FeedForward"><a href="#FeedForward" class="headerlink" title="FeedForward"></a>FeedForward</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a>LayerNorm</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LayerNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> <span class="token number">1e-5</span>        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shift <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        var <span class="token operator">=</span> x<span class="token punctuation">.</span>var<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>scale <span class="token operator">*</span> norm_x <span class="token operator">+</span> self<span class="token punctuation">.</span>shift<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="TransformerBlock"><a href="#TransformerBlock" class="headerlink" title="TransformerBlock"></a>TransformerBlock</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>att <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>            d_in<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            d_out<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            context_length<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            num_heads<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"n_heads"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            dropout<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            qkv_bias<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"qkv_bias"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ff <span class="token operator">=</span> FeedForward<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        shortcut <span class="token operator">=</span> x         x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>att<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut                shortcut <span class="token operator">=</span> x         x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ff<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut        <span class="token keyword">return</span> x <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GPTModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>tok_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>trf_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span><span class="token punctuation">[</span>TransformerBlock<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"n_layers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>final_norm <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>            cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch_size<span class="token punctuation">,</span> seq_len <span class="token operator">=</span> in_idx<span class="token punctuation">.</span>shape        tok_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>tok_emb<span class="token punctuation">(</span>in_idx<span class="token punctuation">)</span>        pos_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_emb<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> device<span class="token operator">=</span>in_idx<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        <span class="token punctuation">)</span>        x <span class="token operator">=</span> tok_embeds <span class="token operator">+</span> pos_embeds        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_emb<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>final_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>out_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">GPT_CONFIG_124M <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"vocab_size"</span><span class="token punctuation">:</span> <span class="token number">50257</span><span class="token punctuation">,</span> <span class="token comment"># Vocabulary size</span>    <span class="token string">"context_length"</span><span class="token punctuation">:</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token comment"># Context length</span>    <span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span> <span class="token comment"># Embedding dimension</span>    <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token comment"># Number of attention heads</span>    <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token comment"># Number of layers</span>    <span class="token string">"drop_rate"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token comment"># Dropout rate</span>    <span class="token string">"qkv_bias"</span><span class="token punctuation">:</span> <span class="token boolean">False</span> <span class="token comment"># Query-Key-Value bias</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generate_text_simple</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> idx<span class="token punctuation">,</span>                        max_new_tokens<span class="token punctuation">,</span> context_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 一次一次的迭代续写</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_new_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>        idx_cond <span class="token operator">=</span> idx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>context_size<span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            logits <span class="token operator">=</span> model<span class="token punctuation">(</span>idx_cond<span class="token punctuation">)</span>                    logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># The last time step</span>        probas <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        idx_next <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>probas<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> idx_next<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> idx<span class="token keyword">def</span> <span class="token function">text_to_token_ids</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> allowed_special<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'&lt;|endoftext|>'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>    encoded_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>encoded<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> encoded_tensor<span class="token keyword">def</span> <span class="token function">token_ids_to_text</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    flat <span class="token operator">=</span> token_ids<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>flat<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_loss_batch</span><span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_batch <span class="token operator">=</span> input_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    target_batch <span class="token operator">=</span> target_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span>    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>        logits<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target_batch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token keyword">def</span> <span class="token function">calc_loss_loader</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0.</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">"nan"</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> num_batches <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> num_batches<span class="token punctuation">:</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device             <span class="token punctuation">)</span>            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> num_batches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="预训练函数"><a href="#预训练函数" class="headerlink" title="预训练函数"></a>预训练函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_model_simple</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span>                    optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span>                    eval_freq<span class="token punctuation">,</span> eval_iter<span class="token punctuation">,</span> start_context<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> track_tokens_seen <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    tokens_seen<span class="token punctuation">,</span> global_step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> input_batch<span class="token punctuation">,</span> target_batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device            <span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            tokens_seen <span class="token operator">+=</span> input_batch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span>            global_step <span class="token operator">+=</span> <span class="token number">1</span>                        <span class="token keyword">if</span> global_step <span class="token operator">%</span> eval_freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                train_loss<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>                    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter                <span class="token punctuation">)</span>                train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>                val_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span>                track_tokens_seen<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokens_seen<span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ep </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string"> (Step </span><span class="token interpolation"><span class="token punctuation">&#123;</span>global_step<span class="token punctuation">:</span><span class="token format-spec">06d</span><span class="token punctuation">&#125;</span></span><span class="token string">): "</span></span>                    <span class="token string-interpolation"><span class="token string">f"Train loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">, "</span></span>                    <span class="token string-interpolation"><span class="token string">f"Val loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>        generate_and_print_sample<span class="token punctuation">(</span>            model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> start_context        <span class="token punctuation">)</span>    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> track_tokens_seen<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter        <span class="token punctuation">)</span>        val_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter        <span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> train_loss<span class="token punctuation">,</span> val_loss<span class="token keyword">def</span> <span class="token function">generate_and_print_sample</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> start_context<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    context_size <span class="token operator">=</span> model<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    encoded <span class="token operator">=</span> text_to_token_ids<span class="token punctuation">(</span>start_context<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        token_ids <span class="token operator">=</span> generate_text_simple<span class="token punctuation">(</span>            model<span class="token operator">=</span>model<span class="token punctuation">,</span> idx<span class="token operator">=</span>encoded<span class="token punctuation">,</span>            max_new_tokens<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> context_size<span class="token operator">=</span>context_size        <span class="token punctuation">)</span>    decoded_text <span class="token operator">=</span> token_ids_to_text<span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>decoded_text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="加载数据类"><a href="#加载数据类" class="headerlink" title="加载数据类"></a>加载数据类</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GPTDatasetV1</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> txt<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>input_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>target_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                token_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>txt<span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">)</span> <span class="token operator">-</span> max_length<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>            input_chunk <span class="token operator">=</span> token_ids<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>max_length<span class="token punctuation">]</span>            target_chunk <span class="token operator">=</span> token_ids<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span>i<span class="token operator">+</span>max_length<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>                self<span class="token punctuation">.</span>input_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>input_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>target_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_ids<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>input_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>target_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">create_dataloader_v1</span><span class="token punctuation">(</span>txt<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>                        stride<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                        num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tokenizer <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span>    dataset <span class="token operator">=</span> GPTDatasetV1<span class="token punctuation">(</span>txt<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">,</span> stride<span class="token punctuation">)</span>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        dataset<span class="token punctuation">,</span>        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>        shuffle<span class="token operator">=</span>shuffle<span class="token punctuation">,</span>        drop_last<span class="token operator">=</span>drop_last<span class="token punctuation">,</span>        num_workers<span class="token operator">=</span>num_workers    <span class="token punctuation">)</span>    <span class="token keyword">return</span> dataloader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="下载预训练数据"><a href="#下载预训练数据" class="headerlink" title="下载预训练数据"></a>下载预训练数据</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>requesturl <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"https://raw.githubusercontent.com/rasbt/"</span>    <span class="token string">"LLMs-from-scratch/main/ch02/01_main-chapter-code/"</span>    <span class="token string">"the-verdict.txt"</span><span class="token punctuation">)</span>file_path <span class="token operator">=</span> <span class="token string">"the-verdict.txt"</span>urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span> file_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">file_path <span class="token operator">=</span> <span class="token string">"the-verdict.txt"</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>    text_data <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    tokenizer <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span>total_characters <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text_data<span class="token punctuation">)</span>total_tokens <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_ratio <span class="token operator">=</span> <span class="token number">0.90</span>split_idx <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>train_ratio <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text_data<span class="token punctuation">)</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> text_data<span class="token punctuation">[</span><span class="token punctuation">:</span>split_idx<span class="token punctuation">]</span>val_data <span class="token operator">=</span> text_data<span class="token punctuation">[</span>split_idx<span class="token punctuation">:</span><span class="token punctuation">]</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> create_dataloader_v1<span class="token punctuation">(</span>    train_data<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    stride<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> create_dataloader_v1<span class="token punctuation">(</span>    val_data<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    stride<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Train loader:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nValidation loader:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> val_loader<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">    Train loader:    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])        Validation loader:    torch.Size([2, 256]) torch.Size([2, 256])    ```   ### 预训练```pythontorch.manual_seed(123)model = GPTModel(GPT_CONFIG_124M)# model.eval()device = torch.device("cuda" if torch.cuda.is_available() else "cpu")model.to(device)with torch.no_grad():    train_loss = calc_loss_loader(train_loader, model, device)    val_loss = calc_loss_loader(val_loader, model, device)    print("Training loss:", train_loss)print("Validation loss:", val_loss)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Training loss: 10.995166460673014Validation loss: 10.99630355834961</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>    model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    lr<span class="token operator">=</span><span class="token number">0.0004</span><span class="token punctuation">,</span>    weight_decay<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>num_epochs <span class="token operator">=</span> <span class="token number">10</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> tokens_seen <span class="token operator">=</span> train_model_simple<span class="token punctuation">(</span>    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span>    num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_freq<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> eval_iter<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>    start_context<span class="token operator">=</span><span class="token string">"Every effort moves you"</span><span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Ep 1 (Step 000000): Train loss 9.973, Val loss 9.913    Ep 1 (Step 000005): Train loss 8.197, Val loss 8.290    Every effort moves you                                                      Ep 2 (Step 000010): Train loss 6.802, Val loss 7.059    Ep 2 (Step 000015): Train loss 6.140, Val loss 6.640    Every effort moves you, the, the, the, the, the, the.                                         Ep 3 (Step 000020): Train loss 5.688, Val loss 6.512    Ep 3 (Step 000025): Train loss 5.370, Val loss 6.407    Every effort moves you.                                                     Ep 4 (Step 000030): Train loss 4.856, Val loss 6.393    Ep 4 (Step 000035): Train loss 4.330, Val loss 6.221    Every effort moves you know the, and my the fact--I had the fact of the fact--his, and I had been the fact--I had been, and, and I had been, and--his, and Mrs.           Ep 5 (Step 000040): Train loss 3.943, Val loss 6.078    Every effort moves you know," was one of the ax.                                              Ep 6 (Step 000045): Train loss 3.061, Val loss 6.133    Ep 6 (Step 000050): Train loss 2.863, Val loss 6.081    Every effort moves you know," was not that the axioms he was not the the Sevres and silver of an exquisburn, I had to see a smile, and I looked at the donkey again.               Ep 7 (Step 000055): Train loss 2.209, Val loss 6.160    Ep 7 (Step 000060): Train loss 1.692, Val loss 6.160    Every effort moves you know," was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his painting.                    Ep 8 (Step 000065): Train loss 1.277, Val loss 6.224    Ep 8 (Step 000070): Train loss 0.978, Val loss 6.216    Every effort moves you?"  "Yes--quite insensible to the fact with the Sevres and silver of an exquisburn's an unusual degree to the display of his close grayish beard--as if he had the donkey. "There were days when I    Ep 9 (Step 000075): Train loss 0.666, Val loss 6.302    Ep 9 (Step 000080): Train loss 0.533, Val loss 6.382    Every effort moves you?"  "Yes--quite insensible to the fact with a laugh: "Yes--and by me!"  "Oh, and Mrs. Stroud. She, one might put it, the donkey. "strongest," as his    Ep 10 (Step 000085): Train loss 0.347, Val loss 6.424    Every effort moves you?"  "Yes--quite insensible to the irony. She wanted him vindicated--and by me!"  He laughed again, and threw back his head to look up at the sketch of the donkey. "There were days when I```           ### matplotlib```pythonimport matplotlib.pyplot as plt from matplotlib.ticker import MaxNLocatordef plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):    fig, axl = plt.subplots(figsize=(5,3))    axl.plot(epochs_seen, train_losses, label="Training loss")    axl.plot(        epochs_seen, val_losses, linestyle="-.", label="Validation loss"    )    axl.set_xlabel("Epochs")    axl.set_ylabel("Loss")    axl.legend(loc="upper right")    axl.xaxis.set_major_locator(MaxNLocator(integer=True))    ax2 = axl.twiny()    ax2.plot(tokens_seen, train_losses, alpha=0)    ax2.set_xlabel("Tokens seen")    fig.tight_layout()    plt.show()    epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAdIPYV"><img src="https://s21.ax1x.com/2024/10/23/pAdIPYV.png" alt="pAdIPYV.png"></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;GPT架构总览&lt;/strong&gt;如下图所示，我们这里简单创建了一个GPT模型，它是ChatGPT的基础架构。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://imgse.com/i/pAdEp40&quot;&gt;&lt;img src=&quot;https://s21.ax1x.co</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="https://zhangchaofan01.gitee.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>alphafold2_install</title>
    <link href="https://zhangchaofan01.gitee.io/2024/10/18/alphafold2-install/"/>
    <id>https://zhangchaofan01.gitee.io/2024/10/18/alphafold2-install/</id>
    <published>2024-10-18T13:50:31.000Z</published>
    <updated>2024-10-18T13:56:32.684Z</updated>
    
    <content type="html"><![CDATA[<p>原始的AlphaFold2需要docker环境，目前我们服务器还没有配置docker，就先用conda环境替代吧。</p><h2 id="1-软件下载"><a href="#1-软件下载" class="headerlink" title="1.软件下载"></a>1.软件下载</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;kalininalab&#x2F;alphafold_non_docker.gitwget https:&#x2F;&#x2F;github.com&#x2F;google-deepmind&#x2F;alphafold&#x2F;archive&#x2F;refs&#x2F;tags&#x2F;v2.3.2.tar.gztar -zxvf v2.3.2.tar.gz# 环境配置建议参考alphafold_non_docker里的README.md，特别注意CUDA版本相关的包conda create -n alphafold2conda activate alphafold2conda install -y -c conda-forge openmm&#x3D;8.0.0 pdbfixer python&#x3D;3.10 -c conda-forgeconda install nvidia&#x2F;label&#x2F;cuda-12.4.0::cuda-toolkit conda install cudnn&#x3D;8.9.2.26&#x3D;cuda12_0 -c nvidiaconda install -y -c bioconda hmmer hhsuite&#x3D;&#x3D;3.3.0 kalign2 cudnn&#x3D;8.9pip install absl-py&#x3D;&#x3D;1.0.0 biopython&#x3D;&#x3D;1.79 chex&#x3D;&#x3D;0.0.7 dm-haiku&#x3D;&#x3D;0.0.13 dm-tree&#x3D;&#x3D;0.1.6 immutabledict&#x3D;&#x3D;2.0.0 ml-collections&#x3D;&#x3D;0.1.0 numpy&#x3D;&#x3D;1.22 pandas&#x3D;&#x3D;1.3.4 protobuf&#x3D;&#x3D;3.20.1 scipy&#x3D;&#x3D;1.11.4 tensorflow-cpu&#x3D;&#x3D;2.9.0pip3 install --upgrade --no-cache-dir jax&#x3D;&#x3D;0.4.23 jaxlib&#x3D;&#x3D;0.4.23+cuda12.cudnn89 -f https:&#x2F;&#x2F;storage.googleapis.com&#x2F;jax-releases&#x2F;jax_cuda_releases.html# 下载依赖数据库(非常大)bash alphafold_non_docker&#x2F;download_db.sh -d database<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装的时候非常混乱，这里给出我的环境，基于<code>CUDA12.4</code>, 可以直接通过<code>conda</code>安装：<br><code>conda env create -f alphafold2.yml</code></p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>alphafold2.yml(CUDA12.4)</span></div><code class="language-shell">name: alphafold2channels:  - bioconda  - nvidia  - nvidia&#x2F;label&#x2F;cuda-12.4.0  - conda-forge  - defaultsdependencies:  - _libgcc_mutex&#x3D;0.1&#x3D;conda_forge  - _openmp_mutex&#x3D;4.5&#x3D;2_gnu  - bzip2&#x3D;1.0.8&#x3D;h4bc722e_7  - ca-certificates&#x3D;2024.9.24&#x3D;h06a4308_0  - cuda-cccl&#x3D;12.4.99&#x3D;0  - cuda-command-line-tools&#x3D;12.4.0&#x3D;0  - cuda-compiler&#x3D;12.4.0&#x3D;0  - cuda-cudart&#x3D;12.4.99&#x3D;0  - cuda-cudart-dev&#x3D;12.4.99&#x3D;0  - cuda-cudart-static&#x3D;12.4.99&#x3D;0  - cuda-cuobjdump&#x3D;12.4.99&#x3D;0  - cuda-cupti&#x3D;12.4.99&#x3D;0  - cuda-cupti-static&#x3D;12.4.99&#x3D;0  - cuda-cuxxfilt&#x3D;12.4.99&#x3D;0  - cuda-documentation&#x3D;12.4.99&#x3D;0  - cuda-driver-dev&#x3D;12.4.99&#x3D;0  - cuda-gdb&#x3D;12.4.99&#x3D;0  - cuda-libraries&#x3D;12.4.0&#x3D;0  - cuda-libraries-dev&#x3D;12.4.0&#x3D;0  - cuda-libraries-static&#x3D;12.4.0&#x3D;0  - cuda-nsight&#x3D;12.4.99&#x3D;0  - cuda-nsight-compute&#x3D;12.4.0&#x3D;0  - cuda-nvcc&#x3D;12.4.99&#x3D;0  - cuda-nvdisasm&#x3D;12.4.99&#x3D;0  - cuda-nvml-dev&#x3D;12.4.99&#x3D;0  - cuda-nvprof&#x3D;12.4.99&#x3D;0  - cuda-nvprune&#x3D;12.4.99&#x3D;0  - cuda-nvrtc&#x3D;12.4.99&#x3D;0  - cuda-nvrtc-dev&#x3D;12.4.99&#x3D;0  - cuda-nvrtc-static&#x3D;12.4.99&#x3D;0  - cuda-nvtx&#x3D;12.4.99&#x3D;0  - cuda-nvvp&#x3D;12.4.99&#x3D;0  - cuda-opencl&#x3D;12.4.99&#x3D;0  - cuda-opencl-dev&#x3D;12.4.99&#x3D;0  - cuda-profiler-api&#x3D;12.4.99&#x3D;0  - cuda-sanitizer-api&#x3D;12.4.99&#x3D;0  - cuda-toolkit&#x3D;12.4.0&#x3D;0  - cuda-tools&#x3D;12.4.0&#x3D;0  - cuda-version&#x3D;12.6&#x3D;3  - cuda-visual-tools&#x3D;12.4.0&#x3D;0  - cudnn&#x3D;8.9.2.26&#x3D;cuda12_0  - gds-tools&#x3D;1.9.0.20&#x3D;0  - hhsuite&#x3D;3.3.0&#x3D;py310pl5321hc31ed2c_13  - hmmer&#x3D;3.4&#x3D;hdbdd923_2  - kalign2&#x3D;2.04&#x3D;h031d066_7  - ld_impl_linux-64&#x3D;2.43&#x3D;h712a8e2_1  - libblas&#x3D;3.9.0&#x3D;24_linux64_openblas  - libcblas&#x3D;3.9.0&#x3D;24_linux64_openblas  - libcublas&#x3D;12.4.2.65&#x3D;0  - libcublas-dev&#x3D;12.4.2.65&#x3D;0  - libcublas-static&#x3D;12.4.2.65&#x3D;0  - libcufft&#x3D;11.2.0.44&#x3D;0  - libcufft-dev&#x3D;11.2.0.44&#x3D;0  - libcufft-static&#x3D;11.2.0.44&#x3D;0  - libcufile&#x3D;1.9.0.20&#x3D;0  - libcufile-dev&#x3D;1.9.0.20&#x3D;0  - libcufile-static&#x3D;1.9.0.20&#x3D;0  - libcurand&#x3D;10.3.5.119&#x3D;0  - libcurand-dev&#x3D;10.3.5.119&#x3D;0  - libcurand-static&#x3D;10.3.5.119&#x3D;0  - libcusolver&#x3D;11.6.0.99&#x3D;0  - libcusolver-dev&#x3D;11.6.0.99&#x3D;0  - libcusolver-static&#x3D;11.6.0.99&#x3D;0  - libcusparse&#x3D;12.3.0.142&#x3D;0  - libcusparse-dev&#x3D;12.3.0.142&#x3D;0  - libcusparse-static&#x3D;12.3.0.142&#x3D;0  - libffi&#x3D;3.4.2&#x3D;h7f98852_5  - libgcc&#x3D;14.2.0&#x3D;h77fa898_1  - libgcc-ng&#x3D;14.2.0&#x3D;h69a702a_1  - libgfortran&#x3D;14.2.0&#x3D;h69a702a_1  - libgfortran-ng&#x3D;14.2.0&#x3D;h69a702a_1  - libgfortran5&#x3D;14.2.0&#x3D;hd5240d6_1  - libgomp&#x3D;14.2.0&#x3D;h77fa898_1  - liblapack&#x3D;3.9.0&#x3D;24_linux64_openblas  - libnpp&#x3D;12.2.5.2&#x3D;0  - libnpp-dev&#x3D;12.2.5.2&#x3D;0  - libnpp-static&#x3D;12.2.5.2&#x3D;0  - libnsl&#x3D;2.0.1&#x3D;hd590300_0  - libnvfatbin&#x3D;12.4.99&#x3D;0  - libnvfatbin-dev&#x3D;12.4.99&#x3D;0  - libnvjitlink&#x3D;12.4.99&#x3D;0  - libnvjitlink-dev&#x3D;12.4.99&#x3D;0  - libnvjpeg&#x3D;12.3.1.89&#x3D;0  - libnvjpeg-dev&#x3D;12.3.1.89&#x3D;0  - libnvjpeg-static&#x3D;12.3.1.89&#x3D;0  - libopenblas&#x3D;0.3.27&#x3D;pthreads_hac2b453_1  - libsqlite&#x3D;3.46.1&#x3D;hadc24fc_0  - libstdcxx&#x3D;14.2.0&#x3D;hc0a3c3a_1  - libstdcxx-ng&#x3D;14.2.0&#x3D;h4852527_1  - libuuid&#x3D;2.38.1&#x3D;h0b41bf4_0  - libxcrypt&#x3D;4.4.36&#x3D;hd590300_1  - libzlib&#x3D;1.3.1&#x3D;hb9d3cd8_2  - ncurses&#x3D;6.5&#x3D;he02047a_1  - nsight-compute&#x3D;2024.1.0.13&#x3D;0  - ocl-icd&#x3D;2.3.2&#x3D;hd590300_1  - ocl-icd-system&#x3D;1.0.0&#x3D;1  - openmm&#x3D;8.0.0&#x3D;py310h9995159_4  - openssl&#x3D;3.3.2&#x3D;hb9d3cd8_0  - pdbfixer&#x3D;1.9&#x3D;pyh1a96a4e_0  - perl&#x3D;5.32.1&#x3D;0_h5eee18b_perl5  - pip&#x3D;24.2&#x3D;pyh8b19718_1  - python&#x3D;3.10.15&#x3D;h4a871b0_2_cpython  - python_abi&#x3D;3.10&#x3D;5_cp310  - readline&#x3D;8.2&#x3D;h8228510_1  - setuptools&#x3D;75.1.0&#x3D;pyhd8ed1ab_0  - tk&#x3D;8.6.13&#x3D;noxft_h4845f30_101  - tzdata&#x3D;2024b&#x3D;hc8b5060_0  - wheel&#x3D;0.44.0&#x3D;pyhd8ed1ab_0  - xz&#x3D;5.2.6&#x3D;h166bdaf_0  - pip:      - absl-py&#x3D;&#x3D;1.0.0      - astunparse&#x3D;&#x3D;1.6.3      - biopython&#x3D;&#x3D;1.79      - cachetools&#x3D;&#x3D;5.5.0      - certifi&#x3D;&#x3D;2024.8.30      - charset-normalizer&#x3D;&#x3D;3.4.0      - chex&#x3D;&#x3D;0.0.7      - contextlib2&#x3D;&#x3D;21.6.0      - dm-haiku&#x3D;&#x3D;0.0.13      - dm-tree&#x3D;&#x3D;0.1.6      - flatbuffers&#x3D;&#x3D;1.12      - gast&#x3D;&#x3D;0.4.0      - google-auth&#x3D;&#x3D;2.35.0      - google-auth-oauthlib&#x3D;&#x3D;0.4.6      - google-pasta&#x3D;&#x3D;0.2.0      - grpcio&#x3D;&#x3D;1.67.0      - h5py&#x3D;&#x3D;3.12.1      - idna&#x3D;&#x3D;3.10      - immutabledict&#x3D;&#x3D;2.0.0      - jax&#x3D;&#x3D;0.4.23      - jaxlib&#x3D;&#x3D;0.4.23+cuda12.cudnn89      - jmp&#x3D;&#x3D;0.0.4      - keras&#x3D;&#x3D;2.9.0      - keras-preprocessing&#x3D;&#x3D;1.1.2      - libclang&#x3D;&#x3D;18.1.1      - markdown&#x3D;&#x3D;3.7      - markupsafe&#x3D;&#x3D;3.0.1      - ml-collections&#x3D;&#x3D;0.1.0      - ml-dtypes&#x3D;&#x3D;0.5.0      - numpy&#x3D;&#x3D;1.22.0      - oauthlib&#x3D;&#x3D;3.2.2      - opt-einsum&#x3D;&#x3D;3.4.0      - packaging&#x3D;&#x3D;24.1      - pandas&#x3D;&#x3D;1.3.4      - protobuf&#x3D;&#x3D;3.20.1      - pyasn1&#x3D;&#x3D;0.6.1      - pyasn1-modules&#x3D;&#x3D;0.4.1      - python-dateutil&#x3D;&#x3D;2.9.0.post0      - pytz&#x3D;&#x3D;2024.2      - pyyaml&#x3D;&#x3D;6.0.2      - requests&#x3D;&#x3D;2.32.3      - requests-oauthlib&#x3D;&#x3D;2.0.0      - rsa&#x3D;&#x3D;4.9      - scipy&#x3D;&#x3D;1.11.4      - six&#x3D;&#x3D;1.16.0      - tabulate&#x3D;&#x3D;0.9.0      - tensorboard&#x3D;&#x3D;2.9.0      - tensorboard-data-server&#x3D;&#x3D;0.6.1      - tensorboard-plugin-wit&#x3D;&#x3D;1.8.1      - tensorflow-cpu&#x3D;&#x3D;2.9.0      - tensorflow-estimator&#x3D;&#x3D;2.9.0      - tensorflow-io-gcs-filesystem&#x3D;&#x3D;0.37.1      - termcolor&#x3D;&#x3D;2.5.0      - toolz&#x3D;&#x3D;1.0.0      - typing-extensions&#x3D;&#x3D;4.12.2      - urllib3&#x3D;&#x3D;2.2.3      - werkzeug&#x3D;&#x3D;3.0.4      - wrapt&#x3D;&#x3D;1.16.0prefix: &#x2F;data&#x2F;chaofan&#x2F;miniconda3&#x2F;envs&#x2F;alphafold2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个是我之前基于<code>CUDA11.6</code>的环境：</p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>alphafold2.yml(CUDA11.6)</span></div><code class="language-shell">name: alphafold2channels:  - nvidia  - conda-forge  - bioconda  - defaultsdependencies:  - _libgcc_mutex&#x3D;0.1&#x3D;main  - _openmp_mutex&#x3D;5.1&#x3D;1_gnu  - blas&#x3D;1.0&#x3D;mkl  - ca-certificates&#x3D;2023.7.22&#x3D;hbcca054_0  - cuda-nvcc&#x3D;11.6.124&#x3D;hbba6d2d_0  - cudatoolkit&#x3D;11.2.2&#x3D;hbe64b41_10  - fftw&#x3D;3.3.9&#x3D;h27cfd23_1  - hhsuite&#x3D;3.3.0&#x3D;py38pl5321h8ded8fe_5  - hmmer&#x3D;3.3.2&#x3D;h87f3376_2  - intel-openmp&#x3D;2021.4.0&#x3D;h06a4308_3561  - kalign2&#x3D;2.04&#x3D;hec16e2b_3  - libedit&#x3D;3.1.20221030&#x3D;h5eee18b_0  - libffi&#x3D;3.2.1&#x3D;hf484d3e_1007  - libgcc-ng&#x3D;11.2.0&#x3D;h1234567_1  - libgomp&#x3D;11.2.0&#x3D;h1234567_1  - libnsl&#x3D;2.0.0&#x3D;h5eee18b_0  - libstdcxx-ng&#x3D;11.2.0&#x3D;h1234567_1  - mkl&#x3D;2021.4.0&#x3D;h06a4308_640  - mkl-service&#x3D;2.4.0&#x3D;py38h7f8727e_0  - mkl_fft&#x3D;1.3.1&#x3D;py38hd3c417c_0  - mkl_random&#x3D;1.2.2&#x3D;py38h51133e4_0  - ncurses&#x3D;6.4&#x3D;h6a678d5_0  - numpy-base&#x3D;1.24.3&#x3D;py38h31eccc5_0  - ocl-icd&#x3D;2.3.1&#x3D;h7f98852_0  - ocl-icd-system&#x3D;1.0.0&#x3D;1  - openmm&#x3D;7.5.1&#x3D;py38ha082873_1  - openssl&#x3D;1.1.1l&#x3D;h7f98852_0  - parallel&#x3D;20230922&#x3D;ha770c72_0  - pdbfixer&#x3D;1.7&#x3D;pyhd3deb0d_0  - perl&#x3D;5.32.1&#x3D;0_h5eee18b_perl5  - pip&#x3D;23.2.1&#x3D;py38h06a4308_0  - python&#x3D;3.8.0&#x3D;h0371630_2  - python_abi&#x3D;3.8&#x3D;2_cp38  - readline&#x3D;7.0&#x3D;h7b6447c_5  - setuptools&#x3D;68.0.0&#x3D;py38h06a4308_0  - six&#x3D;1.16.0&#x3D;pyhd3eb1b0_1  - sqlite&#x3D;3.33.0&#x3D;h62c20be_0  - tk&#x3D;8.6.12&#x3D;h1ccaba5_0  - wheel&#x3D;0.41.2&#x3D;py38h06a4308_0  - xz&#x3D;5.4.2&#x3D;h5eee18b_0  - zlib&#x3D;1.2.13&#x3D;h5eee18b_0  - pip:      - absl-py&#x3D;&#x3D;1.0.0      - alphapulldown&#x3D;&#x3D;0.30.7      - anyio&#x3D;&#x3D;4.0.0      - appdirs&#x3D;&#x3D;1.4.4      - argon2-cffi&#x3D;&#x3D;23.1.0      - argon2-cffi-bindings&#x3D;&#x3D;21.2.0      - arrow&#x3D;&#x3D;1.3.0      - asttokens&#x3D;&#x3D;2.4.0      - astunparse&#x3D;&#x3D;1.6.3      - async-lru&#x3D;&#x3D;2.0.4      - attrs&#x3D;&#x3D;23.1.0      - babel&#x3D;&#x3D;2.13.0      - backcall&#x3D;&#x3D;0.2.0      - beautifulsoup4&#x3D;&#x3D;4.12.2      - biopython&#x3D;&#x3D;1.78      - bleach&#x3D;&#x3D;6.1.0      - cachetools&#x3D;&#x3D;5.3.1      - certifi&#x3D;&#x3D;2023.7.22      - cffi&#x3D;&#x3D;1.16.0      - charset-normalizer&#x3D;&#x3D;3.3.0      - chex&#x3D;&#x3D;0.0.7      - comm&#x3D;&#x3D;0.1.4      - contextlib2&#x3D;&#x3D;21.6.0      - cycler&#x3D;&#x3D;0.12.1      - debugpy&#x3D;&#x3D;1.8.0      - decorator&#x3D;&#x3D;5.1.1      - defusedxml&#x3D;&#x3D;0.7.1      - dm-haiku&#x3D;&#x3D;0.0.9      - dm-tree&#x3D;&#x3D;0.1.6      - exceptiongroup&#x3D;&#x3D;1.1.3      - executing&#x3D;&#x3D;2.0.0      - fastjsonschema&#x3D;&#x3D;2.18.1      - flatbuffers&#x3D;&#x3D;1.12      - fqdn&#x3D;&#x3D;1.5.1      - gast&#x3D;&#x3D;0.4.0      - google-auth&#x3D;&#x3D;2.23.2      - google-auth-oauthlib&#x3D;&#x3D;0.4.6      - google-pasta&#x3D;&#x3D;0.2.0      - grpcio&#x3D;&#x3D;1.59.0      - h5py&#x3D;&#x3D;3.1.0      - idna&#x3D;&#x3D;3.4      - immutabledict&#x3D;&#x3D;2.0.0      - importlib-metadata&#x3D;&#x3D;6.8.0      - importlib-resources&#x3D;&#x3D;5.8.0      - ipykernel&#x3D;&#x3D;6.25.2      - ipython&#x3D;&#x3D;8.12.3      - ipywidgets&#x3D;&#x3D;8.1.1      - isoduration&#x3D;&#x3D;20.11.0      - jax&#x3D;&#x3D;0.3.25      - jaxlib&#x3D;&#x3D;0.3.25+cuda11.cudnn805      - jedi&#x3D;&#x3D;0.19.1      - jinja2&#x3D;&#x3D;3.1.2      - jmp&#x3D;&#x3D;0.0.4      - json5&#x3D;&#x3D;0.9.14      - jsonpointer&#x3D;&#x3D;2.4      - jsonschema&#x3D;&#x3D;4.19.1      - jsonschema-specifications&#x3D;&#x3D;2023.7.1      - jupyter-client&#x3D;&#x3D;8.4.0      - jupyter-core&#x3D;&#x3D;5.4.0      - jupyter-events&#x3D;&#x3D;0.7.0      - jupyter-lsp&#x3D;&#x3D;2.2.0      - jupyter-server&#x3D;&#x3D;2.7.3      - jupyter-server-terminals&#x3D;&#x3D;0.4.4      - jupyterlab&#x3D;&#x3D;4.0.7      - jupyterlab-pygments&#x3D;&#x3D;0.2.2      - jupyterlab-server&#x3D;&#x3D;2.25.0      - jupyterlab-widgets&#x3D;&#x3D;3.0.9      - keras&#x3D;&#x3D;2.9.0      - keras-preprocessing&#x3D;&#x3D;1.1.2      - kiwisolver&#x3D;&#x3D;1.4.5      - libclang&#x3D;&#x3D;16.0.6      - markdown&#x3D;&#x3D;3.4.4      - markupsafe&#x3D;&#x3D;2.1.3      - matplotlib&#x3D;&#x3D;3.3.3      - matplotlib-inline&#x3D;&#x3D;0.1.6      - mistune&#x3D;&#x3D;2.0.5      - ml-collections&#x3D;&#x3D;0.1.0      - ml-dtypes&#x3D;&#x3D;0.2.0      - nbclient&#x3D;&#x3D;0.8.0      - nbconvert&#x3D;&#x3D;7.4.0      - nbformat&#x3D;&#x3D;5.4.0      - nest-asyncio&#x3D;&#x3D;1.5.8      - notebook-shim&#x3D;&#x3D;0.2.3      - numpy&#x3D;&#x3D;1.21.6      - oauthlib&#x3D;&#x3D;3.2.2      - opt-einsum&#x3D;&#x3D;3.3.0      - overrides&#x3D;&#x3D;7.4.0      - packaging&#x3D;&#x3D;23.2      - pandas&#x3D;&#x3D;1.3.4      - pandocfilters&#x3D;&#x3D;1.5.0      - parso&#x3D;&#x3D;0.8.3      - pexpect&#x3D;&#x3D;4.8.0      - pickleshare&#x3D;&#x3D;0.7.5      - pillow&#x3D;&#x3D;10.0.1      - pkgutil-resolve-name&#x3D;&#x3D;1.3.10      - platformdirs&#x3D;&#x3D;3.11.0      - prometheus-client&#x3D;&#x3D;0.17.1      - prompt-toolkit&#x3D;&#x3D;3.0.39      - protobuf&#x3D;&#x3D;3.20.1      - psutil&#x3D;&#x3D;5.9.5      - ptyprocess&#x3D;&#x3D;0.7.0      - pure-eval&#x3D;&#x3D;0.2.2      - py3dmol&#x3D;&#x3D;2.0.1      - pyasn1&#x3D;&#x3D;0.5.0      - pyasn1-modules&#x3D;&#x3D;0.3.0      - pycparser&#x3D;&#x3D;2.21      - pygments&#x3D;&#x3D;2.16.1      - pyparsing&#x3D;&#x3D;3.1.1      - python-dateutil&#x3D;&#x3D;2.8.2      - python-json-logger&#x3D;&#x3D;2.0.7      - pytz&#x3D;&#x3D;2023.3.post1      - pyyaml&#x3D;&#x3D;6.0.1      - pyzmq&#x3D;&#x3D;25.1.1      - referencing&#x3D;&#x3D;0.30.2      - requests&#x3D;&#x3D;2.31.0      - requests-oauthlib&#x3D;&#x3D;1.3.1      - rfc3339-validator&#x3D;&#x3D;0.1.4      - rfc3986-validator&#x3D;&#x3D;0.1.1      - rpds-py&#x3D;&#x3D;0.10.6      - rsa&#x3D;&#x3D;4.9      - scipy&#x3D;&#x3D;1.7.0      - send2trash&#x3D;&#x3D;1.8.2      - sniffio&#x3D;&#x3D;1.3.0      - soupsieve&#x3D;&#x3D;2.5      - stack-data&#x3D;&#x3D;0.6.3      - tabulate&#x3D;&#x3D;0.9.0      - tensorboard&#x3D;&#x3D;2.9.0      - tensorboard-data-server&#x3D;&#x3D;0.6.1      - tensorboard-plugin-wit&#x3D;&#x3D;1.8.1      - tensorflow&#x3D;&#x3D;2.9.0      - tensorflow-cpu&#x3D;&#x3D;2.9.0      - tensorflow-estimator&#x3D;&#x3D;2.9.0      - tensorflow-io-gcs-filesystem&#x3D;&#x3D;0.34.0      - termcolor&#x3D;&#x3D;2.3.0      - terminado&#x3D;&#x3D;0.17.1      - tinycss2&#x3D;&#x3D;1.2.1      - tomli&#x3D;&#x3D;2.0.1      - toolz&#x3D;&#x3D;0.12.0      - tornado&#x3D;&#x3D;6.3.3      - tqdm&#x3D;&#x3D;4.66.1      - traitlets&#x3D;&#x3D;5.11.2      - types-python-dateutil&#x3D;&#x3D;2.8.19.14      - typing-extensions&#x3D;&#x3D;4.8.0      - uri-template&#x3D;&#x3D;1.3.0      - urllib3&#x3D;&#x3D;2.0.6      - wcwidth&#x3D;&#x3D;0.2.8      - webcolors&#x3D;&#x3D;1.13      - webencodings&#x3D;&#x3D;0.5.1      - websocket-client&#x3D;&#x3D;1.6.4      - werkzeug&#x3D;&#x3D;3.0.0      - widgetsnbextension&#x3D;&#x3D;4.0.9      - wrapt&#x3D;&#x3D;1.15.0      - zipp&#x3D;&#x3D;3.17.0prefix: &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;miniconda3&#x2F;envs&#x2F;alphafold2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-测试"><a href="#2-测试" class="headerlink" title="2.测试"></a>2.测试</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp alphafold_non_docker&#x2F;run_alphafold.sh alphafold-2.3.2&#x2F;# 修改下相关文件地址vi alphafold-2.3.2&#x2F;run_alphafold.sh# bash alphafold-2.3.2&#x2F;run_alphafold.sh -c reduced_dbs -d .&#x2F;database&#x2F; -o .&#x2F;dummy_test&#x2F; -f t2.fa -t 2024-10-17 -m multimer -l 1 -n 40<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>t2.fa</span></div><code class="language-txt">>Pip1VTEVPNSMDWRKRGSVTGVKDQGVCGCCWAFSAAAAIEGAYQIANNELISLSEQQLLDCSTQNKGCEGGLMTVAYDFLLQNNGGGITTETNYPYEEAQNVCKTEQPAAVTINGYEVVPSDESSLLKAVVNQPISVGIAANDEFHMYGSGIYDGSCNSRLNHAVTVIGYGTSEEDGTKYWIVKNSWGSDWGEEGYMRIARDVGVDGGHCGIAKVASFPTA>EpiC2BQLNGYSKKEVTPEDTELLQKAQSNVSAYNSDVTSRICYLKVDSLETQVVSGENYKFHVSGCSVNSDKELGGCANQNCESSKYDIVIYSQSWTNTLKVTSITPAN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>结果与我们之前在<code>CUDA11.6</code>版本上的一致，也与原文章结果一致。</p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>result</span></div><code class="language-shell">&#123;    &quot;iptm+ptm&quot;: &#123;        &quot;model_1_multimer_v3_pred_0&quot;: 0.913495827158252,        &quot;model_2_multimer_v3_pred_0&quot;: 0.9082750066457126,        &quot;model_3_multimer_v3_pred_0&quot;: 0.9185924126209433,        &quot;model_4_multimer_v3_pred_0&quot;: 0.9199507589621323,        &quot;model_5_multimer_v3_pred_0&quot;: 0.9214059557649581    &#125;,    &quot;order&quot;: [        &quot;model_5_multimer_v3_pred_0&quot;,        &quot;model_4_multimer_v3_pred_0&quot;,        &quot;model_3_multimer_v3_pred_0&quot;,        &quot;model_1_multimer_v3_pred_0&quot;,        &quot;model_2_multimer_v3_pred_0&quot;    ]&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-安装过程中遇到的问题"><a href="#3-安装过程中遇到的问题" class="headerlink" title="3.安装过程中遇到的问题"></a>3.安装过程中遇到的问题</h2><p>1.</p><blockquote><p>Warning: importing ‘simtk.openmm’ is deprecated.  Import ‘openmm’ instead.<br>Traceback (most recent call last):<br>  File “/data/chaofan/software/alphafold2/alphafold-2.3.2/run_alphafold.py”, line 40, in <module><br>    from alphafold.relax import relax<br>  File “/data/chaofan/software/alphafold2/alphafold-2.3.2/alphafold/relax/relax.py”, line 18, in <module><br>    from alphafold.relax import amber_minimize<br>  File “/data/chaofan/software/alphafold2/alphafold-2.3.2/alphafold/relax/amber_minimize.py”, line 33, in <module><br>    from simtk.openmm.app.internal.pdbstructure import PdbStructure<br>ModuleNotFoundError: No module named ‘simtk.openmm.app.internal’   </p></blockquote><blockquote><p><a href="https://github.com/google-deepmind/alphafold/issues/410">https://github.com/google-deepmind/alphafold/issues/410</a>  </p></blockquote><p>2.</p><blockquote><p>Warning: importing ‘simtk.openmm’ is deprecated.  Import ‘openmm’ instead.<br>FATAL Flags parsing error: Unknown command line flag ‘run_relax’<br>Pass –helpshort or –helpfull to see help on flags.  </p></blockquote><blockquote><p>删掉<code>run_alphafold.sh</code>文件中的<code>--run_relax=$run_relax</code></p></blockquote><p>3.</p><blockquote><p>AttributeError: module ‘jax’ has no attribute ‘xla’  </p></blockquote><blockquote><p>pip install dm-haiku -U</p></blockquote><p>还有一种安装方法，自行配置CUDA驱动，参考<code>非root用户安装cuda与cudnn</code>,可以装个和<code>alphafold_non_docker</code>一样的CUDA的版本，配置conda启动时自动替换一些环境变量，可能就没那么麻烦了，这里只提供一种可能的方式，我没有试过。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原始的AlphaFold2需要docker环境，目前我们服务器还没有配置docker，就先用conda环境替代吧。&lt;/p&gt;
&lt;h2 id=&quot;1-软件下载&quot;&gt;&lt;a href=&quot;#1-软件下载&quot; class=&quot;headerlink&quot; title=&quot;1.软件下载&quot;&gt;&lt;/a&gt;1.软</summary>
      
    
    
    
    
    <category term="Deep Learning" scheme="https://zhangchaofan01.gitee.io/tags/Deep-Learning/"/>
    
    <category term="linux" scheme="https://zhangchaofan01.gitee.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>slurm单机部署</title>
    <link href="https://zhangchaofan01.gitee.io/2024/10/10/slurm-dan-ji-bu-shu/"/>
    <id>https://zhangchaofan01.gitee.io/2024/10/10/slurm-dan-ji-bu-shu/</id>
    <published>2024-10-10T13:31:43.000Z</published>
    <updated>2024-10-12T12:58:47.539Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;最近课题组新到了一台8卡GPU服务器，为了更有效的利用计算资源，准备安装一个slurm任务提交系统。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat &#x2F;etc&#x2F;os-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>NAME=”CentOS Linux”<br>VERSION=”8”<br>ID=”centos”<br>ID_LIKE=”rhel fedora”<br>VERSION_ID=”8”<br>PLATFORM_ID=”platform:el8”<br>PRETTY_NAME=”CentOS Linux 8”<br>ANSI_COLOR=”0;31”<br>CPE_NAME=”cpe:/o:centos:centos:8”<br>HOME_URL=”<a href="https://centos.org/&quot;">https://centos.org/&quot;</a><br>BUG_REPORT_URL=”<a href="https://bugs.centos.org/&quot;">https://bugs.centos.org/&quot;</a><br>CENTOS_MANTISBT_PROJECT=”CentOS-8”<br>CENTOS_MANTISBT_PROJECT_VERSION=”8”  </p></blockquote><h3 id="1-换清华源-非必要"><a href="#1-换清华源-非必要" class="headerlink" title="1.换清华源(非必要)"></a>1.换清华源(非必要)</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#sudo cp &#x2F;etc&#x2F;apt&#x2F;sources.list &#x2F;etc&#x2F;apt&#x2F;sources.list.bakrm &#x2F;etc&#x2F;apt&#x2F;sources.listcat &gt;&gt; &#x2F;etc&#x2F;apt&#x2F;sources.list &lt;&lt; &quot;EOF&quot;#添加清华源deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-backports main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-backports main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-security main restricted universe multiverseEOF# 更新配置文件sudo apt-get updatesudo apt-get upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-安装slurm"><a href="#2-安装slurm" class="headerlink" title="2.安装slurm"></a>2.安装slurm</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 下载 slurm_install.sh 网络问题，我直接从github上粘贴过去的wget --no-check-certificate https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;NISP-GmbH&#x2F;SLURM&#x2F;main&#x2F;slurm_install.shexport VER&#x3D;23.02.0# line 1239: bc: command not foundsudo apt-get install bcbash slurm_install.sh# Do you want to enable Slurm accounting support? Possible answers: [yes&#x2F;no] &lt;- no# yes 要配置DB# 按要求修改配置文件vi &#x2F;etc&#x2F;slurm&#x2F;slurm.conf# 设置CPU数量和内存# 详细信息可以通过 systemctl status slurmd 得到，有冲突他会提示# 直接填提示的就行NodeName&#x3D;citrus CPUs&#x3D;256 RealMemory&#x3D;1031612 CoresPerSocket&#x3D;64 SocketsPerBoard&#x3D;2 ThreadsPerCore&#x3D;2 State&#x3D;idle Feature&#x3D;dcv2,other# 更新配置文件sudo systemctl restart slurmctldsudo systemctl restart slurmd# 检查服务运行状态sudo systemctl status slurmctldsudo systemctl status slurmd# 查看slurm 系统配置sinfo -o &quot;%P %D %c %m %C&quot;# 设置开机自启动sudo systemctl enable slurmctld # 守护进程sudo systemctl enable slurmdsudo systemctl enable munge # 一个用于安全认证的守护进程# sudo systemctl enable slurmdbd 没有装DB 不需要<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-GPU配置"><a href="#3-GPU配置" class="headerlink" title="3.GPU配置"></a>3.GPU配置</h3><p>&emsp;&emsp;我们服务器有8张GPUs，现在配置下GPU的设置，让slurm能正确识别GPUs。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># vi &#x2F;etc&#x2F;slurm&#x2F;slurm.conf&quot;GresTypes&#x3D;gpuNodeName&#x3D;citrus CPUs&#x3D;256 Gres&#x3D;gpu:8 RealMemory&#x3D;1031612 CoresPerSocket&#x3D;64 SocketsPerBoard&#x3D;2 ThreadsPerCore&#x3D;2 State&#x3D;idle Feature&#x3D;dcv2,other&quot;# Grescat &gt;&gt; &#x2F;etc&#x2F;slurm&#x2F;gres.conf &lt;&lt; &quot;EOF&quot;NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia0NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia1NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia2NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia3NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia4NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia5NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia6NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia7EOF# 更新配置文件sudo systemctl restart slurmctldsudo systemctl restart slurmdsystemctl restart munge.service# 检查是否识别GPUsinfo -o &quot;%n %T %C %G&quot; # 正确识别8张GPU卡# citrus idle 0&#x2F;256&#x2F;0&#x2F;256 gpu:8<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-测试"><a href="#4-测试" class="headerlink" title="4.测试"></a>4.测试</h3><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>resource_test.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;bash#SBATCH --job-name&#x3D;resource_test#SBATCH --output&#x3D;resource_test.out#SBATCH --error&#x3D;resource_test.err#SBATCH --ntasks&#x3D;1#SBATCH --mem&#x3D;40G#SBATCH --cpus-per-task&#x3D;10#SBATCH --gres&#x3D;gpu:1echo &quot;Hello world!&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sbatch resource_test.shsqueuescancel jobid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>有一种丰收的喜悦：<br><a href="https://imgse.com/i/pAYh6gI"><img src="https://s21.ax1x.com/2024/10/12/pAYh6gI.png" alt="pAYh6gI.png"></a><br><a href="https://imgse.com/i/pAYhObT"><img src="https://s21.ax1x.com/2024/10/12/pAYhObT.md.png" alt="pAYhObT.md.png"></a></p><h3 id="5-删除slurm"><a href="#5-删除slurm" class="headerlink" title="5.删除slurm"></a>5.删除slurm</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo systemctl stop slurmctldsudo systemctl stop slurmdsudo systemctl stop slurmdbd# sudo yum remove slurm*sudo apt-get remove --purge slurm*sudo rm -rf &#x2F;etc&#x2F;slurm&#x2F;sudo rm -rf &#x2F;var&#x2F;log&#x2F;slurm&#x2F;sudo rm -rf &#x2F;var&#x2F;spool&#x2F;slurm&#x2F;sudo userdel slurmsudo groupdel slurmsudo rm -rf &#x2F;var&#x2F;log&#x2F;slurm&#x2F;sudo rm &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;slurmctld.servicesudo rm &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;slurmd.servicesudo rm &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;slurmdbd.servicesudo systemctl daemon-reload# 谨慎sudo find &#x2F; -name &quot;*slurm*&quot; -exec rm -rf &#123;&#125; +<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>普通用户提交任务报错:  </p><blockquote><p><code>sbatch: error: Batch job submission failed: Unexpected message received</code><br>检查 <code>/var/log</code> <code>/var/log/slurmctld.log</code>是否有写入权限。<br>一个比较直接的方法是创建一个新的<code>group</code>，将用户提交到这个新的<code>group</code>里，将<code>/var/log</code>文件所属的group也改为这个，大部分的问题都是用户权限，仔细排查应该不会有什么难度。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&amp;emsp;&amp;emsp;最近课题组新到了一台8卡GPU服务器，为了更有效的利用计算资源，准备安装一个slurm任务提交系统。&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-shell&quot; data-language=&quot;shell&quot;&gt;&lt;code c</summary>
      
    
    
    
    
    <category term="linux" scheme="https://zhangchaofan01.gitee.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>htseq-count的坑</title>
    <link href="https://zhangchaofan01.gitee.io/2024/09/27/htseq-count-de-keng/"/>
    <id>https://zhangchaofan01.gitee.io/2024/09/27/htseq-count-de-keng/</id>
    <published>2024-09-27T00:17:16.000Z</published>
    <updated>2024-09-27T00:26:52.776Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;最近在跑RNA-seq碰到一个自己挖的坑，samtools将sam文件转为二进制的bam文件并排序，默认是按照pos进行排序的。htseq-count默认的输入sam|bam是按照name排序的，这样就导致了一个问题，htseq-count会把不在相邻行的paried-end reads当成一条序列：</p><blockquote><p>Warning: 16607642 reads with missing mate encountered.  </p></blockquote><p>&emsp;&emsp;后果是导致虚假的输出： <a href="https://github.com/htseq/htseq/issues/35"><code>Notice that your BAM file is probably sorted by position, but you&#39;re not using the -r pos option. That will most likely result in bogus output.</code></a> 我们需要设置<code>htseq-count</code>的<code>-r pos</code>参数，或者在对bam文件进行排序时，保留按<code>name</code>进行排序。</p><pre class="line-numbers language-none"><code class="language-none">Usage: samtools sort [options...] [in.bam]Options:  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)  -u         Output uncompressed data (equivalent to -l 0)  -m INT     Set maximum memory per thread; suffix K&#x2F;M&#x2F;G recognized [768M]  -M         Use minimiser for clustering unaligned&#x2F;unplaced reads  -K INT     Kmer size to use for minimiser [20]  -n         Sort by read name (not compatible with samtools index command)  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)  -o FILE    Write final output to FILE rather than standard output  -T PREFIX  Write temporary files to PREFIX.nnnn.bam  --no-PG    do not add a PG line      --input-fmt-option OPT[&#x3D;VAL]               Specify a single input file format option in the form               of OPTION or OPTION&#x3D;VALUE  -O, --output-fmt FORMAT[,OPT[&#x3D;VAL]]...               Specify output format (SAM, BAM, CRAM)      --output-fmt-option OPT[&#x3D;VAL]               Specify a single output file format option in the form               of OPTION or OPTION&#x3D;VALUE      --reference FILE               Reference sequence FASTA FILE [null]  -@, --threads INT               Number of additional threads to use [0]      --write-index               Automatically index the output files [off]      --verbosity INT               Set level of verbosity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&amp;emsp;&amp;emsp;最近在跑RNA-seq碰到一个自己挖的坑，samtools将sam文件转为二进制的bam文件并排序，默认是按照pos进行排序的。htseq-count默认的输入sam|bam是按照name排序的，这样就导致了一个问题，htseq-count会把不在相</summary>
      
    
    
    
    
    <category term="linux" scheme="https://zhangchaofan01.gitee.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux查看GPU状态</title>
    <link href="https://zhangchaofan01.gitee.io/2024/08/25/linux-cha-kan-gpu-zhuang-tai/"/>
    <id>https://zhangchaofan01.gitee.io/2024/08/25/linux-cha-kan-gpu-zhuang-tai/</id>
    <published>2024-08-25T06:36:49.000Z</published>
    <updated>2024-08-25T06:57:28.437Z</updated>
    
    <content type="html"><![CDATA[<p>在日常的训练过程中，你可能需要经常查看当前GPU的使用状态(类似于Linux的Top)。有很多命令可以做到。</p><h3 id="1-nvidia-smi"><a href="#1-nvidia-smi" class="headerlink" title="1. nvidia-smi"></a>1. nvidia-smi</h3><p>&emsp;&emsp;这个命令是基础，一般你系统装完CUDA都会有。这里详细的记录了当前系统的GPU数量和相应GPU的具体信息，比如这里只有一张3090显卡，他的满载功耗为350W，显存为24G，当前正在运行一个任务，性能占用为14%。</p><pre class="line-numbers language-none"><code class="language-none">Sun Aug 25 14:44:25 2024       +-----------------------------------------------------------------------------+| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;||   0  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N&#x2F;A ||  0%   49C    P2   112W &#x2F; 350W |   1639MiB &#x2F; 24576MiB |     14%      Default ||                               |                      |                  N&#x2F;A |+-------------------------------+----------------------+----------------------+                                                                               +-----------------------------------------------------------------------------+| Processes:                                                                  ||  GPU   GI   CI        PID   Type   Process name                  GPU Memory ||        ID   ID                                                   Usage      ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;||    0   N&#x2F;A  N&#x2F;A    723829      C   python                           1637MiB |+-----------------------------------------------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;但是<code>nvidia-smi</code>只显示你运行命令时刻的GPU状态，你可以使用<code>watch</code>获得显卡每个时刻的状态：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 这里的1 是 每一秒刷新的意思watch -n 1 nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-gpustate"><a href="#2-gpustate" class="headerlink" title="2. gpustate"></a>2. gpustate</h3><p>&emsp;&emsp;你也可以使用<code>gpustate</code>命令来获取简洁的状态，也可以配合<code>watch</code>命令获得长时间的状态。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 首先得安装gpustatepip intall gpustategpustate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">AMP Sun Aug 25 14:49:10 2024  510.60.02[0] NVIDIA GeForce RTX 3090 | 44°C,   7 % |  1639 &#x2F; 24576 MB | chaofan(1637M)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-nvitop"><a href="#3-nvitop" class="headerlink" title="3. nvitop"></a>3. nvitop</h3><p>&emsp;&emsp;我最喜欢的则是<code>nvitop</code>,他的输出类似于<code>nvidia-smi</code>，但输出信息更丰富，会出来一个类似<code>top</code>命令的窗口，自动更新当前GPU+CPU状态。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 首先得安装</span>pip install nvitop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAF7Ox0"><img src="https://s21.ax1x.com/2024/08/25/pAF7Ox0.png" alt="pAF7Ox0.png"></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在日常的训练过程中，你可能需要经常查看当前GPU的使用状态(类似于Linux的Top)。有很多命令可以做到。&lt;/p&gt;
&lt;h3 id=&quot;1-nvidia-smi&quot;&gt;&lt;a href=&quot;#1-nvidia-smi&quot; class=&quot;headerlink&quot; title=&quot;1. nvi</summary>
      
    
    
    
    
    <category term="linux" scheme="https://zhangchaofan01.gitee.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Circos example</title>
    <link href="https://zhangchaofan01.gitee.io/2023/12/29/circos-example/"/>
    <id>https://zhangchaofan01.gitee.io/2023/12/29/circos-example/</id>
    <published>2023-12-29T12:54:29.000Z</published>
    <updated>2023-12-29T12:55:26.709Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Circos流程记录"><a href="#Circos流程记录" class="headerlink" title="Circos流程记录"></a>Circos流程记录</h1><p>&emsp;&emsp;最近要用到Circos进行绘图，因此进行记录，方便下次绘图。</p><h2 id="0-软件安装"><a href="#0-软件安装" class="headerlink" title="0. 软件安装"></a>0. 软件安装</h2><p>&emsp;&emsp;<code>Circos</code>基于<code>Perl</code>，所以我们需要进行大量<code>Perl</code>包的安装。当然，秉着赌狗的心理，我们看看能不能直接通过<code>conda</code>装。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># conda新建名为 Circos 的环境(每次安装独立的软件时，都建议新建一个conda环境安装，不容易出现什么安装冲突)conda create -n Circos# 激活环境conda activate Circos# 通过bioconda源搜索circos，看看有哪些版本conda search circos -c bioconda# 这里我们安装最新的 0.69.9conda install circos&#x3D;0.69.9 -c bioconda# 这里没有报错，直接输入 y 进行安装# conda安装后 检查是否有依赖缺失circos --modules<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里我们缺少<code>GD</code>和<code>GD::Polyline</code>模块。</p><p><a href="https://imgse.com/i/piT0g76"><img src="https://s11.ax1x.com/2023/12/21/piT0g76.png" alt="piT0g76.png"></a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 通过 conda 安装 libgd 依赖conda install -c fastchan libgd# 通过 conda 安装 perl-gd (perl的gd模块)conda install -c bioconda perl-gd# 如果libwebp这个版本装不上，就直接把版本号去掉安装，然后在conda这个环境的lib文件夹下 &quot;骗软件&quot;# ln -s libwebp.so.7 libwebp.so.6conda install -c conda-forge libwebp&#x3D;0.5.2# 最后检查一遍，一般help文档能出来就说明装成功了circos -h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/piTB1UK"><img src="https://s11.ax1x.com/2023/12/21/piTB1UK.md.png" alt="piTB1UK.md.png"></a></p><h2 id="1-Circos的使用"><a href="#1-Circos的使用" class="headerlink" title="1. Circos的使用"></a>1. Circos的使用</h2><h3 id="1-1-绘制染色体-karyotype"><a href="#1-1-绘制染色体-karyotype" class="headerlink" title="1.1 绘制染色体(karyotype)"></a>1.1 绘制染色体(karyotype)</h3><p>&emsp;&emsp;我们首先需要准备一个<code>karyotype</code>文件，这个文件描述了所绘制染色体的基本信息。这个文件由七列构成，无表头，任意空白字符分割即可。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">faidx ..&#x2F;nextDevono.fa -i chromsizes | sort -nr -k2 | awk &#39;&#123;print &quot;chr&quot;, &quot;-&quot;, $1,NR,&quot;0&quot;,$2, &quot;169,69,255&quot;&#125;&#39; &gt; karyotype.txtfaidx &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;Z7.fa -i chromsizes | sort -n -k2 | awk &#39;&#123;print &quot;chr&quot;, &quot;-&quot;, $1,13-NR,&quot;0&quot;,$2, &quot;6,97,118&quot;&#125;&#39; &gt;&gt; karyotype.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;这里我们的结果文件如下所示:</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>karyotype.txt</span></div><code class="language-txt"># 这里前两列是karyotype固定的，代表绘制染色体# 第三列是染色体ID，也是其他配置文件的坐标锚点# 第四列是具体展示在图上的染色体名称# 第五、六列是染色体起始、终止位置 起着展示染色体长度的信息# 第七列则是染色体方块的颜色，这里名称为RGB颜色chr - ctg000130 1 0 6741225 169,69,255chr - ctg000050 2 0 5683444 169,69,255chr - ctg000120 3 0 3309307 169,69,255chr - ctg000020 4 0 3201804 169,69,255chr - ctg000100 5 0 2838009 169,69,255chr - ctg000040 6 0 2659068 169,69,255chr - ctg000030 7 0 2635818 169,69,255chr - ctg000110 8 0 2444020 169,69,255chr - ctg000010 9 0 2417686 169,69,255chr - ctg000000 10 0 1868462 169,69,255chr - ctg000090 11 0 561846 169,69,255chr - ctg000070 12 0 75900 169,69,255chr - ctg000080 13 0 72450 169,69,255chr - ctg000060 14 0 61073 169,69,255chr - 12 12 0 416412 6,97,118chr - 11 11 0 561391 6,97,118chr - 10 10 0 1841737 6,97,118chr - 9 9 0 2401432 6,97,118chr - 8 8 0 2464928 6,97,118chr - 7 7 0 2519108 6,97,118chr - 6 6 0 2544158 6,97,118chr - 5 5 0 2863349 6,97,118chr - 4 4 0 3085453 6,97,118chr - 3 3 0 3269484 6,97,118chr - 2 2 0 5542836 6,97,118chr - 1 1 0 6770053 6,97,118<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;我们先生成一个染色体的配置文件<code>ideogram.conf</code>，将以下内容放到这个文件中，展示我们上面生成的染色体形状。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>ideogram.conf</span></div><code class="language-txt">#指定染色体文件（绝对/相对路径+文件名）##########################################################################&lt;ideogram>                #这是定义染色体相关参数的标签，相当于HTML的一个条目&lt;spacing>                 #定义染色体间隙宽度的标签，以&lt;/spacing>，其中包括要设置的参数default = 0.006r          #r指的是圆的周长，设置0.5%圆的周长为间隙&lt;pairwise 1;ctg000130>       #可以用&lt;pairwise>标签特别指定某些染色体的间隙（用的是ID），因为在大多数文章中，都会留一个大间隙，来放labelspacing = 5r            #这里20r表示是相对default = 0.005r的20倍，也就是10%的圆的周长&lt;/pairwise>              #标签都要以&lt;/>结尾，&lt;pairwise 12;ctg000060>spacing = 5r&lt;/pairwise>&lt;/spacing>                #间隙定义结束，下面是对染色体样式的调整radius           = 0.65r  #轮廓的位置，这里的r指的是半径，由圆心到圆周上范围依次是0-1r，，超出部分将不再显示。thickness        = 20p    #染色体整体的宽度，这里p指的是像素大小，也可以用r表示，1r=1500pfill             = yes    #是否为染色体填充颜色，如果为yes，自动用第七列定义的颜色着色stroke_color     = dgrey  #染色体边框的颜色，支持多种格式的输入，如：red或255,182,106stroke_thickness = 2p     #染色体边框的粗细show_label     = yes # 展示染色体IDlabel_with_tag = yes # tag 标识是否包含到 label 中label_font     = bold # label 的字体label_center   = yeslabel_size     = 32plabel_color    = greylabel_parallel = yes # label方向， 是否与圆外圈平行label_case     = upper # label 的大小写：upper,lowerlabel_radius = 0.98r&lt;/ideogram>               #定义染色体属性的标签结束##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们再配置一个基础的运行<code>conf</code>文件: Alternaria.conf</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>Alternaria.conf</span></div><code class="language-txt">##########################################################################chromosomes_units           = 100000 # 设置u的单位，1u = 100kbpkaryotype = ./karyotype.txt&lt;&lt;include ideogram.conf>>#下面是每次都要复制粘贴上去的，他们属于circos自带的配置文件，用于调用颜色，距离，报错等信息&lt;image>                    #注意路径&lt;&lt;include etc/image.conf>> #注意引用外部配置文件需要使用&lt;&lt;#>>&lt;/image>&lt;&lt;include etc/colors_fonts_patterns.conf>> &lt;&lt;include etc/housekeeping.conf>>##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">circos -conf Alternaria.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们得到了初步的染色体结果:</p><p><a href="https://imgse.com/i/pi7E1Pg"><img src="https://s11.ax1x.com/2023/12/22/pi7E1Pg.png" alt="pi7E1Pg.png"></a></p><p>我们再配置一个<code>ticks.conf</code>文件，加上染色体ID及刻度线。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>ticks.conf</span></div><code class="language-txt">########################################################################### 配置染色体标签和刻度线show_ticks          = yes  #选择yes表示要显示刻度线show_tick_labels    = yes  #选择yes表示要显示刻度线的数值#定义刻度线的整体位置与形状&lt;ticks>                    #刻度线的转用标签，但凡是复数出现的，其下面的参数都表示全局参数，像下面的&lt;tick>单数形式，都表示局部参数radius           = 1r      #刻度线的位置，1r为最远距离，超过1r不再显示color            = blackthickness        = 3pmultiplier       = 1e-6    #刻度标签的大小，这里我们一个标签=10u，这里大刻度就是1=1M,如果multiplier=1e-5,那这里的刻度就是10format           = %d      #然后以整数的形式标记在刻度线上#定义小的刻度线，且不显示数值&lt;tick>spacing        = 1u        #最开始我们定义1u = multiplier = 100000，表示一个小刻度为100kbpsize           = 8pshow_label     = no        # 是否展示小刻度线&lt;/tick>#定义大的刻度线，显示数值&lt;tick>spacing        = 10u # 这里设置一个大刻度为10个小刻度size           = 20pshow_label     = yeslabel_size     = 30plabel_offset   = 10p      #设置数值和刻度线之间的间隔format         = %d&lt;/tick>&lt;/ticks>##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们再在Alternaria.conf中加入这个<code>ticks.conf</code></p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>Alternaria.conf</span></div><code class="language-txt">##########################################################################chromosomes_units           = 100000 # 设置u的单位，1u = 100kbpkaryotype = ./karyotype.txt&lt;&lt;include ideogram.conf>>&lt;&lt;include ticks.conf>>#下面是每次都要复制粘贴上去的，他们属于circos自带的配置文件，用于调用颜色，距离，报错等信息&lt;image>                    #注意路径&lt;&lt;include etc/image.conf>> #注意引用外部配置文件需要使用&lt;&lt;#>>&lt;/image>&lt;&lt;include etc/colors_fonts_patterns.conf>> &lt;&lt;include etc/housekeeping.conf>>##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 运行circos -conf Alternaria.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7EBiF"><img src="https://s11.ax1x.com/2023/12/22/pi7EBiF.png" alt="pi7EBiF.png"></a></p><h3 id="1-2-外圈展示GC含量"><a href="#1-2-外圈展示GC含量" class="headerlink" title="1.2 外圈展示GC含量"></a>1.2 外圈展示GC含量</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">faidx ..&#x2F;nextDevono.fa -i chromsizes &gt;  nextDevono.txtfaidx &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;Z7.fa -i chromsizes &gt;  Z7.txtbedtools makewindows -g nextDevono.txt -w 20000 &gt; gaisen.20kb.winbedtools makewindows -g Z7.txt -w 20000 | sort -n -k 1 -n -k 2  &gt; Z7.20kb.winbedtools nuc -fi ..&#x2F;nextDevono.fa -bed gaisen.20kb.win | \cut -f 1-3,5 | grep -v &quot;#&quot; | \awk -vFS&#x3D;&quot;\t&quot; -vOFS&#x3D;&quot;\t&quot; &#39;&#123;print $1,$2,$3,$4*(100)-50&#125;&#39; &gt; gc.density.txtbedtools nuc -fi &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;Z7.fa -bed Z7.20kb.win | \cut -f 1-3,5 | grep -v &quot;#&quot; | \awk -vFS&#x3D;&quot;\t&quot; -vOFS&#x3D;&quot;\t&quot; &#39;&#123;print $1,$2,$3,$4*(100)-50&#125;&#39; &gt;&gt; gc.density.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们另外生成一个<code>GC.conf</code>文件。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>GC.conf</span></div><code class="language-txt">&lt;plots>    &lt;plot>        type      = line #设定显示类型        thickness = 2p #折线图的粗细        max_gap = 1u         file    = gc.density.txt #输入数据        color   = vdgrey #折线颜色        min     = -5 #环道内圈代表的数值下限，超出下限的数值不会显示，下同        max     = 5 #环道外圈代表的数值上限        r0      = 1.06r #环道内圈位置        r1      = 1.18r #环道外圈位置        fill_color = vdgrey_a3        &lt;rules>            &lt;rule> #设置折线图大于0部分显示为蓝色                condition    = var(value) > 0                color        = blue                fill_color   = blue_a1            &lt;/rule>            &lt;rule> #设置折线图小于0部分显示为红色                condition    = var(value) &lt; 0                color        = red                fill_color   = red_a1            &lt;/rule>        &lt;/rules>    &lt;/plot>&lt;/plots><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7mvBn"><img src="https://s11.ax1x.com/2023/12/22/pi7mvBn.png" alt="pi7mvBn.png"></a></p><h3 id="1-3-外圈展示基因含量"><a href="#1-3-外圈展示基因含量" class="headerlink" title="1.3 外圈展示基因含量"></a>1.3 外圈展示基因含量</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">grep &#39;[[:blank:]]gene[[:blank:]]&#39; ..&#x2F;fungap_out.gff3 | \awk &#39;&#123;print $1&quot;\t&quot;$4&quot;\t&quot;$5&#125;&#39; |bedtools coverage -a gaisen.20kb.win -b - | \cut -f 1-4 &gt; gene.density.txtgrep &#39;[[:blank:]]gene[[:blank:]]&#39; &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;2023-10-05.corrected.gff3 | \awk &#39;&#123;print $1&quot;\t&quot;$4&quot;\t&quot;$5&#125;&#39; |bedtools coverage -a Z7.20kb.win -b - | \cut -f 1-4 &gt;&gt; gene.density.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们把gene_density信息也加到<code>GC.conf</code>文件。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>GC.conf</span></div><code class="language-txt">&lt;plots>    &lt;plot>        type      = line #设定显示类型        thickness = 2p #折线图的粗细        max_gap = 1u         file    = gc.density.txt #输入数据        color   = vdgrey #折线颜色        min     = -5 #环道内圈代表的数值下限，超出下限的数值不会显示，下同        max     = 5 #环道外圈代表的数值上限        r0      = 1.08r #环道内圈位置        r1      = 1.16r #环道外圈位置        fill_color = vdgrey_a3        &lt;rules>            &lt;rule> #设置折线图大于0部分显示为蓝色                condition    = var(value) > 0                color        = blue                fill_color   = blue_a1            &lt;/rule>            &lt;rule> #设置折线图小于0部分显示为红色                condition    = var(value) &lt; 0                color        = red                fill_color   = red_a1            &lt;/rule>        &lt;/rules>    &lt;/plot>    ########################################## NEW ##########################    &lt;plot>    type      = histogram #设定显示类型    thickness = 2p #折线图的粗细file = gene.density.txtr0 = 1.18rr1 = 1.26rcolor = 114,176,67    &lt;/plot>    ########################################## NEW ##########################&lt;/plots><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7uvF0"><img src="https://s11.ax1x.com/2023/12/22/pi7uvF0.png" alt="pi7uvF0.png"></a></p><h3 id="1-4-展示共线性基因"><a href="#1-4-展示共线性基因" class="headerlink" title="1.4 展示共线性基因"></a>1.4 展示共线性基因</h3><p>&emsp;&emsp;我们首先通过<code>JCVI</code>鉴定两个基因组上的共线性区域，通过<code>simple</code>文件提取共线性区域。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python -m jcvi.formats.gff bed --type&#x3D;mRNA --key&#x3D;ID Gaisen.gff &gt; Gaisen.bedpython -m jcvi.formats.gff bed --type&#x3D;mRNA --key&#x3D;ID Z7.gff &gt; Z7.bed# 鉴定两个基因组间的共线性基因python -m jcvi.compara.catalog ortholog --dbtype prot Z7 Gaisen --cscore&#x3D;.98 --no_strip_names  # 创建simple文件python -m jcvi.compara.synteny screen --minspan&#x3D;25 --simple Z7.Gaisen.anchors Z7.Gaisen.simple# 从gff文件中提取simple block的区间python jcvi2link.py &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;2023-10-05.corrected.gff3 ..&#x2F;fungap_out.gff3 &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;07.genome_assemble&#x2F;07.JCVI&#x2F;Z7.Gaisen.simple link.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>jcvi2link.py</span></div><code class="language-python"><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span>exit <span class="token keyword">def</span> <span class="token function">gene_dic</span><span class="token punctuation">(</span>gff<span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>gff<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"#"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"mRNA"</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> tmp_dic<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">5</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"python </span><span class="token interpolation"><span class="token punctuation">&#123;</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string"> [Z7_gff] [Gaisen_gff] [simple_file] [link_txt]"</span></span><span class="token punctuation">)</span>    Z7_dic <span class="token operator">=</span> gene_dic<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    Gaisen_dic <span class="token operator">=</span> gene_dic<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    colors <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"+"</span><span class="token punctuation">:</span><span class="token string">"62,169,8"</span><span class="token punctuation">,</span><span class="token string">"-"</span><span class="token punctuation">:</span><span class="token string">"65,182,230"</span><span class="token punctuation">&#125;</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>        Z7_min <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Z7_max <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Gaisen_min <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Gaisen_max <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span>Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Z7_min<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Z7_max<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Gaisen_min<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Gaisen_max<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\tcolor="</span><span class="token operator">+</span>colors<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>得到这样的结果文件:<br><a href="https://imgse.com/i/pi7BPdx"><img src="https://s11.ax1x.com/2023/12/23/pi7BPdx.png" alt="pi7BPdx.png"></a></p><p>我们再配置<code>link.conf</code>文件:</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>link.conf</span></div><code class="language-txt">&lt;links>&lt;link>file          = link.txtribbon        = yesradius        = 0.95rbezier_radius = 0rflat   = yes # 强制条带不扭转bezier_radius_purity = 0.5thickness     = 1&lt;/link>&lt;/links><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7Dp9S"><img src="https://s11.ax1x.com/2023/12/23/pi7Dp9S.png" alt="pi7Dp9S.png"></a></p><p>当然，还有很多进阶的配置，后面慢慢改。</p><h3 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程:"></a><strong>参考教程</strong>:</h3><ul><li><a href="https://irenexzwen.gitbooks.io/hello-gitbook/content">https://irenexzwen.gitbooks.io/hello-gitbook/content</a></li><li><a href="https://www.jianshu.com/p/9c0d2b9d724e">https://www.jianshu.com/p/9c0d2b9d724e</a></li><li><a href="https://www.jianshu.com/p/e63292c1001c">https://www.jianshu.com/p/e63292c1001c</a></li><li><a href="https://www.jianshu.com/p/78f4ae15d22a">https://www.jianshu.com/p/78f4ae15d22a</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Circos流程记录&quot;&gt;&lt;a href=&quot;#Circos流程记录&quot; class=&quot;headerlink&quot; title=&quot;Circos流程记录&quot;&gt;&lt;/a&gt;Circos流程记录&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;最近要用到Circos进行绘图，因此进行记录，方便下</summary>
      
    
    
    
    
    <category term="Genome" scheme="https://zhangchaofan01.gitee.io/tags/Genome/"/>
    
    <category term="shell" scheme="https://zhangchaofan01.gitee.io/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>SYRI Synteny and Rearrangement Identifier</title>
    <link href="https://zhangchaofan01.gitee.io/2023/12/29/syri-synteny-and-rearrangement-identifier/"/>
    <id>https://zhangchaofan01.gitee.io/2023/12/29/syri-synteny-and-rearrangement-identifier/</id>
    <published>2023-12-29T12:41:43.000Z</published>
    <updated>2023-12-29T13:09:46.534Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用SYRI鉴定基因组变异及可视化"><a href="#使用SYRI鉴定基因组变异及可视化" class="headerlink" title="使用SYRI鉴定基因组变异及可视化"></a>使用SYRI鉴定基因组变异及可视化</h1><h3 id="1-调整两条比对基因组的染色体方向"><a href="#1-调整两条比对基因组的染色体方向" class="headerlink" title="1.调整两条比对基因组的染色体方向"></a>1.调整两条比对基因组的染色体方向</h3><p><code>SYRI</code>对比对的基因组有非常严格的要求：</p><ol><li>两个基因组的染色体ID必须一一对应(同源染色体ID必须一致，染色体数量也必须一致，染色体ID不能是数字)； </li><li>同源染色体strand方向必须一致。</li></ol><p>&emsp;&emsp;我们根据之前已有的共线性关系，手动生成一个染色体操作表格，然后用<code>pythpn</code>代码进行ID替换与strand方向的改变。</p><p>&emsp;&emsp;这里<code>RAW_ID</code>是其中一个样基因组染色体ID，<code>NEW_ID</code>是新的染色体ID，这个与另外一个样本的染色体ID是一一对应的(另外一个样本的染色体ID就是这种1,2,3,4..11), <code>STRAND</code>为链的方向，<code>+</code>代表两个样本这条染色体方向一致，<code>-</code>代表方向相反，需手动生成反向互补链。<br><strong>替换表格</strong>:</p><table><thead><tr><th>RAW_ID</th><th>NEW_ID</th><th>STRAND</th></tr></thead><tbody><tr><td>ctg000130</td><td>Chr1</td><td>+</td></tr><tr><td>ctg000050</td><td>Chr2</td><td>-</td></tr><tr><td>ctg000120</td><td>Chr3</td><td>+</td></tr><tr><td>ctg000020</td><td>Chr4</td><td>-</td></tr><tr><td>ctg000100</td><td>Chr5</td><td>+</td></tr><tr><td>ctg000040</td><td>Chr6</td><td>-</td></tr><tr><td>ctg000030</td><td>Chr7</td><td>+</td></tr><tr><td>ctg000110</td><td>Chr8</td><td>-</td></tr><tr><td>ctg000010</td><td>Chr9</td><td>+</td></tr><tr><td>ctg000000</td><td>Chr10</td><td>-</td></tr><tr><td>ctg000090</td><td>Chr11</td><td>-</td></tr></tbody></table><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">def</span> <span class="token function">read_fa</span><span class="token punctuation">(</span>fa_file<span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fa_file<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'\n'</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'>'</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span>t_lst<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>t_lst<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> t_lst <span class="token keyword">in</span> tmp_dic<span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> tmp_dic<span class="token keyword">def</span> <span class="token function">reverse_complement</span><span class="token punctuation">(</span>dna_sequence<span class="token punctuation">)</span><span class="token punctuation">:</span>    complement_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token string">'T'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">:</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">:</span> <span class="token string">'G'</span><span class="token punctuation">,</span> <span class="token string">'G'</span><span class="token punctuation">:</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">:</span><span class="token string">'N'</span><span class="token punctuation">&#125;</span>    reverse_sequence <span class="token operator">=</span> dna_sequence<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    complement_sequence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>complement_dict<span class="token punctuation">[</span>base<span class="token punctuation">]</span> <span class="token keyword">for</span> base <span class="token keyword">in</span> reverse_sequence<span class="token punctuation">)</span>    <span class="token keyword">return</span> complement_sequence<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"python </span><span class="token interpolation"><span class="token punctuation">&#123;</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string"> [raw_fa] [info_tab] [paired_fa]"</span></span><span class="token punctuation">)</span>        info_tab <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"RAW_ID"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>        info_tab<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>     raw_fas <span class="token operator">=</span> read_fa<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> seq_id <span class="token keyword">in</span> info_tab<span class="token punctuation">:</span>        <span class="token keyword">if</span> info_tab<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'+'</span><span class="token punctuation">:</span>            tmp_seq <span class="token operator">=</span> raw_fas<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 输出反向互补链</span>            tmp_seq <span class="token operator">=</span> reverse_complement<span class="token punctuation">(</span>raw_fas<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">">"</span><span class="token operator">+</span>info_tab<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span> <span class="token operator">+</span> tmp_seq<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>                ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 直接运行python pair_chr.py ..&#x2F;nextDevono.fa info.tab gaisen.fa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-SYRI鉴定SV并可视化"><a href="#2-SYRI鉴定SV并可视化" class="headerlink" title="2.SYRI鉴定SV并可视化"></a>2.SYRI鉴定SV并可视化</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># nucmer比对nucmer -c 100 -l 50 -t 8 -p Z7.gaisen Z7.fa gaisen.fa# 比对结果过滤delta-filter -m -i 90 -l 100 Z7.gaisen.delta &gt; Z7.gaisen.filtered.delta# 比对格式转换show-coords -THrd Z7.gaisen.filtered.delta &gt; Z7.gaisen.filtered.coords# SYRI鉴定基因组变异python3 &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;miniconda&#x2F;envs&#x2F;syri_env&#x2F;bin&#x2F;syri -s &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;miniconda&#x2F;envs&#x2F;syri_env&#x2F;bin&#x2F;show-snps -c Z7.gaisen.filtered.coords -d Z7.gaisen.filtered.delta -r Z7.fa -q gaisen.fa --prefix Z7.gaisen.# 生成基因组信息文件，tab分隔(详细内容见代码框下)vi genome.txt# plotsr可视化 -H：输出图形高 -W： 输出图形高plotsr \    --sr Z7.gaisen.syri.out \    --genomes genome.txt -o genome.pdf -b pdf -H 16 -W 12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>genome.txt</code>文件内容：</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>genome.txt</span></div><code class="language-txt">#filenametagsZ7.faZ7lw:2gaisen.faGaisenlw:2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/piL4hZt"><img src="https://s11.ax1x.com/2023/12/29/piL4hZt.png" alt="piL4hZt.png"></a></p><p>&emsp;&emsp;嗯，结果看着还行。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用SYRI鉴定基因组变异及可视化&quot;&gt;&lt;a href=&quot;#使用SYRI鉴定基因组变异及可视化&quot; class=&quot;headerlink&quot; title=&quot;使用SYRI鉴定基因组变异及可视化&quot;&gt;&lt;/a&gt;使用SYRI鉴定基因组变异及可视化&lt;/h1&gt;&lt;h3 id=&quot;1-调整两</summary>
      
    
    
    
    
    <category term="Genome" scheme="https://zhangchaofan01.gitee.io/tags/Genome/"/>
    
    <category term="Python" scheme="https://zhangchaofan01.gitee.io/tags/Python/"/>
    
    <category term="linux" scheme="https://zhangchaofan01.gitee.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>ncRNA-annotation</title>
    <link href="https://zhangchaofan01.gitee.io/2023/10/02/ncrna-annotation/"/>
    <id>https://zhangchaofan01.gitee.io/2023/10/02/ncrna-annotation/</id>
    <published>2023-10-02T08:03:11.000Z</published>
    <updated>2023-10-02T12:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-conda-环境配置"><a href="#1-conda-环境配置" class="headerlink" title="1.conda 环境配置"></a>1.conda 环境配置</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># conda envconda create -n ncRNAconda activate ncRNA# download infernalconda install -c bioconda infernal<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-注释-DB-配置"><a href="#2-注释-DB-配置" class="headerlink" title="2.注释 DB 配置"></a>2.注释 DB 配置</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#  download Rfam datacd &#x2F;data&#x2F;chaofan&#x2F;sourcemkdir 04.ncRNA &amp;&amp; cd 04.ncRNAwget ftp:&#x2F;&#x2F;ftp.ebi.ac.uk&#x2F;pub&#x2F;databases&#x2F;Rfam&#x2F;CURRENT&#x2F;Rfam.cm.gzgzip -d Rfam.cm.gzwget ftp:&#x2F;&#x2F;ftp.ebi.ac.uk&#x2F;pub&#x2F;databases&#x2F;Rfam&#x2F;CURRENT&#x2F;Rfam.clanin# cmpress 索引cmpress Rfam.cm# 从https:&#x2F;&#x2F;rfam.org&#x2F;search&#x2F;type下载相应RF-number对应的注释# 地址为: &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;RF.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-开始注释-ncRNA"><a href="#3-开始注释-ncRNA" class="headerlink" title="3.开始注释 ncRNA"></a>3.开始注释 ncRNA</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 开始注释cd &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;13.Alternaria_Z7&#x2F;08.gaisen_genome&#x2F;l0cmscan -Z 66 --cut_ga --rfam --nohmmonly --tblout gaisen.asm.primer.tblout  \  --fmt 2 --cpu 40 --clanin &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.clanin \  &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.cm gaisen.asm.primer.fa &gt; gaisen.asm.primer.cmscancd &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;13.Alternaria_Z7&#x2F;08.gaisen_genome&#x2F;nextDenovocmscan -Z 66 --cut_ga --rfam --nohmmonly --tblout nextDevono.tblout  \  --fmt 2 --cpu 40 --clanin &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.clanin \  &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.cm nextDevono.fa &gt; nextDevono.cmscan# -Z：根据基因组大小来定，基因组大小的2倍，Mb单位，选一个整数# –tblout 指定table格式输出文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-注释结果整理"><a href="#4-注释结果整理" class="headerlink" title="4.注释结果整理"></a>4.注释结果整理</h2><p>保留非重叠区及重叠区最佳 hit(可以不做)</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">awk &#39;BEGIN&#123;OFS&#x3D;&quot;\t&quot;;&#125;&#123;if(FNR&#x3D;&#x3D;1) print &quot;target_name\taccession\tquery_name\tquery_start\tquery_end\tstrand\tscore\tEvalue&quot;; if(FNR&gt;2 &amp;&amp; $20!&#x3D;&quot;&#x3D;&quot; &amp;&amp; $0!~&#x2F;^#&#x2F;) print $2,$3,$4,$10,$11,$12,$17,$18; &#125;&#39; nextDevono.tblout &gt; nextDevono.tblout.xls<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注释结果整理为 gff 格式, 有些具体的细节我按照自己喜欢的格式进行生成，也可以进行调整。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python &#x2F;data&#x2F;chaofan&#x2F;scripts&#x2F;infernal-tblout2gff.py nextDevono.tblout nextDevono.infernal.ncRNA.gff3 &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;RF.txtpython &#x2F;data&#x2F;chaofan&#x2F;scripts&#x2F;infernal-tblout2gff.py gaisen.asm.primer.tblout gaisen.asm.primer.infernal.ncRNA.gff3 &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;RF.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="5-所用脚本"><a href="#5-所用脚本" class="headerlink" title="5.所用脚本"></a>5.所用脚本</h2><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>infernal-tblout2gff.py</span></div><code class="language-python"><span class="token comment">#!/data/chaofan/software/miniconda/bin/python</span><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">import</span> os<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Usage: python </span><span class="token interpolation"><span class="token punctuation">&#123;</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string"> [infernal-tblout] [ouf_gff] [RF.txt]"</span></span><span class="token punctuation">)</span>    ouf_lines <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"Input file not exists!"</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"RF-number info not exists!"</span><span class="token punctuation">)</span>    RF_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"Gene;"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> <span class="token string">";"</span> <span class="token keyword">in</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'#'</span><span class="token punctuation">,</span> <span class="token string">'\n'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'='</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        start_end <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span><span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        t <span class="token operator">=</span> <span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"cmscan"</span><span class="token punctuation">,</span> RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> start_end<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> start_end<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> \            tmp<span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tmp<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">"Description="</span><span class="token operator">+</span>tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">":"</span><span class="token operator">+</span><span class="token string">"_"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        ouf_lines<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>    ouf_lines <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>ouf_lines<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> s<span class="token punctuation">:</span><span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token builtin">int</span><span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    t_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token comment"># add_id</span>    <span class="token keyword">for</span> order <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ouf_lines<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> t_dic<span class="token punctuation">:</span>            t_dic<span class="token punctuation">[</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            t_dic<span class="token punctuation">[</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>        ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"ID="</span><span class="token operator">+</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"_"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>t_dic<span class="token punctuation">[</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>zfill<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">+</span>\            <span class="token string">"; "</span><span class="token operator">+</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"\t"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>t_l<span class="token punctuation">)</span> <span class="token keyword">for</span> t_l <span class="token keyword">in</span> ouf_lines<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp;&ensp;如发现任何问题，恳请联系我纠正。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-conda-环境配置&quot;&gt;&lt;a href=&quot;#1-conda-环境配置&quot; class=&quot;headerlink&quot; title=&quot;1.conda 环境配置&quot;&gt;&lt;/a&gt;1.conda 环境配置&lt;/h2&gt;&lt;pre class=&quot;line-numbers language</summary>
      
    
    
    
    
    <category term="Genome" scheme="https://zhangchaofan01.gitee.io/tags/Genome/"/>
    
    <category term="ncRNA" scheme="https://zhangchaofan01.gitee.io/tags/ncRNA/"/>
    
  </entry>
  
  <entry>
    <title>manual_genome</title>
    <link href="https://zhangchaofan01.gitee.io/2023/08/25/manual-genome/"/>
    <id>https://zhangchaofan01.gitee.io/2023/08/25/manual-genome/</id>
    <published>2023-08-25T03:02:02.000Z</published>
    <updated>2023-08-25T03:35:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1.引言"></a>1.引言</h2><p>&ensp;&ensp;&ensp;&ensp;我们在基因组的组装过程中可能需要手动检查的情况，直接对初始的组装结果进行手动矫正，而这个脚本就是用来做这个的。<br>这些都是在原序列的基础上操作的，我检查了几个例子是没问题的，但是用的时候还是要注意隐藏的 BUG。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Usage: python removeDNA_fromBED.py [raw_contig] [dispose.bed] [disposed_contig]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-输入输出"><a href="#2-输入输出" class="headerlink" title="2.输入输出"></a>2.输入输出</h2><p>输入的 bed 文件根据操作的不同，有不同的列数，每个操作都是一行。<br>一共有 4 大类:</p><ul><li>‘D’: Deletion 删除;</li><li>‘RC’: Reverse_Complement 反向互补;</li><li>‘I’: Insertion 插入序列，这个操作行有五列，除 le 和<code>D</code>和<code>RC</code>类似的 4 列外，<br>多了第五列用来存放要插入的序列，而且这一行的第二列和第三列应该是一样的。<br>你是插入一个点，比如在 11 位置插入，就是在前 10 个碱基后插入一段序列。</li><li>‘M’: Move 挪动序列，这个操作行有 7 列: Chr start1 end1 M start2 end2 [+|-]<br>你是移动，就会有两个位置嘛，如果第七列为 + 符号，代表把 start1 到 end1 的序列<br>挪动到 start2 和 end2 的位置，这种情况下 start2 是等于 end2 的。这个操作等价与在<br>start1 到 end 的一个删除和在 start2 的一个插入。 如果第七列为 - 符号，则方向<br>相反，把 start2-end2 的序列插入到 start1(=end1)的位置。</li></ul><p>输入 <code>bed</code> 文件示例：</p><pre class="line-numbers language-none"><code class="language-none">contig1110RCcontig11111IZCF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入 <code>fasta</code>文件：</p><pre class="line-numbers language-none"><code class="language-none">&gt;contig1AAAAAAAAAATTTTTTTTTTCCCCCCCCCCGGGGGGGGGG<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输出结果：</p><pre class="line-numbers language-none"><code class="language-none">&gt;contig1TTTTTTTTTTZCFTTTTTTTTTTCCCCCCCCCCGGGGGGGGGG<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-脚本"><a href="#3-脚本" class="headerlink" title="3.脚本"></a>3.脚本</h2><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>manual_genome.py</span></div><code class="language-python"><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">def</span> <span class="token function">reverse_complement</span><span class="token punctuation">(</span>sequence<span class="token punctuation">)</span><span class="token punctuation">:</span>    complement_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token string">'T'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">:</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">:</span> <span class="token string">'G'</span><span class="token punctuation">,</span> <span class="token string">'G'</span><span class="token punctuation">:</span> <span class="token string">'C'</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">:</span> <span class="token string">'t'</span><span class="token punctuation">,</span> <span class="token string">'t'</span><span class="token punctuation">:</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">:</span><span class="token string">'g'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">:</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">:</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'n'</span><span class="token punctuation">:</span> <span class="token string">'n'</span><span class="token punctuation">&#125;</span>    reverse_complement_sequence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>complement_dict<span class="token punctuation">[</span>base<span class="token punctuation">]</span> <span class="token keyword">for</span> base <span class="token keyword">in</span> sequence<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> reverse_complement_sequence<span class="token keyword">def</span> <span class="token function">read_fasta_file</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    fasta_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    current_sequence <span class="token operator">=</span> <span class="token string">""</span>    current_id <span class="token operator">=</span> <span class="token boolean">None</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 处理标识符行</span>                <span class="token keyword">if</span> current_id <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                    fasta_dict<span class="token punctuation">[</span>current_id<span class="token punctuation">]</span> <span class="token operator">=</span> current_sequence                current_id <span class="token operator">=</span> line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>                current_sequence <span class="token operator">=</span> <span class="token string">""</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># 处理序列行</span>                current_sequence <span class="token operator">+=</span> line        <span class="token keyword">if</span> current_id <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            fasta_dict<span class="token punctuation">[</span>current_id<span class="token punctuation">]</span> <span class="token operator">=</span> current_sequence    <span class="token keyword">return</span> fasta_dict<span class="token keyword">def</span> <span class="token function">read_tsv_file</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> fa_dic<span class="token punctuation">)</span><span class="token punctuation">:</span>    tsv_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> line<span class="token punctuation">:</span>  <span class="token comment"># 跳过空行</span>                columns <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>                key <span class="token operator">=</span> columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                <span class="token keyword">if</span> key <span class="token keyword">not</span> <span class="token keyword">in</span> tsv_dict<span class="token punctuation">:</span>                    tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                <span class="token keyword">if</span> columns<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">"M"</span><span class="token punctuation">:</span>                    tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token comment"># move order</span>                    <span class="token comment"># M = insertion + deletion</span>                    <span class="token keyword">if</span> columns<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'+'</span><span class="token punctuation">:</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> \                            fa_dic<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> \                            fa_dic<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment">#</span>    <span class="token keyword">for</span> ctg <span class="token keyword">in</span> tsv_dict<span class="token punctuation">:</span>        tsv_dict<span class="token punctuation">[</span>ctg<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>tsv_dict<span class="token punctuation">[</span>ctg<span class="token punctuation">]</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tsv_dict<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"Usage: python manual_genome.py [raw_contig] [dispose.bed] [disposed_contig]\n\n\n"</span> <span class="token operator">+</span> \            <span class="token string">"Like BED format [1_index]: \nChr\tstart\tEND\tkeyword\nkeyword: 'D': deletion; 'RC' : reverse_complement; "</span> <span class="token operator">+</span> \            <span class="token string">"'M': move seqs from one pos to another pos(in same contig)."</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> \            <span class="token string">"If keyword = 'I', the line with 5 columns: Chr start end I [insertion_seq].\n"</span><span class="token operator">+</span> \            <span class="token string">"If keyword = 'M', the line with 7 columns: Chr start1 end1 M start2 end2 [+|-].\n"</span><span class="token operator">+</span> \            <span class="token string">"If 7thcol in M lines = '+', means move seqs from start1 to start2, else move seqs from start2 to start1\n"</span><span class="token punctuation">)</span>    fa_dic <span class="token operator">=</span> read_fasta_file<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    dispose_dic <span class="token operator">=</span> read_tsv_file<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> fa_dic<span class="token punctuation">)</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> contig <span class="token keyword">in</span> fa_dic<span class="token punctuation">:</span>        raw_Seq <span class="token operator">=</span> fa_dic<span class="token punctuation">[</span>contig<span class="token punctuation">]</span>        gap_bp <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> items <span class="token keyword">in</span> dispose_dic<span class="token punctuation">[</span>contig<span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># Deletion</span>            <span class="token keyword">if</span> items<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"D"</span><span class="token punctuation">:</span>                raw_Seq <span class="token operator">=</span> raw_Seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span> <span class="token operator">+</span> raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token punctuation">]</span>                gap_bp <span class="token operator">+=</span>  <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">print</span><span class="token punctuation">(</span>gap_bp<span class="token punctuation">)</span>            <span class="token comment"># reverse_complement</span>            <span class="token keyword">if</span> items<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"RC"</span><span class="token punctuation">:</span>                raw_Seq <span class="token operator">=</span> raw_Seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span> <span class="token operator">+</span> \                    reverse_complement<span class="token punctuation">(</span>raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                    raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> items<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"I"</span><span class="token punctuation">:</span>                raw_Seq <span class="token operator">=</span> raw_Seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span> <span class="token operator">+</span> \                    items<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">+</span> \                    raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token punctuation">]</span>                gap_bp <span class="token operator">-=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">">"</span><span class="token operator">+</span>contig<span class="token operator">+</span><span class="token string">"\n"</span><span class="token operator">+</span>raw_Seq<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp;&ensp;如发现任何问题，恳请联系我纠正。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1.引言&quot;&gt;&lt;/a&gt;1.引言&lt;/h2&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;我们在基因组的组装过程中可能需要手动检查的情况，直接对初始的组装结果进行手动</summary>
      
    
    
    
    
    <category term="Genome" scheme="https://zhangchaofan01.gitee.io/tags/Genome/"/>
    
    <category term="python" scheme="https://zhangchaofan01.gitee.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Install R-packages from github</title>
    <link href="https://zhangchaofan01.gitee.io/2023/08/14/install-r-packages-from-github/"/>
    <id>https://zhangchaofan01.gitee.io/2023/08/14/install-r-packages-from-github/</id>
    <published>2023-08-14T03:07:58.000Z</published>
    <updated>2023-08-14T03:09:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>一些常用的从 github 上安装 R 包的方法:</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 1. devtoolsinstall.packages(&quot;devtools&quot;, dep&#x3D;TRUE)library(devtools)install_github(&quot;caitiecollins&#x2F;treeWAS&quot;, build_vignettes &#x3D; TRUE)# 2. githubinstalllibrary(githubinstall)install_github(&#39;hadlley&#x2F;dplyr&#39;)# 3. remotesinstall.packages(&#39;remotes&#39;)remotes::install_git(&quot;https:&#x2F;&#x2F;hub.fastgit.xyz&#x2F;yzhlinscau&#x2F;AFEchidna.git&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>本人经常用第三种方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一些常用的从 github 上安装 R 包的方法:&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-shell&quot; data-language=&quot;shell&quot;&gt;&lt;code class=&quot;language-shell&quot;&gt;# 1. devtools
i</summary>
      
    
    
    
    
    <category term="R" scheme="https://zhangchaofan01.gitee.io/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>fungiMatingType</title>
    <link href="https://zhangchaofan01.gitee.io/2023/07/10/fungimatingtype/"/>
    <id>https://zhangchaofan01.gitee.io/2023/07/10/fungimatingtype/</id>
    <published>2023-07-10T01:05:04.000Z</published>
    <updated>2023-07-20T01:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0.前言"></a>0.前言</h2><p>&emsp;&emsp;在做真菌的一些生信分析中，可能需要真菌的繁殖方式的信息。真菌的繁殖方式主要有两种：<code>同宗配合</code>与<code>异宗配合</code>，自然界中绝大多数的情况下都是<code>异宗配合</code>。控制真菌交配型的基因主要有两种： MAT1-1 和 MAT1-2，<code>异宗配合</code>指的是繁殖时必须需要这两种不同的交配型，<code>同宗配合</code>则没有这个限制<sup><a href="#ref1">1</a></sup>。<br><a href="https://imgse.com/i/pC7tp6O"><img src="https://s1.ax1x.com/2023/07/19/pC7tp6O.jpg" alt="pC7tp6O.jpg"></a></p><h2 id="1-NCBI-下载同源序列"><a href="#1-NCBI-下载同源序列" class="headerlink" title="1.NCBI 下载同源序列"></a>1.NCBI 下载同源序列</h2><p>&emsp;&emsp;通过上面的知识，我们了解到<em>Alternaria</em>属于<em>Dothideomycetes</em>，主要有两种交配型基因<code>MAT 1-1-1</code>与<code>MAT 1-2-1</code>。然后我们使用 NCBI 进行检索，关键字为<code>((Alternaria) AND mating-type) NOT partial</code>,发现搜索结果也主要的分为了<code>MAT 1-1-1</code>与<code>MAT 1-2-1</code>这两种。<br><a href="https://imgse.com/i/pC7tUjU"><img src="https://s1.ax1x.com/2023/07/19/pC7tUjU.png" alt="pC7tUjU.png"></a><br>&emsp;&emsp;我们两种交配型分别挑选 6~7 条 items，然后按顺序点击下图标签，这里第四步可以选择下载 DNA 还是 protein 序列，我们直接选择 DNA 序列。<br><a href="https://imgse.com/i/pC7tDE9"><img src="https://s1.ax1x.com/2023/07/19/pC7tDE9.png" alt="pC7tDE9.png"></a><br>交配型 MAT1-1 与 MAT1-2 的序列差异非常的大，不管是 DNA 还是 protein，你也可以自己试试。</p><h2 id="2-前处理"><a href="#2-前处理" class="headerlink" title="2.前处理"></a>2.前处理</h2><p>&emsp;&emsp;主要使用 blastn 来鉴定，输入数据包括上一步下载的 DNA 序列和组装好的基因组，如果你的物种基因组很小，就几十 Mb，然后你的二代数据用<a href="https://github.com/ablab/spades">SPADEs</a>能组装的非常好。用<a href="https://github.com/ablab/spades">SPADEs</a>怎么组装基因组之前写过，这里就不详细讲了。</p><p>&emsp;&emsp;上一步下载的 fasta 格式的 DNA 序列的 ID 信息有点乱：</p><blockquote><p>&gt;lcl|AB444193.1_cds_BAJ10530.1_1 [gene=MAT1-1-1] [protein=mating type protein MAT1-1-1] [protein_id=BAJ10530.1] [location=join(&lt;1..142,190..&gt;631)] [gbkey=CDS]</p></blockquote><p>最好修改下 ID，方便后续处理，我的话会改成:</p><pre class="line-numbers language-none"><code class="language-none">&gt;ADE44136.1__MAT1-1-1&gt;ADE44135.1__MAT1-1-1&gt;ADE44134.1__MAT1-1-1&gt;ADE44132.1__MAT1-1-1&gt;ADE44131.1__MAT1-1-1&gt;ADE44128.1__MAT1-1-1&gt;ADE44126.1__MAT1-2-1&gt;ADE44125.1__MAT1-2-1&gt;ADE44124.1__MAT1-2-1&gt;ADE44123.1__MAT1-2-1&gt;ADE44120.1__MAT1-2-1&gt;ADE44118.1__MAT1-2-1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-交配型的鉴定"><a href="#3-交配型的鉴定" class="headerlink" title="3.交配型的鉴定"></a>3.交配型的鉴定</h2><h3 id="3-1-blast-建库"><a href="#3-1-blast-建库" class="headerlink" title="3.1 blast 建库"></a>3.1 blast 建库</h3><p>&emsp;&emsp;怎么安装 blast 什么的这里也不讲了，自己百度。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">makeblastdb -dbtype nucl -in Alternaria_sp.nr.re.cds -out Alternaria_sp.nr.re.cds<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-blastn-比对"><a href="#3-2-blastn-比对" class="headerlink" title="3.2 blastn 比对"></a>3.2 blastn 比对</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">blastn -query sample1.geno.fa -db Alternaria_sp.nr.re.cds -outfmt 6 -evalue 1e-10 -max_target_seqs 12 -num_threads 10 -out sample1.MAT.blasn<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果就两行：</p><blockquote><p>NODE_11_length_1128118_cov_18.265760 ADE44132.1<strong>MAT1-1-1 99.784 925 2 0 698132 699056 1170 246 0.0 1698<br>NODE_11_length_1128118_cov_18.265760 ADE44132.1</strong>MAT1-1-1 99.592 245 1 0 699104 699348 241.99e-125 448</p></blockquote><p>因为我们使用的是 mRNA 剪切过后的 CDS 序列，所以比上的区域有个大的 GAP。这里最好将<code>-max_target_seqs</code>设为你之前从 NCBI 上下载的总序列数，有可能会鉴定到两种交配型的情况，这种很罕见，但有，处理的时候注意。</p><p><strong>References</strong>:</p><p name = "ref1">https://wswxtb.ijournals.cn/html/wswxtbcn/2020/5/tb20051572.htm</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;0-前言&quot;&gt;&lt;a href=&quot;#0-前言&quot; class=&quot;headerlink&quot; title=&quot;0.前言&quot;&gt;&lt;/a&gt;0.前言&lt;/h2&gt;&lt;p&gt;&amp;emsp;&amp;emsp;在做真菌的一些生信分析中，可能需要真菌的繁殖方式的信息。真菌的繁殖方式主要有两种：&lt;code&gt;同宗配</summary>
      
    
    
    
    
    <category term="Genome" scheme="https://zhangchaofan01.gitee.io/tags/Genome/"/>
    
    <category term="Fungi" scheme="https://zhangchaofan01.gitee.io/tags/Fungi/"/>
    
  </entry>
  
</feed>
