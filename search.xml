<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>hzau_RNA-seq</title>
      <link href="2025/06/02/hzau-rna-seq/"/>
      <url>2025/06/02/hzau-rna-seq/</url>
      
        <content type="html"><![CDATA[<style>pre {  overflow-y: auto;  max-height: 900px;}</style><p>流程总览：</p><p><img src="/blog_pics/hzau_RNA-seq/pipeline_overview.png" alt="png"><br>本流程参考华中农业大学<a href="http://www.guolianglab.org/">李国亮老师</a>的<a href="https://github.com/chaofan520/Bioinformatics_Pipelines/hzau_RNA-seq">课程PPT</a>，旨在提供一个打包好的pipeline，一行命令进行转录组数据的分析。</p><h2 id="0-环境配置"><a href="#0-环境配置" class="headerlink" title="0. 环境配置"></a>0. 环境配置</h2><p>需要预安装的一些软件，包括：</p><ol><li><code>conda</code><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n hzau_RNA-seqconda activate hzau_RNA-seqconda install python&#x3D;3.10 fastqc fastp multiqc&#x3D;1.26 sra-tools&#x3D;3.1 samtools&#x3D;1.21 -c bioconda -c conda-forgeconda install hisat2&#x3D;2.2.1 STAR&#x3D;2.7.11b stringtie&#x3D;2.2.3 subread&#x3D;2.1.1 deeptools snakemake -c bioconda -c conda-forge# 大爷的 之前openssl版本有问题conda install r-base&#x3D;4.4.2 r-biocmanager r-ggplot2&#x3D;3.5.1 curl&#x3D;8.11.1 openssl&#x3D;3.4.0 -c bioconda -c conda-forge# 我这里通过conda安装bioconductor-deseq2老有问题，只能通过BiocManager。可能你直接conda装就成功了# conda install bioconductor-deseq2 -c bioconda -c conda-forge <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-R" data-language="R"><div class="caption"><span>install_DESeq2.R</span></div><code class="language-R"># 如DEseq2直接通过conda安装成功，则不需要运行 &quot;BiocManager::install(&quot;DESeq2&quot;)&quot;BiocManager::install(&quot;DESeq2&quot;)# 安装其它依赖install.packages(&quot;purrr&quot;)install.packages(&quot;tibble&quot;)library(DESeq2)# Done!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-原始数据下载"><a href="#1-原始数据下载" class="headerlink" title="1. 原始数据下载"></a>1. 原始数据下载</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 配置工作目录mkdir 00.raw_sra 01.raw_fastq 02.clean_fastq 03.alignment_file 04.count_matrix 05.DEseq2# 下载原始sra文件cat SRR_Acc_List.txt | awk &#39;&#123;print $1&#125;&#39; |while read line; do    prefetch $&#123;line&#125; -O 00.raw_sra &amp;done## 下载完需检查文件大小是否与原网页一致 # sra转fastq.gzcat SRR_Acc_List.txt | awk &#39;&#123;print $1&#125;&#39; | while read line; do    fastq-dump 00.raw_sra&#x2F;$&#123;line&#125;&#x2F;$&#123;line&#125;.sra --split-3 --gzip -O 01.raw_fastq &amp;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>SRR_Acc_List.txt</span></div><code class="language-txt">SRR15859987 # mature leaves Col-0 Repeat1SRR15859988 # mature leaves Col-0 Repeat2SRR15859989 # mature leaves Col-0 Repeat3SRR15859993 # mature leaves met1-3 Repeat1SRR15859994 # mature leaves met1-3 Repeat2SRR15859995 # mature leaves met1-3 Repeat3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-Shell命令行操作"><a href="#2-Shell命令行操作" class="headerlink" title="2. Shell命令行操作"></a>2. <code>Shell</code>命令行操作</h2>李老师这里介绍了几种常用的流程：<blockquote><ol><li>Fastp -&gt; HISAT2/STAR -&gt; featureCounts|htseq-count（基于gene Counts）  -&gt; DESeq2  </li><li>Fastp -&gt; HISAT2/STAR -&gt; StringTie（基于转录本） -&gt; EdgeR  </li></ol></blockquote></li></ol><p>我这个()注释位置与原PPT不同，放这里个人感觉更直观。</p><h3 id="2-1-数据质控"><a href="#2-1-数据质控" class="headerlink" title="2.1 数据质控"></a>2.1 数据质控</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># raw_data 测序数据质量检测fastqc 01.raw_fastq&#x2F;*.gz -o 01.raw_fastq&#x2F; -t 12multiqc 01.raw_fastq&#x2F; -o 01.raw_fastq&#x2F;multiqc # 可以看下multiqc_report.html，原始数据有点接头# fastq 测序数据质控for i in 87 88 89 93 94 95do    fastp -i 01.raw_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz -o 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz -I 01.raw_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz -O 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz -h 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;.fastp.html -j 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;.fastp.json --thread 16done # clean_data 测序数据质量检测fastqc 02.clean_fastq&#x2F;*.gz -o 02.clean_fastq&#x2F; -t 12multiqc 02.clean_fastq&#x2F; -o 02.clean_fastq&#x2F;multiqc # 对比下质控前后结果# 目前大部分情况下是不需要去除rRNA的<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-数据比对"><a href="#2-2-数据比对" class="headerlink" title="2.2 数据比对"></a>2.2 数据比对</h3><p>首先下载基因组数据</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># dna_sm 基因组softmask版本wget https:&#x2F;&#x2F;ftp.ensemblgenomes.ebi.ac.uk&#x2F;pub&#x2F;plants&#x2F;release-61&#x2F;fasta&#x2F;arabidopsis_thaliana&#x2F;dna&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa.gzwget https:&#x2F;&#x2F;ftp.ensemblgenomes.ebi.ac.uk&#x2F;pub&#x2F;plants&#x2F;release-61&#x2F;gtf&#x2F;arabidopsis_thaliana&#x2F;Arabidopsis_thaliana.TAIR10.61.gtf.gzgzip -d *.gz mkdir Referencemv Arabidopsis_thaliana.TAIR10.61.gtf Reference&#x2F;mv Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa Reference&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-1-HISAT2比对"><a href="#2-2-1-HISAT2比对" class="headerlink" title="2.2.1 HISAT2比对"></a>2.2.1 <code>HISAT2</code>比对</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir Reference&#x2F;hisat2_index# 构建HISAT2 基因组比对索引hisat2-build -p 20 Reference&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa Reference&#x2F;hisat2_index&#x2F;Arabidopsis_thaliana.TAIR10mkdir -p 03.alignment_file&#x2F;hisat2_resultfor i in 87 88 89 93 94 95do    hisat2 -x Reference&#x2F;hisat2_index&#x2F;Arabidopsis_thaliana.TAIR10 -1 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz -2 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz -S 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sam -p 20 --summary-file 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.summarydone <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-2-STAR比对"><a href="#2-2-2-STAR比对" class="headerlink" title="2.2.2 STAR比对"></a>2.2.2 <code>STAR</code>比对</h4><p>其实使用STAR比对这一步可以不做的，我个人一般也是直接使用<code>HISAT2</code>进行mapping。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir Reference&#x2F;STAR_index# 构建STAR 基因组比对索引STAR --runThreadN 16 --runMode genomeGenerate --genomeDir Reference&#x2F;STAR_index&#x2F; --genomeFastaFiles Reference&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa# 有个 WARNING啊，课件里只用了一条染色体应该也有WARNING的# !!!!! WARNING: --genomeSAindexNbases 14 is too large for the genome size&#x3D;119667750, which may cause seg-fault at the mapping step. Re-run genome generation with recommended --genomeSAindexNbases 12# 我们重新生成STAR --runThreadN 16 --runMode genomeGenerate --genomeDir Reference&#x2F;STAR_index&#x2F; --genomeFastaFiles Reference&#x2F;Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa --genomeSAindexNbases 12mkdir -p 03.alignment_file&#x2F;star_resultfor i in 87 88 89 93 94 95do    STAR --runThreadN 16 --runMode alignReads --readFilesCommand zcat --outSAMunmapped None --genomeDir Reference&#x2F;STAR_index&#x2F; --readFilesIn 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_1.fastq.gz 02.clean_fastq&#x2F;SRR158599$&#123;i&#125;_2.fastq.gz --outFileNamePrefix 03.alignment_file&#x2F;star_result&#x2F;SRR158599$&#123;i&#125;_done <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-3-sam2bam"><a href="#2-2-3-sam2bam" class="headerlink" title="2.2.3 sam2bam"></a>2.2.3 sam2bam</h4><p><code>HISAT2</code>的输出<code>sam</code>是按照<code>readsname</code>进行排序的，可以直接用于<code>htseq-count</code>进行计数。但有些软件（比如：StringTie<sup><a name="ref1">1</a></sup>）的输入要求必须是按<code>position</code>进行排序，我们需要使用<code>samtools</code>进行转换。而且<code>sam</code>文件非常大，将<code>sam</code>转换为<code>bam</code>也能很好的缓解储存压力。<code>samtools sort</code>的输出默认是按照<code>position</code>进行排序，如果这样的<code>bam</code>用于<code>htseq-count</code>计数，需指定<code>-r pos</code>(default: name)。这里只是提一嘴，我们这里不使用<code>htseq-count</code>进行计数。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">for i in 87 88 89 93 94 95do    samtools view -@ 16 -bS 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sam &gt; 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.bam &amp;&amp; rm 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sam    samtools sort -@ 16 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.bam -o 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bam &amp;&amp; rm 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.bam    samtools index 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bamdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-计算基因表达量"><a href="#2-3-计算基因表达量" class="headerlink" title="2.3 计算基因表达量"></a>2.3 计算基因表达量</h3><h4 id="2-3-1-featureCounts-htseq-count"><a href="#2-3-1-featureCounts-htseq-count" class="headerlink" title="2.3.1 featureCounts|htseq-count"></a>2.3.1 featureCounts|htseq-count</h4><p>这里使用<code>featureCounts</code>或<code>htseq-count</code>都行，我们这里参照原PPT使用<code>featureCounts</code>。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p 04.count_matrix&#x2F;featureCountsfor i in 87 88 89 93 94 95do    featureCounts -a Reference&#x2F;Arabidopsis_thaliana.TAIR10.61.gtf -o 04.count_matrix&#x2F;featureCounts&#x2F;SRR158599$&#123;i&#125;.featurecount.txt -p 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bam   # 双端数据千万别忘了加 -pdone <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>featureCounts</code>的输出很简单，单个样本的情况下输出七列，第一列为基因ID，第六列为这个基因所有<code>exon</code>的长度（去掉了不同转录本间的冗余长度，可直接用来算<code>FPKM</code>），第7列为<code>mapping</code>到的<code>Fragments</code>数量（单端测序数据也称为<code>reads</code>数量）。</p><p><img src="/blog_pics/hzau_RNA-seq/featureCounts_ouf.png" alt="png"> </p><h4 id="2-3-2-Stringtie"><a href="#2-3-2-Stringtie" class="headerlink" title="2.3.2 Stringtie"></a>2.3.2 Stringtie</h4><p><code>Stringtie</code>可以用来鉴定新的转录本，挖掘可变剪切事件，也可以直接定量，参考简书教程<sup><a name="ref1">2</a></sup>。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p 04.count_matrix&#x2F;stringtiefor i in 87 88 89 93 94 95do    stringtie -p 16 03.alignment_file&#x2F;hisat2_result&#x2F;SRR158599$&#123;i&#125;.hisat2.sort.bam -G Reference&#x2F;Arabidopsis_thaliana.TAIR10.61.gtf -o 04.count_matrix&#x2F;stringtie&#x2F;SRR158599$&#123;i&#125;.gtf -e -A 04.count_matrix&#x2F;stringtie&#x2F;SRR158599$&#123;i&#125;.gene.tabdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意，<code>Stringtie</code>的输出直接为<code>FPKM</code>和<code>TPM</code>,没有<code>count</code>。后续的<code>DESeq2</code>差异表达分析的输入必须使用原始的<code>count</code>。其实我们用了<code>featureCounts|htseq-count</code>进行计数后没必要再用<code>Stringtie</code>，如果需要<code>FPKM</code>和<code>TPM</code>值，可以通过<code>count</code>进行转换。</p><p><img src="/blog_pics/hzau_RNA-seq/Stringtie_ouf.png" alt="png"> </p><h3 id="2-4-检查样本的重复性"><a href="#2-4-检查样本的重复性" class="headerlink" title="2.4 检查样本的重复性"></a>2.4 检查样本的重复性</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 计算每个bam文件的覆盖度情况multiBamSummary bins --bamfiles 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859987.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859988.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859989.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859993.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859994.hisat2.sort.bam 03.alignment_file&#x2F;hisat2_result&#x2F;SRR15859995.hisat2.sort.bam --minMappingQuality 30 --labels Col_rep1 Col_rep2 Col_rep3 met_rep1 met_rep2 met_rep3 -out 03.alignment_file&#x2F;readCounts.npz --outRawCounts 03.alignment_file&#x2F;readCounts.tab -p 20# 基于覆盖度信息进行层次聚类plotCorrelation -in 03.alignment_file&#x2F;readCounts.npz --corMethod spearman --skipZeros --plotTitle &quot;Spearman Correlation of Read Counts&quot; --whatToPlot heatmap --colorMap RdYlBu --plotNumbers -o 03.alignment_file&#x2F;heatmap_SpearmanCorr_readCounts.png --outFileCorMatrix 03.alignment_file&#x2F;readCounts.tab<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>样本重复性不错：<br><img src="/blog_pics/hzau_RNA-seq/sample_cor.png" alt="png"></p><h3 id="2-5-DESeq2差异表达分析"><a href="#2-5-DESeq2差异表达分析" class="headerlink" title="2.5 DESeq2差异表达分析"></a>2.5 <code>DESeq2</code>差异表达分析</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Rscript DEseq2.R<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-R" data-language="R"><div class="caption"><span>DEseq2.R</span></div><code class="language-R">library(purrr)suppressMessages(library(DESeq2))library(ggplot2)library(tibble)################# Merge count table ##################samplelist &lt;- c(&quot;SRR15859987&quot;, &quot;SRR15859988&quot;, &quot;SRR15859989&quot;, &quot;SRR15859993&quot;, &quot;SRR15859994&quot;, &quot;SRR15859995&quot;)# 读取不同样本的基因表达量列表exprlist &lt;- lapply(samplelist, function(x)&#123;     expr &lt;- read.table(paste0(&quot;04.count_matrix&#x2F;featureCounts&#x2F;&quot;, x, &quot;.featurecount.txt&quot;), header&#x3D;T) ## 读取文件     expr&lt;- expr[,c(1,7)] ### 提取基因id和表达量值     colnames(expr) &lt;- c(&quot;GeneID&quot;, x) ## 重命名     expr&#125;)# 多个基因样本的基因表达量列表合并expr.mat &lt;- purrr::reduce(exprlist, function(x,y)&#123;merge(x,y, by&#x3D;&quot;GeneID&quot;, all.x&#x3D;T)&#125;)write.table(expr.mat,   file &#x3D; &quot;.&#x2F;05.DEseq2&#x2F;merged_count_matrix.txt&quot;,   sep &#x3D; &quot;\t&quot;,   quote &#x3D; FALSE,   row.names &#x3D; FALSE  )######################### DEG #########################group_info &lt;- data.frame(Sample&#x3D;samplelist, Group&#x3D;c(rep(&quot;Col&quot;,3), rep(&quot;met1&quot;,3))) print(group_info)expr &lt;- column_to_rownames(expr.mat, &quot;GeneID&quot;)  # 表达矩阵head(expr)colData &lt;- group_info # 分组信息colData$Group &lt;- factor(colData$Group, levels &#x3D; c(&quot;Col&quot;, &quot;met1&quot;))dds &lt;- DESeqDataSetFromMatrix(countData &#x3D; as.matrix(expr), colData &#x3D; colData, design &#x3D; ~Group)dds &lt;- dds[rowSums(counts(dds)) &gt; 10, ] # 过滤低表达基因dds &lt;- DESeq(dds) # 差异分析print(&quot;######## Compare groups&quot;)print(resultsNames(dds)) # 查看比较组别print(dds)# log2(met1 &#x2F; Col)res &lt;- results(dds) # 获取差异表达结果head(res) # 查看差异表达结果## 保存分析结果write.csv(res, &quot;.&#x2F;05.DEseq2&#x2F;deseq2.diff.csv&quot;)####################### Volcano #######################res.plot &lt;- data.frame(res, stringsAsFactors &#x3D; FALSE, check.names &#x3D; FALSE)res.plot &lt;- na.omit(res.plot)res.plot$gene &lt;- rownames(res.plot)res.plot$sig &lt;- &quot;Not Signaficant&quot;res.plot[res.plot$log2FoldChange &gt; 2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- &quot;Highly expression in met1&quot;res.plot[res.plot$log2FoldChange &lt; -2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- &quot;Highly expression in Col&quot;res.plot$label &lt;- ifelse(res.plot$padj &lt; 10e-100 &amp; abs(res.plot$log2FoldChange) &gt;&#x3D; 5,                        rownames(res.plot), &quot;&quot;)p &lt;- ggplot(data&#x3D;res.plot, aes(x&#x3D;log2FoldChange,y&#x3D; -log10(padj))) +  geom_point(aes(color&#x3D;sig)) +   geom_text(aes(label&#x3D;label),  nudge_x&#x3D;.5,nudge_y&#x3D;.5, size&#x3D;2.5) +  scale_color_manual(values&#x3D;c(&quot;#546de5&quot;, &quot;#ff4757&quot;, &quot;#d2dae2&quot;)) +   labs(x&#x3D;expression(log[2](FC)), y&#x3D;expression(-log[10](padj))) +  geom_hline(yintercept&#x3D;2, linetype&#x3D;4) +  geom_vline(xintercept&#x3D;c(-2, 2),linetype&#x3D;4) +  theme_bw() + theme(panel.grid &#x3D; element_blank(),   legend.position &#x3D; &quot;top&quot;, legend.title &#x3D; element_blank(), aspect.ratio&#x3D;1,        legend.background &#x3D; element_blank())## 保存ggsave(&quot;.&#x2F;05.DEseq2&#x2F;Volcano.plot.pdf&quot;, p, width&#x3D;5.5, height&#x3D;5.5)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与原PPT有点差异，不知道原PPT是比对到全基因组，还是只是<code>Chr1</code>。</p><p><img src="/blog_pics/hzau_RNA-seq/Volcano_plot.png" alt="png"></p><h2 id="3-snakemake-pipeline"><a href="#3-snakemake-pipeline" class="headerlink" title="3. snakemake pipeline"></a>3. <code>snakemake</code> pipeline</h2><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>Snakefile</span></div><code class="language-python"><span class="token comment"># Snakefile for RNA-seq analysis pipeline (with pre-provided reference)</span>configfile<span class="token punctuation">:</span> <span class="token string">"config.yaml"</span><span class="token comment"># --- 从配置文件读取参数 --- </span>WORK_DIR <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"work_dir"</span><span class="token punctuation">]</span>THREADS <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"threads"</span><span class="token punctuation">]</span>REF_FASTA <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"ref_fasta"</span><span class="token punctuation">]</span>  <span class="token comment"># 基因组fasta路径</span>REF_GTF <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"ref_gtf"</span><span class="token punctuation">]</span>      <span class="token comment"># 注释文件路径</span>REF_PREFIX <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">"ref_prefix"</span><span class="token punctuation">]</span><span class="token comment"># 获取所有样本列表</span>ALL_SAMPLES <span class="token operator">=</span> <span class="token punctuation">[</span>sample <span class="token keyword">for</span> group <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> group<span class="token punctuation">]</span>SAMPLES_GROUP <span class="token operator">=</span> <span class="token punctuation">&#123;</span>sample<span class="token punctuation">:</span>group <span class="token keyword">for</span> group <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>group<span class="token punctuation">]</span><span class="token punctuation">&#125;</span>GROUP_OF_SAMPLES <span class="token operator">=</span> <span class="token punctuation">[</span>SAMPLES_GROUP<span class="token punctuation">[</span>sample<span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> ALL_SAMPLES<span class="token punctuation">]</span>GROUP_NAMES <span class="token operator">=</span> unique_groups <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span>GROUP_OF_SAMPLES<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>GROUP_NAMES<span class="token punctuation">)</span><span class="token comment"># --- 定义目录结构 --- </span>dirs <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">"00.raw_sra"</span><span class="token punctuation">,</span>    <span class="token string">"01.raw_fastq"</span><span class="token punctuation">,</span>    <span class="token string">"02.clean_fastq"</span><span class="token punctuation">,</span>    <span class="token string">"03.alignment_file/hisat2_result"</span><span class="token punctuation">,</span>    <span class="token string">"04.count_matrix/featureCounts"</span><span class="token punctuation">,</span>     <span class="token string">"05.DEseq2"</span><span class="token punctuation">,</span>    <span class="token string">"Reference/hisat2_index"</span><span class="token punctuation">]</span>rule <span class="token builtin">all</span><span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"05.DEseq2/&#123;plot&#125;"</span><span class="token punctuation">,</span> plot<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"merged_count_matrix.txt"</span><span class="token punctuation">,</span> <span class="token string">"deseq2.diff.csv"</span><span class="token punctuation">,</span> <span class="token string">"Volcano.plot.pdf"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">"03.alignment_file/heatmap_SpearmanCorr_readCounts.png"</span><span class="token comment"># --- 创建目录结构 --- </span>rule create_dirs<span class="token punctuation">:</span>    run<span class="token punctuation">:</span>        <span class="token keyword">import</span> os        <span class="token keyword">for</span> d <span class="token keyword">in</span> dirs<span class="token punctuation">:</span>            os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>WORK_DIR<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># --- 数据下载和质控部分保持不变 ---</span>rule download_sra<span class="token punctuation">:</span>    output<span class="token punctuation">:</span>        <span class="token string">"00.raw_sra/&#123;sample&#125;/&#123;sample&#125;.sra"</span>    params<span class="token punctuation">:</span>        outdir <span class="token operator">=</span> <span class="token string">"00.raw_sra"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][prefetch]&#125; &#123;wildcards.sample&#125; -O &#123;params.outdir&#125;"</span>rule sra_to_fastq<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        <span class="token string">"00.raw_sra/&#123;sample&#125;/&#123;sample&#125;.sra"</span>    output<span class="token punctuation">:</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_2.fastq.gz"</span>     shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastq-dump]&#125; &#123;input&#125; --split-3 --gzip -O 01.raw_fastq"</span><span class="token comment"># --- FastQC原始数据质控 --- </span>rule raw_fastqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        raw_fq1 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        raw_fq2 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_2.fastq.gz"</span>    output<span class="token punctuation">:</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_1_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_2_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_1_fastqc.zip"</span><span class="token punctuation">,</span>        <span class="token string">"01.raw_fastq/&#123;sample&#125;_2_fastqc.zip"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.raw_fq1&#125; -o 01.raw_fastq -t 1;"</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.raw_fq2&#125; -o 01.raw_fastq -t 1"</span><span class="token comment"># --- MultiQC汇总报告 --- </span>rule raw_multiqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"01.raw_fastq/&#123;sample&#125;_&#123;pair&#125;_fastqc.html"</span><span class="token punctuation">,</span>                sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">,</span> pair<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        <span class="token string">"01.raw_fastq/multiqc_report.html"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][multiqc]&#125; 01.raw_fastq/ -o 01.raw_fastq"</span><span class="token comment"># --- Fastp数据清洗 --- </span>rule fastp_clean<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        r1 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        r2 <span class="token operator">=</span> <span class="token string">"01.raw_fastq/&#123;sample&#125;_2.fastq.gz"</span><span class="token punctuation">,</span>        raw_multiqc <span class="token operator">=</span> <span class="token string">"01.raw_fastq/multiqc_report.html"</span>    output<span class="token punctuation">:</span>        cr1 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        cr2 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_2.fastq.gz"</span><span class="token punctuation">,</span>        html <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;.fastp.html"</span><span class="token punctuation">,</span>        json <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;.fastp.json"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastp]&#125; -i &#123;input.r1&#125; -I &#123;input.r2&#125; "</span>        <span class="token string">"-o &#123;output.cr1&#125; -O &#123;output.cr2&#125; "</span>        <span class="token string">"-h &#123;output.html&#125; -j &#123;output.json&#125; "</span>        <span class="token string">"--thread 4"</span><span class="token comment"># --- 清洗后质控 --- </span>rule clean_fastqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        clean_fq1 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        clean_fq2 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_2.fastq.gz"</span>    output<span class="token punctuation">:</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_1_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_2_fastqc.html"</span><span class="token punctuation">,</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_1_fastqc.zip"</span><span class="token punctuation">,</span>        <span class="token string">"02.clean_fastq/&#123;sample&#125;_2_fastqc.zip"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.clean_fq1&#125; -o 02.clean_fastq -t 1;"</span>        <span class="token string">"&#123;config[tools][fastqc]&#125; &#123;input.clean_fq2&#125; -o 02.clean_fastq -t 1"</span>rule clean_multiqc<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"02.clean_fastq/&#123;sample&#125;_&#123;pair&#125;_fastqc.html"</span><span class="token punctuation">,</span>                sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">,</span> pair<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        <span class="token string">"02.clean_fastq/multiqc_report.html"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][multiqc]&#125; 02.clean_fastq/ -o 02.clean_fastq"</span><span class="token comment"># --- 参考基因组处理 ---</span><span class="token keyword">print</span><span class="token punctuation">(</span>REF_FASTA<span class="token punctuation">)</span>rule hisat2_index<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        REF_FASTA    output<span class="token punctuation">:</span>        expand<span class="token punctuation">(</span><span class="token string">"Reference/hisat2_index/&#123;prefix&#125;.&#123;n&#125;.ht2"</span><span class="token punctuation">,</span>               prefix<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">"ref_prefix"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][hisat2]&#125;-build -p &#123;THREADS&#125; &#123;config[ref_fasta]&#125; Reference/hisat2_index/&#123;config[ref_prefix]&#125;"</span><span class="token comment"># --- 比对和定量 ---</span>rule hisat2_align<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        clean_multiqc <span class="token operator">=</span> <span class="token string">"02.clean_fastq/multiqc_report.html"</span><span class="token punctuation">,</span>        r1 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_1.fastq.gz"</span><span class="token punctuation">,</span>        r2 <span class="token operator">=</span> <span class="token string">"02.clean_fastq/&#123;sample&#125;_2.fastq.gz"</span><span class="token punctuation">,</span>        idx <span class="token operator">=</span> expand<span class="token punctuation">(</span><span class="token string">"Reference/hisat2_index/&#123;prefix&#125;.&#123;n&#125;.ht2"</span><span class="token punctuation">,</span>                   prefix<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">"ref_prefix"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        sam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sam"</span><span class="token punctuation">,</span>        summary <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.summary"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][hisat2]&#125; -x Reference/hisat2_index/&#123;config[ref_prefix]&#125; "</span>        <span class="token string">"-1 &#123;input.r1&#125; -2 &#123;input.r2&#125; "</span>        <span class="token string">"-S &#123;output.sam&#125; -p 4 "</span>        <span class="token string">"--summary-file &#123;output.summary&#125;"</span>rule sam_to_bam<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        sam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sam"</span>    output<span class="token punctuation">:</span>        bam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam"</span><span class="token punctuation">,</span>        bai <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam.bai"</span>  <span class="token comment"># 索引文件</span>    params<span class="token punctuation">:</span>        unsorted_bam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.bam"</span>  <span class="token comment"># 中间文件</span>    shell<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        # 1. SAM转BAM        &#123;config[tools][samtools]&#125; view -@ 4 -bS &#123;input.sam&#125; > &#123;params.unsorted_bam&#125;                # 2. 排序BAM        &#123;config[tools][samtools]&#125; sort -@ 4 &#123;params.unsorted_bam&#125; -o &#123;output.bam&#125;                # 3. 删除中间文件        rm -v &#123;params.unsorted_bam&#125; &#123;input.sam&#125;                # 4. 创建索引        &#123;config[tools][samtools]&#125; index &#123;output.bam&#125;        """</span>rule feature_counts<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        bam <span class="token operator">=</span> <span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam"</span><span class="token punctuation">,</span>        gtf <span class="token operator">=</span> REF_GTF    output<span class="token punctuation">:</span>        counts <span class="token operator">=</span> <span class="token string">"04.count_matrix/featureCounts/&#123;sample&#125;.featurecount.txt"</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][featurecounts]&#125; -a &#123;input.gtf&#125; -o &#123;output.counts&#125; "</span>        <span class="token string">"-p &#123;input.bam&#125;"</span><span class="token comment"># --- 样本相关性分析 ---</span>rule sample_correlation<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        bams <span class="token operator">=</span> expand<span class="token punctuation">(</span><span class="token string">"03.alignment_file/hisat2_result/&#123;sample&#125;.hisat2.sort.bam"</span><span class="token punctuation">,</span> sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">)</span>    output<span class="token punctuation">:</span>        <span class="token string">"03.alignment_file/heatmap_SpearmanCorr_readCounts.png"</span><span class="token punctuation">,</span>        <span class="token string">"03.alignment_file/readCounts.npz"</span><span class="token punctuation">,</span>        <span class="token string">"03.alignment_file/readCounts.tab"</span>    params<span class="token punctuation">:</span>        labels <span class="token operator">=</span> <span class="token keyword">lambda</span> wildcards<span class="token punctuation">:</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>            <span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group<span class="token punctuation">&#125;</span></span><span class="token string">_rep</span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>              <span class="token keyword">for</span> group <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span>              <span class="token keyword">for</span> i<span class="token punctuation">,</span> sample <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>group<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token punctuation">)</span>    shell<span class="token punctuation">:</span>        <span class="token string">"&#123;config[tools][multiBamSummary]&#125; bins --bamfiles &#123;input.bams&#125; "</span>        <span class="token string">"--minMappingQuality 30 --labels &#123;params.labels&#125; "</span>        <span class="token string">"-out &#123;output[1]&#125; --outRawCounts &#123;output[2]&#125; "</span>        <span class="token string">"-p &#123;THREADS&#125; \n"</span>        <span class="token string">"&#123;config[tools][plotCorrelation]&#125; -in &#123;output[1]&#125; --corMethod spearman "</span>        <span class="token string">"--skipZeros --plotTitle 'Spearman Correlation of Read Counts' "</span>        <span class="token string">"--whatToPlot heatmap --colorMap RdYlBu --plotNumbers "</span>        <span class="token string">"-o &#123;output[0]&#125;"</span><span class="token comment"># --- DESeq2差异分析 --- </span>rule merged_deseq2_analysis<span class="token punctuation">:</span>    <span class="token builtin">input</span><span class="token punctuation">:</span>        counts <span class="token operator">=</span> expand<span class="token punctuation">(</span><span class="token string">"04.count_matrix/featureCounts/&#123;sample&#125;.featurecount.txt"</span><span class="token punctuation">,</span> sample<span class="token operator">=</span>ALL_SAMPLES<span class="token punctuation">)</span><span class="token punctuation">,</span>        gtf <span class="token operator">=</span> REF_GTF    output<span class="token punctuation">:</span>        merged_count_txt <span class="token operator">=</span> <span class="token string">"05.DEseq2/merged_count_matrix.txt"</span><span class="token punctuation">,</span>        diff_csv <span class="token operator">=</span> <span class="token string">"05.DEseq2/deseq2.diff.csv"</span><span class="token punctuation">,</span>        volcano <span class="token operator">=</span> <span class="token string">"05.DEseq2/Volcano.plot.pdf"</span>    run<span class="token punctuation">:</span>        <span class="token comment"># 准备分组信息</span>        group_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> group_name<span class="token punctuation">,</span> samples <span class="token keyword">in</span> config<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            group_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>s<span class="token punctuation">&#125;</span></span><span class="token string">':'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group_name<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> s <span class="token keyword">in</span> samples<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token comment"># 将列表转换为字符串</span>        sample_str <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>s<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> s <span class="token keyword">in</span> ALL_SAMPLES<span class="token punctuation">]</span><span class="token punctuation">)</span>        group_str <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>g<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> g <span class="token keyword">in</span> GROUP_OF_SAMPLES<span class="token punctuation">]</span><span class="token punctuation">)</span>        group_class_str <span class="token operator">=</span>  <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>c<span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span> <span class="token keyword">for</span> c <span class="token keyword">in</span> GROUP_NAMES<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token comment"># 生成R脚本</span>        script <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""library(purrr)suppressMessages(library(DESeq2))library(ggplot2)library(tibble)samplelist &lt;- c(</span><span class="token interpolation"><span class="token punctuation">&#123;</span>sample_str<span class="token punctuation">&#125;</span></span><span class="token string">)grouplist &lt;- c(</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group_str<span class="token punctuation">&#125;</span></span><span class="token string">)exprlist &lt;- lapply(samplelist, function(x)&#123;&#123;     expr &lt;- read.table(paste0('04.count_matrix/featureCounts/', x, '.featurecount.txt'), header=T)     expr&lt;- expr[,c(1,7)]      colnames(expr) &lt;- c('GeneID', x)      expr&#125;&#125;)expr.mat &lt;- purrr::reduce(exprlist, function(x,y)&#123;&#123;merge(x,y, by="GeneID", all.x=T)&#125;&#125;)write.table(expr.mat,     file = "</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>merged_count_txt<span class="token punctuation">&#125;</span></span><span class="token string">",     sep = "\t",     quote = FALSE,     row.names = FALSE)group_info &lt;- data.frame(Sample=samplelist, Group=grouplist) print(group_info)expr &lt;- column_to_rownames(expr.mat, "GeneID")head(expr)colData &lt;- group_info colData$Group &lt;- factor(colData$Group, levels = c(</span><span class="token interpolation"><span class="token punctuation">&#123;</span>group_class_str<span class="token punctuation">&#125;</span></span><span class="token string">))dds &lt;- DESeqDataSetFromMatrix(countData = as.matrix(expr), colData = colData, design = ~Group)dds &lt;- dds[rowSums(counts(dds)) > 10, ] dds &lt;- DESeq(dds) print(resultsNames(dds)) print(dds)res &lt;- results(dds) head(res) write.csv(res, "</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>diff_csv<span class="token punctuation">&#125;</span></span><span class="token string">")res.plot &lt;- data.frame(res, stringsAsFactors = FALSE, check.names = FALSE)res.plot &lt;- na.omit(res.plot)res.plot$gene &lt;- rownames(res.plot)res.plot$sig &lt;- "Not Signaficant"res.plot[res.plot$log2FoldChange > 2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- "Highly expression in met1"res.plot[res.plot$log2FoldChange &lt; -2 &amp; res.plot$padj &lt; 0.01, ]$sig &lt;- "Highly expression in CK"res.plot$label &lt;- ifelse(res.plot$padj &lt; 10e-100 &amp; abs(res.plot$log2FoldChange) >= 5,                        rownames(res.plot), "")p &lt;- ggplot(data=res.plot, aes(x=log2FoldChange,y= -log10(padj))) +  geom_point(aes(color=sig)) +   geom_text(aes(label=label),  nudge_x=.5,nudge_y=.5, size=2.5) +  scale_color_manual(values=c("#546de5", "#ff4757", "#d2dae2")) +   labs(x=expression(log[2](FC)), y=expression(-log[10](padj))) +  geom_hline(yintercept=2, linetype=4) +  geom_vline(xintercept=c(-2, 2),linetype=4) +  theme_bw() + theme(panel.grid = element_blank(),   legend.position = "top", legend.title = element_blank(), aspect.ratio=1,        legend.background = element_blank())ggsave("</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output<span class="token punctuation">.</span>volcano<span class="token punctuation">&#125;</span></span><span class="token string">", p, width=8, height=6)"""</span></span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"merged_analysis.R"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>script<span class="token punctuation">)</span>        shell<span class="token punctuation">(</span><span class="token string">"Rscript merged_analysis.R"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-yaml" data-language="yaml"><div class="caption"><span>config.yaml</span></div><code class="language-yaml"><span class="token comment"># config.yaml</span><span class="token key atrule">samples</span><span class="token punctuation">:</span>  <span class="token key atrule">CK</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> SRR15859987    <span class="token punctuation">-</span> SRR15859988     <span class="token punctuation">-</span> SRR15859989  <span class="token key atrule">met1</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> SRR15859993    <span class="token punctuation">-</span> SRR15859994    <span class="token punctuation">-</span> SRR15859995<span class="token comment"># 参考文件配置</span><span class="token key atrule">ref_fasta</span><span class="token punctuation">:</span> <span class="token string">"../Reference/Arabidopsis_thaliana.TAIR10.dna_sm.toplevel.fa"</span><span class="token key atrule">ref_gtf</span><span class="token punctuation">:</span> <span class="token string">"../Reference/Arabidopsis_thaliana.TAIR10.61.gtf"</span><span class="token key atrule">ref_prefix</span><span class="token punctuation">:</span> <span class="token string">"Arabidopsis_thaliana.TAIR10"</span><span class="token key atrule">work_dir</span><span class="token punctuation">:</span> <span class="token string">"."</span><span class="token key atrule">threads</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token comment"># 工具路径配置</span><span class="token key atrule">tools</span><span class="token punctuation">:</span>  <span class="token key atrule">fastqc</span><span class="token punctuation">:</span> <span class="token string">"fastqc"</span>  <span class="token key atrule">multiqc</span><span class="token punctuation">:</span> <span class="token string">"multiqc"</span>  <span class="token key atrule">fastp</span><span class="token punctuation">:</span> <span class="token string">"fastp"</span>  <span class="token key atrule">hisat2</span><span class="token punctuation">:</span> <span class="token string">"hisat2"</span>  <span class="token key atrule">samtools</span><span class="token punctuation">:</span> <span class="token string">"samtools"</span>  <span class="token key atrule">featurecounts</span><span class="token punctuation">:</span> <span class="token string">"featureCounts"</span>  <span class="token key atrule">prefetch</span><span class="token punctuation">:</span> <span class="token string">"prefetch"</span>  <span class="token key atrule">fastq-dump</span><span class="token punctuation">:</span> <span class="token string">"fastq-dump"</span>  <span class="token key atrule">multiBamSummary</span><span class="token punctuation">:</span> <span class="token string">"multiBamSummary"</span>  <span class="token key atrule">plotCorrelation</span><span class="token punctuation">:</span> <span class="token string">"plotCorrelation"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">snakemake -j 20<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/blog_pics/hzau_RNA-seq/Snakemake_volcano.png" alt="png"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual">StringTie Manual</a>  </li><li><a href="https://www.jianshu.com/p/c9434353b648">StringTie 简书教程</a>  </li><li><a href="https://github.com/chaofan520/Bioinformatics_Pipelines/tree/main/hzau_RNA-seq">PPT 地址</a></li></ol><center><span style="color:#ff0000;">本人能力有限，难免出现错误，恳请批评指正</span></center>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> Pipeline </tag>
            
            <tag> RNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EvolvePro-directed evolution</title>
      <link href="2025/04/15/evolvepro-directed-evolution/"/>
      <url>2025/04/15/evolvepro-directed-evolution/</url>
      
        <content type="html"><![CDATA[<style>pre {  overflow-y: auto;  max-height: 300px;}</style><h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>进化（演化）是生物种群在遗传变异、自然选择、遗传漂变等因素作用下，随时间累积而发生的适应性变化过程。进化的结果在宏观上可以体现在生物体与祖先的表型差异，微观上则是分子水平的基因频率改变。自然界中的进化有几个重要性的因素：1）变异的多样性；2）变异可遗传；3）选择压力适中。<br>&emsp;&emsp;而定向进化则是人为地模拟自然界中选择作用，可以对物种的表型进行选择，也可以对具体的某个分子（蛋白）进行选择。我们首先从原始序列（也称为野生型）人工构建大量的突变体文库，然后衡量突变体的表型（如植株的高度，果实大小、蛋白分子的稳定性|溶解度|酶活性等）。选择最优表型的突变体，作为下一次突变的起始序列，迭代这一过程。这一过程可以理解为于爬山，理想表型的突变体在山顶，每迭代一次相当于向山顶靠近一步。<br>&emsp;&emsp;20世纪中叶小麦的绿色革命可以作为一个宏观定向进化的例子，我们想获得一个抗倒伏的矮杆品种，初始情况下我们有一个性状优良的小麦群体，但是这个群体的小麦都比较高。我们人为选取该群体中较矮的植株进行诱变，对后代的植株高度进行观察，选择后代中较矮的植株再进行诱变，如此迭代几轮，直到后代整体的植株高度符合要求。分子的定向进化也类似于这个过程。<br>&emsp;&emsp;前言部分只是简单的介绍了下背景，感兴趣的同学可以去深入了解。大家可以想一下为什么<code>酶定向进化</code>和<code>肽和抗体噬菌体展示</code>一起获得2018年诺贝尔化学奖。</p><p><a href="https://www.nature.shu.edu.cn/CN/10.3969/j.issn.0253-9608.2018.06.004"><img src="https://s21.ax1x.com/2025/05/18/pEv672q.png" alt="pEv672q.png"></a></p><h2 id="1-EvolvePro环境安装"><a href="#1-EvolvePro环境安装" class="headerlink" title="1. EvolvePro环境安装"></a>1. EvolvePro环境安装</h2><p>需要预安装的一些软件，包括：</p><ol><li><code>conda</code></li><li><code>CUDA驱动</code></li><li><code>Slurm</code>作业提交系统</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">## 1. EvolvePro的安装</span>git clone https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>mat10d<span class="token operator">/</span>EvolvePro<span class="token punctuation">.</span>gitcd EvolveProconda env create <span class="token operator">-</span>f environment<span class="token punctuation">.</span>ymlconda activate evolvepro<span class="token comment">## 2. 安装依赖</span><span class="token comment">### 感觉不是必须</span><span class="token comment">### 众所周知的原因，大陆地区这里可能会失败，多试几次就好了（雾</span>sh setup_plm<span class="token punctuation">.</span>shconda activate plm<span class="token comment"># 切换回evolvepro</span>conda activate evolvepro<span class="token comment">## 3. Download Pretrained models</span><span class="token comment"># wget https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt</span>cd  data<span class="token operator">/</span>chaofan<span class="token operator">/</span>projects<span class="token operator">/</span><span class="token number">08</span><span class="token punctuation">.</span>Directed_evolution<span class="token operator">/</span><span class="token number">00</span><span class="token punctuation">.</span>EVOLVEpro <span class="token comment"># 工作文件夹</span>wget https<span class="token punctuation">:</span><span class="token operator">//</span>dl<span class="token punctuation">.</span>fbaipublicfiles<span class="token punctuation">.</span>com<span class="token operator">/</span>fair<span class="token operator">-</span>esm<span class="token operator">/</span>models<span class="token operator">/</span>esm1b_t33_650M_UR50S<span class="token punctuation">.</span>ptwget https<span class="token punctuation">:</span><span class="token operator">//</span>dl<span class="token punctuation">.</span>fbaipublicfiles<span class="token punctuation">.</span>com<span class="token operator">/</span>fair<span class="token operator">-</span>esm<span class="token operator">/</span>regression<span class="token operator">/</span>esm1b_t33_650M_UR50S<span class="token operator">-</span>contact<span class="token operator">-</span>regression<span class="token punctuation">.</span>pt<span class="token comment"># wget https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt</span><span class="token comment"># wget https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt</span><span class="token comment">### esm2用在下游任务上会比esm1b好一点</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;有两条路，一条是多轮实验迭代，每轮实验加入新测量的表型值；另一条是基于深度突变扫描的数据。</p><h2 id="2-代码实现-Experimental-Workflow"><a href="#2-代码实现-Experimental-Workflow" class="headerlink" title="2. 代码实现 (Experimental Workflow)"></a>2. 代码实现 (Experimental Workflow)</h2><h3 id="2-1-构建单氨基酸突变文库"><a href="#2-1-构建单氨基酸突变文库" class="headerlink" title="2.1 构建单氨基酸突变文库"></a>2.1 构建单氨基酸突变文库</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>process <span class="token keyword">import</span> generate_wt<span class="token punctuation">,</span> generate_single_aa_mutantsgenerate_wt<span class="token punctuation">(</span><span class="token string">'MAKEDNIEMQGTVLETLPNTMFRVELENGHVVTAHISGKMRKNYIRILTGDKVTVELTPYDLSKGRIVFRSR'</span><span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">'./kelsic_WT.fasta'</span><span class="token punctuation">)</span>generate_single_aa_mutants<span class="token punctuation">(</span><span class="token string">'./kelsic_WT.fasta'</span><span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">'./kelsic.fasta'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Number of mutants: 1369<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>process <span class="token keyword">import</span> suggest_initial_mutantssuggest_initial_mutants<span class="token punctuation">(</span><span class="token string">'./kelsic.fasta'</span><span class="token punctuation">,</span> num_mutants<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span> random_seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Suggested 12 mutants for testing:1. R23K2. T58E3. I36D4. V31C5. I7A6. K3F7. Q10P8. G38E9. E4M10. D61W11. E4Y12. R23N<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们随机的从单突变体文库中挑选这12条突变序列进行模型初始的训练，这12条序列与后续的Round1.xlsx文件是对应的。</p><h3 id="2-2-获取Protein-Language-model的编码矩阵"><a href="#2-2-获取Protein-Language-model的编码矩阵" class="headerlink" title="2.2 获取Protein Language model的编码矩阵"></a>2.2 获取Protein Language model的编码矩阵</h3><p><code>BERT</code>语言模型能很好的将离散的文本序列转换为数值型的特征矩阵，广泛运用于文本分类任务</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">!mkdir <span class="token operator">-</span>p Single_mutation_concatenate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 如提前下好了预训练模型，通过 .pt 结尾文件代表本地加载权重，如没有 .pt后缀，默认会重新下载权重文件。</span>!python <span class="token operator">/</span>data<span class="token operator">/</span>chaofan<span class="token operator">/</span>software<span class="token operator">/</span>EvolvePro<span class="token operator">/</span>evolvepro<span class="token operator">/</span>plm<span class="token operator">/</span>esm<span class="token operator">/</span>extract<span class="token punctuation">.</span>py esm1b_t33_650M_UR50S<span class="token punctuation">.</span>pt <span class="token punctuation">.</span><span class="token operator">/</span>kelsic<span class="token punctuation">.</span>fasta <span class="token punctuation">.</span><span class="token operator">/</span>kelsic_esm1b_t33_650M_UR50S <span class="token operator">-</span><span class="token operator">-</span>toks_per_batch <span class="token number">512</span> <span class="token operator">-</span><span class="token operator">-</span>include mean <span class="token operator">-</span><span class="token operator">-</span>concatenate_dir <span class="token punctuation">.</span><span class="token operator">/</span>Single_mutation_concatenate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Transferred model to GPURead kelsic.fasta with 1369 sequencesProcessing 1 of 196 batches (7 sequences)Device: cuda:0Processing 2 of 196 batches (7 sequences)Device: cuda:0Processing 3 of 196 batches (7 sequences)Device: cuda:0Processing 4 of 196 batches (7 sequences)Device: cuda:0Processing 5 of 196 batches (7 sequences)Device: cuda:0Processing 6 of 196 batches (7 sequences)Device: cuda:0Processing 7 of 196 batches (7 sequences)Device: cuda:0Processing 8 of 196 batches (7 sequences)Device: cuda:0Processing 9 of 196 batches (7 sequences)Device: cuda:0Processing 10 of 196 batches (7 sequences)Device: cuda:0Processing 11 of 196 batches (7 sequences)Device: cuda:0Processing 12 of 196 batches (7 sequences)Device: cuda:0Processing 13 of 196 batches (7 sequences)Device: cuda:0Processing 14 of 196 batches (7 sequences)Device: cuda:0Processing 15 of 196 batches (7 sequences)Device: cuda:0Processing 16 of 196 batches (7 sequences)Device: cuda:0Processing 17 of 196 batches (7 sequences)Device: cuda:0Processing 18 of 196 batches (7 sequences)Device: cuda:0Processing 19 of 196 batches (7 sequences)Device: cuda:0Processing 20 of 196 batches (7 sequences)Device: cuda:0Processing 21 of 196 batches (7 sequences)Device: cuda:0Processing 22 of 196 batches (7 sequences)Device: cuda:0Processing 23 of 196 batches (7 sequences)Device: cuda:0Processing 24 of 196 batches (7 sequences)Device: cuda:0Processing 25 of 196 batches (7 sequences)Device: cuda:0Processing 26 of 196 batches (7 sequences)Device: cuda:0Processing 27 of 196 batches (7 sequences)Device: cuda:0Processing 28 of 196 batches (7 sequences)Device: cuda:0Processing 29 of 196 batches (7 sequences)Device: cuda:0Processing 30 of 196 batches (7 sequences)Device: cuda:0Processing 31 of 196 batches (7 sequences)Device: cuda:0Processing 32 of 196 batches (7 sequences)Device: cuda:0Processing 33 of 196 batches (7 sequences)Device: cuda:0Processing 34 of 196 batches (7 sequences)Device: cuda:0Processing 35 of 196 batches (7 sequences)Device: cuda:0Processing 36 of 196 batches (7 sequences)Device: cuda:0Processing 37 of 196 batches (7 sequences)Device: cuda:0Processing 38 of 196 batches (7 sequences)Device: cuda:0Processing 39 of 196 batches (7 sequences)Device: cuda:0Processing 40 of 196 batches (7 sequences)Device: cuda:0Processing 41 of 196 batches (7 sequences)Device: cuda:0Processing 42 of 196 batches (7 sequences)Device: cuda:0Processing 43 of 196 batches (7 sequences)Device: cuda:0Processing 44 of 196 batches (7 sequences)Device: cuda:0Processing 45 of 196 batches (7 sequences)Device: cuda:0Processing 46 of 196 batches (7 sequences)Device: cuda:0Processing 47 of 196 batches (7 sequences)Device: cuda:0Processing 48 of 196 batches (7 sequences)Device: cuda:0Processing 49 of 196 batches (7 sequences)Device: cuda:0Processing 50 of 196 batches (7 sequences)Device: cuda:0Processing 51 of 196 batches (7 sequences)Device: cuda:0Processing 52 of 196 batches (7 sequences)Device: cuda:0Processing 53 of 196 batches (7 sequences)Device: cuda:0Processing 54 of 196 batches (7 sequences)Device: cuda:0Processing 55 of 196 batches (7 sequences)Device: cuda:0Processing 56 of 196 batches (7 sequences)Device: cuda:0Processing 57 of 196 batches (7 sequences)Device: cuda:0Processing 58 of 196 batches (7 sequences)Device: cuda:0Processing 59 of 196 batches (7 sequences)Device: cuda:0Processing 60 of 196 batches (7 sequences)Device: cuda:0Processing 61 of 196 batches (7 sequences)Device: cuda:0Processing 62 of 196 batches (7 sequences)Device: cuda:0Processing 63 of 196 batches (7 sequences)Device: cuda:0Processing 64 of 196 batches (7 sequences)Device: cuda:0Processing 65 of 196 batches (7 sequences)Device: cuda:0Processing 66 of 196 batches (7 sequences)Device: cuda:0Processing 67 of 196 batches (7 sequences)Device: cuda:0Processing 68 of 196 batches (7 sequences)Device: cuda:0Processing 69 of 196 batches (7 sequences)Device: cuda:0Processing 70 of 196 batches (7 sequences)Device: cuda:0Processing 71 of 196 batches (7 sequences)Device: cuda:0Processing 72 of 196 batches (7 sequences)Device: cuda:0Processing 73 of 196 batches (7 sequences)Device: cuda:0Processing 74 of 196 batches (7 sequences)Device: cuda:0Processing 75 of 196 batches (7 sequences)Device: cuda:0Processing 76 of 196 batches (7 sequences)Device: cuda:0Processing 77 of 196 batches (7 sequences)Device: cuda:0Processing 78 of 196 batches (7 sequences)Device: cuda:0Processing 79 of 196 batches (7 sequences)Device: cuda:0Processing 80 of 196 batches (7 sequences)Device: cuda:0Processing 81 of 196 batches (7 sequences)Device: cuda:0Processing 82 of 196 batches (7 sequences)Device: cuda:0Processing 83 of 196 batches (7 sequences)Device: cuda:0Processing 84 of 196 batches (7 sequences)Device: cuda:0Processing 85 of 196 batches (7 sequences)Device: cuda:0Processing 86 of 196 batches (7 sequences)Device: cuda:0Processing 87 of 196 batches (7 sequences)Device: cuda:0Processing 88 of 196 batches (7 sequences)Device: cuda:0Processing 89 of 196 batches (7 sequences)Device: cuda:0Processing 90 of 196 batches (7 sequences)Device: cuda:0Processing 91 of 196 batches (7 sequences)Device: cuda:0Processing 92 of 196 batches (7 sequences)Device: cuda:0Processing 93 of 196 batches (7 sequences)Device: cuda:0Processing 94 of 196 batches (7 sequences)Device: cuda:0Processing 95 of 196 batches (7 sequences)Device: cuda:0Processing 96 of 196 batches (7 sequences)Device: cuda:0Processing 97 of 196 batches (7 sequences)Device: cuda:0Processing 98 of 196 batches (7 sequences)Device: cuda:0Processing 99 of 196 batches (7 sequences)Device: cuda:0Processing 100 of 196 batches (7 sequences)Device: cuda:0Processing 101 of 196 batches (7 sequences)Device: cuda:0Processing 102 of 196 batches (7 sequences)Device: cuda:0Processing 103 of 196 batches (7 sequences)Device: cuda:0Processing 104 of 196 batches (7 sequences)Device: cuda:0Processing 105 of 196 batches (7 sequences)Device: cuda:0Processing 106 of 196 batches (7 sequences)Device: cuda:0Processing 107 of 196 batches (7 sequences)Device: cuda:0Processing 108 of 196 batches (7 sequences)Device: cuda:0Processing 109 of 196 batches (7 sequences)Device: cuda:0Processing 110 of 196 batches (7 sequences)Device: cuda:0Processing 111 of 196 batches (7 sequences)Device: cuda:0Processing 112 of 196 batches (7 sequences)Device: cuda:0Processing 113 of 196 batches (7 sequences)Device: cuda:0Processing 114 of 196 batches (7 sequences)Device: cuda:0Processing 115 of 196 batches (7 sequences)Device: cuda:0Processing 116 of 196 batches (7 sequences)Device: cuda:0Processing 117 of 196 batches (7 sequences)Device: cuda:0Processing 118 of 196 batches (7 sequences)Device: cuda:0Processing 119 of 196 batches (7 sequences)Device: cuda:0Processing 120 of 196 batches (7 sequences)Device: cuda:0Processing 121 of 196 batches (7 sequences)Device: cuda:0Processing 122 of 196 batches (7 sequences)Device: cuda:0Processing 123 of 196 batches (7 sequences)Device: cuda:0Processing 124 of 196 batches (7 sequences)Device: cuda:0Processing 125 of 196 batches (7 sequences)Device: cuda:0Processing 126 of 196 batches (7 sequences)Device: cuda:0Processing 127 of 196 batches (7 sequences)Device: cuda:0Processing 128 of 196 batches (7 sequences)Device: cuda:0Processing 129 of 196 batches (7 sequences)Device: cuda:0Processing 130 of 196 batches (7 sequences)Device: cuda:0Processing 131 of 196 batches (7 sequences)Device: cuda:0Processing 132 of 196 batches (7 sequences)Device: cuda:0Processing 133 of 196 batches (7 sequences)Device: cuda:0Processing 134 of 196 batches (7 sequences)Device: cuda:0Processing 135 of 196 batches (7 sequences)Device: cuda:0Processing 136 of 196 batches (7 sequences)Device: cuda:0Processing 137 of 196 batches (7 sequences)Device: cuda:0Processing 138 of 196 batches (7 sequences)Device: cuda:0Processing 139 of 196 batches (7 sequences)Device: cuda:0Processing 140 of 196 batches (7 sequences)Device: cuda:0Processing 141 of 196 batches (7 sequences)Device: cuda:0Processing 142 of 196 batches (7 sequences)Device: cuda:0Processing 143 of 196 batches (7 sequences)Device: cuda:0Processing 144 of 196 batches (7 sequences)Device: cuda:0Processing 145 of 196 batches (7 sequences)Device: cuda:0Processing 146 of 196 batches (7 sequences)Device: cuda:0Processing 147 of 196 batches (7 sequences)Device: cuda:0Processing 148 of 196 batches (7 sequences)Device: cuda:0Processing 149 of 196 batches (7 sequences)Device: cuda:0Processing 150 of 196 batches (7 sequences)Device: cuda:0Processing 151 of 196 batches (7 sequences)Device: cuda:0Processing 152 of 196 batches (7 sequences)Device: cuda:0Processing 153 of 196 batches (7 sequences)Device: cuda:0Processing 154 of 196 batches (7 sequences)Device: cuda:0Processing 155 of 196 batches (7 sequences)Device: cuda:0Processing 156 of 196 batches (7 sequences)Device: cuda:0Processing 157 of 196 batches (7 sequences)Device: cuda:0Processing 158 of 196 batches (7 sequences)Device: cuda:0Processing 159 of 196 batches (7 sequences)Device: cuda:0Processing 160 of 196 batches (7 sequences)Device: cuda:0Processing 161 of 196 batches (7 sequences)Device: cuda:0Processing 162 of 196 batches (7 sequences)Device: cuda:0Processing 163 of 196 batches (7 sequences)Device: cuda:0Processing 164 of 196 batches (7 sequences)Device: cuda:0Processing 165 of 196 batches (7 sequences)Device: cuda:0Processing 166 of 196 batches (7 sequences)Device: cuda:0Processing 167 of 196 batches (7 sequences)Device: cuda:0Processing 168 of 196 batches (7 sequences)Device: cuda:0Processing 169 of 196 batches (7 sequences)Device: cuda:0Processing 170 of 196 batches (7 sequences)Device: cuda:0Processing 171 of 196 batches (7 sequences)Device: cuda:0Processing 172 of 196 batches (7 sequences)Device: cuda:0Processing 173 of 196 batches (7 sequences)Device: cuda:0Processing 174 of 196 batches (7 sequences)Device: cuda:0Processing 175 of 196 batches (7 sequences)Device: cuda:0Processing 176 of 196 batches (7 sequences)Device: cuda:0Processing 177 of 196 batches (7 sequences)Device: cuda:0Processing 178 of 196 batches (7 sequences)Device: cuda:0Processing 179 of 196 batches (7 sequences)Device: cuda:0Processing 180 of 196 batches (7 sequences)Device: cuda:0Processing 181 of 196 batches (7 sequences)Device: cuda:0Processing 182 of 196 batches (7 sequences)Device: cuda:0Processing 183 of 196 batches (7 sequences)Device: cuda:0Processing 184 of 196 batches (7 sequences)Device: cuda:0Processing 185 of 196 batches (7 sequences)Device: cuda:0Processing 186 of 196 batches (7 sequences)Device: cuda:0Processing 187 of 196 batches (7 sequences)Device: cuda:0Processing 188 of 196 batches (7 sequences)Device: cuda:0Processing 189 of 196 batches (7 sequences)Device: cuda:0Processing 190 of 196 batches (7 sequences)Device: cuda:0Processing 191 of 196 batches (7 sequences)Device: cuda:0Processing 192 of 196 batches (7 sequences)Device: cuda:0Processing 193 of 196 batches (7 sequences)Device: cuda:0Processing 194 of 196 batches (7 sequences)Device: cuda:0Processing 195 of 196 batches (7 sequences)Device: cuda:0Processing 196 of 196 batches (4 sequences)Device: cuda:0Saved representations to kelsic_esm1b_t33_650M_UR50SShape of concatenated DataFrame: (1369, 1280)Saved concatenated representations to Single_mutation_concatenate/kelsic_esm1b_t33_650M_UR50S.pt.csv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因为频繁出现注入攻击，现pytorch强制要求加载权重时是否相信来源，此处需要修改<code>/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/esm/pretrained.py</code>代码， 在第70行调用函数处加上<code>weights_only=False</code>。<br><a href="https://imgse.com/i/pEj78Ds"><img src="https://s21.ax1x.com/2025/05/15/pEj78Ds.png" alt="pEj78Ds.png"></a></p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">Number <span class="token keyword">of</span> <span class="token literal-property property">mutants</span><span class="token operator">:</span> <span class="token number">1369</span><span class="token function">Traceback</span> <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token operator">:</span>  File <span class="token string">"/data/chaofan/software/EvolvePro/evolvepro/plm/esm/extract.py"</span><span class="token punctuation">,</span> line <span class="token number">193</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/data/chaofan/software/EvolvePro/evolvepro/plm/esm/extract.py"</span><span class="token punctuation">,</span> line <span class="token number">181</span><span class="token punctuation">,</span> <span class="token keyword">in</span> main    <span class="token function">run</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>  File <span class="token string">"/data/chaofan/software/EvolvePro/evolvepro/plm/esm/extract.py"</span><span class="token punctuation">,</span> line <span class="token number">73</span><span class="token punctuation">,</span> <span class="token keyword">in</span> run    model<span class="token punctuation">,</span> alphabet <span class="token operator">=</span> pretrained<span class="token punctuation">.</span><span class="token function">load_model_and_alphabet</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_location<span class="token punctuation">)</span>                      <span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>  File <span class="token string">"/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/esm/pretrained.py"</span><span class="token punctuation">,</span> line <span class="token number">26</span><span class="token punctuation">,</span> <span class="token keyword">in</span> load_model_and_alphabet    <span class="token keyword">return</span> <span class="token function">load_model_and_alphabet_local</span><span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>           <span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>  File <span class="token string">"/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/esm/pretrained.py"</span><span class="token punctuation">,</span> line <span class="token number">70</span><span class="token punctuation">,</span> <span class="token keyword">in</span> load_model_and_alphabet_local    model_data <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token function">str</span><span class="token punctuation">(</span>model_location<span class="token punctuation">)</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>                 <span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>  File <span class="token string">"/data/chaofan/miniconda3/envs/evolvepro/lib/python3.11/site-packages/torch/serialization.py"</span><span class="token punctuation">,</span> line <span class="token number">1470</span><span class="token punctuation">,</span> <span class="token keyword">in</span> load    raise pickle<span class="token punctuation">.</span><span class="token function">UnpicklingError</span><span class="token punctuation">(</span><span class="token function">_get_wo_message</span><span class="token punctuation">(</span><span class="token function">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> from None_pickle<span class="token punctuation">.</span>UnpicklingError<span class="token operator">:</span> Weights only load failed<span class="token punctuation">.</span> This file can still be loaded<span class="token punctuation">,</span> to <span class="token keyword">do</span> so you have two options<span class="token punctuation">,</span> <span class="token keyword">do</span> those steps only <span class="token keyword">if</span> you trust the source <span class="token keyword">of</span> the checkpoint<span class="token punctuation">.</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> In PyTorch <span class="token number">2.6</span><span class="token punctuation">,</span> we changed the <span class="token keyword">default</span> value <span class="token keyword">of</span> the <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">weights_only</span><span class="token template-punctuation string">`</span></span> argument <span class="token keyword">in</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.load</span><span class="token template-punctuation string">`</span></span> <span class="token keyword">from</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">False</span><span class="token template-punctuation string">`</span></span> to <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">True</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">.</span> Re<span class="token operator">-</span>running <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.load</span><span class="token template-punctuation string">`</span></span> <span class="token keyword">with</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">weights_only</span><span class="token template-punctuation string">`</span></span> <span class="token keyword">set</span> to <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">False</span><span class="token template-punctuation string">`</span></span> will likely succeed<span class="token punctuation">,</span> but it can result <span class="token keyword">in</span> arbitrary code execution<span class="token punctuation">.</span> Do it only <span class="token keyword">if</span> you got the file from a trusted source<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> Alternatively<span class="token punctuation">,</span> to load <span class="token keyword">with</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">weights_only=True</span><span class="token template-punctuation string">`</span></span> please check the recommended steps <span class="token keyword">in</span> the following error message<span class="token punctuation">.</span>WeightsUnpickler error<span class="token operator">:</span> Unsupported global<span class="token operator">:</span> <span class="token constant">GLOBAL</span> argparse<span class="token punctuation">.</span>Namespace was not an allowed global by <span class="token keyword">default</span><span class="token punctuation">.</span> Please use <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.serialization.add_safe_globals([Namespace])</span><span class="token template-punctuation string">`</span></span> or the <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">torch.serialization.safe_globals([Namespace])</span><span class="token template-punctuation string">`</span></span> context manager to allowlist <span class="token keyword">this</span> global <span class="token keyword">if</span> you trust <span class="token keyword">this</span> <span class="token keyword">class</span><span class="token operator">/</span><span class="token keyword">function</span><span class="token punctuation">.</span>Check the documentation <span class="token keyword">of</span> torch<span class="token punctuation">.</span>load to learn more about types accepted by <span class="token keyword">default</span> <span class="token keyword">with</span> weights_only https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>pytorch<span class="token punctuation">.</span>org<span class="token operator">/</span>docs<span class="token operator">/</span>stable<span class="token operator">/</span>generated<span class="token operator">/</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">.</span>html<span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>经过上述步骤，每条文本的氨基酸序列被一个长为1280的数值向量代替，表格中一共有1369条序列，分别是一条野生型+1368条(19*野生型序列长度)单氨基酸变异序列</p><h3 id="2-3-对模型进行多轮few-shot训练"><a href="#2-3-对模型进行多轮few-shot训练" class="headerlink" title="2.3 对模型进行多轮few-shot训练"></a>2.3 对模型进行多轮few-shot训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>evolve <span class="token keyword">import</span> evolve_experimentalprotein_name <span class="token operator">=</span> <span class="token string">'kelsic'</span>embeddings_base_path <span class="token operator">=</span> <span class="token string">'Single_mutation_concatenate'</span>embeddings_file_name <span class="token operator">=</span> <span class="token string">'kelsic_esm1b_t33_650M_UR50S.pt.csv'</span>round_base_path <span class="token operator">=</span> <span class="token string">'/data/chaofan/software/EvolvePro/colab/rounds_data'</span>wt_fasta_path <span class="token operator">=</span> <span class="token string">"./kelsic_WT.fasta"</span>number_of_variants <span class="token operator">=</span> <span class="token number">12</span>output_dir <span class="token operator">=</span> <span class="token string">'./'</span>rename_WT <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-1-Round1"><a href="#2-3-1-Round1" class="headerlink" title="2.3.1 Round1"></a>2.3.1 Round1</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round1'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round1    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    iteration shape: (12, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1357,)        Tested variants in this round: 12    43       K3F    67       E4M    76       E4Y    115      I7A    184     Q10P    427     R23K    430     R23N    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    Name: variant, dtype: object        Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary dist_metric  \    74      E4V  0.954787       NaN              NaN              NaN        None       225    T12S  0.952057       NaN              NaN              NaN        None       5       M1F  0.951310       NaN              NaN              NaN        None       63      E4H  0.950540       NaN              NaN              NaN        None       15      M1S  0.947988       NaN              NaN              NaN        None       19      M1Y  0.944838       NaN              NaN              NaN        None       18      M1W  0.944590       NaN              NaN              NaN        None       249    L14C  0.942195       NaN              NaN              NaN        None       61      E4F  0.942045       NaN              NaN              NaN        None       10      M1L  0.941873       NaN              NaN              NaN        None       142     E8L  0.941533       NaN              NaN              NaN        None       135     E8C  0.941173       NaN              NaN              NaN        None                std_predictions      74               0.0      225              0.0      5                0.0      63               0.0      15               0.0      19               0.0      18               0.0      249              0.0      61               0.0      10               0.0      142              0.0      135              0.0          Data saved to ./kelsic/Round1    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;模型的设计非常简单，主要是用预训练的BERT模型去抽特征，然后用传统的机器学习方法(随机森林，XGBoost等)对特征进行回归分析。第一轮使用<code>12</code>条随机数据进行训练，第二列使用<code>12 * 2</code>条数据重新训练，以此类推，第N轮使用<code>12 * N</code>条数据进行训练。每轮只训练顶层的传统机器学习模型。<br>&emsp;&emsp;训练后的模型先对整个突变体库扫一遍，对每个突变体进行表型值打分并排序，取预测表型值最好的<code>12</code>个突变体（且没有真实表型值）进行真实表型值验证。将新测量的真实表型值加入到下一轮的模型训练中，也就是每一轮过后，训练数据集会多出<code>12</code>条。按道理来说，<code>Round2.xlsx</code>的数据应该是上一轮预测的Top12突变体的真实表型值，但因为不同软件版本的差异，这里展示的结果可能会与原文有一定的差异，这是正常现象。</p><p><a href="https://www.science.org/cms/10.1126/science.adr6006/asset/65d73316-daa4-4525-93cf-b07d2f0254b2/assets/images/large/science.adr6006-f1.jpg"><img src="https://s21.ax1x.com/2025/05/15/pEjbkTI.png" alt="pEjbkTI.png"></a></p><h4 id="2-3-2-Round2"><a href="#2-3-2-Round2" class="headerlink" title="2.3.2 Round2"></a>2.3.2 Round2</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round2'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round2    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    Loaded experimental data for kelsic_Round2.xlsx: (12, 3)    iteration shape: (24, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1345,)        Tested variants in this round: 24    43       K3F    61       E4F    63       E4H    66       E4L    67       E4M    68       E4N    70       E4Q    74       E4V    76       E4Y    86       D5M    115      I7A    135      E8C    146      E8Q    184     Q10P    211     T12C    220     T12M    427     R23K    430     R23N    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    1332    S71C    Name: variant, dtype: object        Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary dist_metric  \    80      D5F  1.000372       NaN              NaN              NaN        None       75      E4W  0.990040       NaN              NaN              NaN        None       64      E4I  0.982857       NaN              NaN              NaN        None       83      D5I  0.977915       NaN              NaN              NaN        None       95      D5Y  0.974122       NaN              NaN              NaN        None       85      D5L  0.971400       NaN              NaN              NaN        None       93      D5V  0.970972       NaN              NaN              NaN        None       62      E4G  0.970870       NaN              NaN              NaN        None       469    E25Q  0.969735       NaN              NaN              NaN        None       7       M1H  0.967748       NaN              NaN              NaN        None       94      D5W  0.967325       NaN              NaN              NaN        None       578    V31I  0.967287       NaN              NaN              NaN        None                std_predictions      80               0.0      75               0.0      64               0.0      83               0.0      95               0.0      85               0.0      93               0.0      62               0.0      469              0.0      7                0.0      94               0.0      578              0.0          Data saved to ./kelsic/Round2    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-3-Round3"><a href="#2-3-3-Round3" class="headerlink" title="2.3.3 Round3"></a>2.3.3 Round3</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round3'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round3    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    Loaded experimental data for kelsic_Round2.xlsx: (12, 3)    Loaded experimental data for kelsic_Round3.xlsx: (12, 3)    iteration shape: (36, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1333,)        Tested variants in this round: 36    18       M1W    43       K3F    59       E4C    61       E4F    63       E4H    64       E4I    66       E4L    67       E4M    68       E4N    70       E4Q    74       E4V    75       E4W    76       E4Y    78       D5C    80       D5F    83       D5I    85       D5L    86       D5M    87       D5N    93       D5V    95       D5Y    115      I7A    135      E8C    146      E8Q    184     Q10P    211     T12C    220     T12M    427     R23K    430     R23N    469     E25Q    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    1332    S71C    Name: variant, dtype: object        Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary dist_metric  \    82      D5H  0.985537       NaN              NaN              NaN        None       77      D5A  0.974578       NaN              NaN              NaN        None       91      D5S  0.973428       NaN              NaN              NaN        None       89      D5Q  0.972064       NaN              NaN              NaN        None       504    E27M  0.964911       NaN              NaN              NaN        None       496    E27C  0.959024       NaN              NaN              NaN        None       500    E27H  0.958966       NaN              NaN              NaN        None       71      E4R  0.957292       NaN              NaN              NaN        None       92      D5T  0.956897       NaN              NaN              NaN        None       137     E8F  0.953024       NaN              NaN              NaN        None       505    E27N  0.952960       NaN              NaN              NaN        None       143     E8M  0.952932       NaN              NaN              NaN        None                std_predictions      82               0.0      77               0.0      91               0.0      89               0.0      504              0.0      496              0.0      500              0.0      71               0.0      92               0.0      137              0.0      505              0.0      143              0.0          Data saved to ./kelsic/Round3    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-4-Round4"><a href="#2-3-4-Round4" class="headerlink" title="2.3.4 Round4"></a>2.3.4 Round4</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round4'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round4.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round4    Embeddings loaded: (1369, 1280)    Loaded experimental data for kelsic_Round1.xlsx: (12, 3)    Loaded experimental data for kelsic_Round2.xlsx: (12, 3)    Loaded experimental data for kelsic_Round3.xlsx: (12, 3)    Loaded experimental data for kelsic_Round4.xlsx: (12, 3)    iteration shape: (48, 2)    Labels shape: (1369, 5)    Embeddings and labels are aligned    (1321,)        Tested variants in this round: 48    18       M1W    43       K3F    59       E4C    61       E4F    63       E4H    64       E4I    66       E4L    67       E4M    68       E4N    70       E4Q    73       E4T    74       E4V    75       E4W    76       E4Y    77       D5A    78       D5C    80       D5F    82       D5H    83       D5I    85       D5L    86       D5M    87       D5N    89       D5Q    91       D5S    92       D5T    93       D5V    95       D5Y    115      I7A    135      E8C    146      E8Q    184     Q10P    211     T12C    220     T12M    390     M21L    427     R23K    430     R23N    445     V24I    469     E25Q    496     E27C    503     E27L    504     E27M    507     E27Q    572     V31C    668     I36D    707     G38E    1087    T58E    1158    D61W    1332    S71C    Name: variant, dtype: object        Top 12 variants predicted by the model:         variant    y_pred  y_actual  y_actual_scaled  y_actual_binary  \    72       E4S  0.978078       NaN              NaN              NaN       94       D5W  0.977183       NaN              NaN              NaN       69       E4P  0.973912       NaN              NaN              NaN       1281    V68I  0.962484       NaN              NaN              NaN       90       D5R  0.951873       NaN              NaN              NaN       71       E4R  0.948736       NaN              NaN              NaN       88       D5P  0.947673       NaN              NaN              NaN       144      E8N  0.947493       NaN              NaN              NaN       141      E8K  0.947032       NaN              NaN              NaN       1034    V55I  0.945509       NaN              NaN              NaN       616     T33I  0.944996       NaN              NaN              NaN       470     E25R  0.944632       NaN              NaN              NaN                dist_metric  std_predictions      72          None              0.0      94          None              0.0      69          None              0.0      1281        None              0.0      90          None              0.0      71          None              0.0      88          None              0.0      144         None              0.0      141         None              0.0      1034        None              0.0      616         None              0.0      470         None              0.0          Data saved to ./kelsic/Round4    /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.      df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-5-Round5"><a href="#2-3-5-Round5" class="headerlink" title="2.3.5 Round5"></a>2.3.5 Round5</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">round_name <span class="token operator">=</span> <span class="token string">'Round5'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round4.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round5.xlsx'</span><span class="token punctuation">]</span>this_round_variants<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> df_sorted_all <span class="token operator">=</span> evolve_experimental<span class="token punctuation">(</span>    protein_name<span class="token punctuation">,</span>    round_name<span class="token punctuation">,</span>    embeddings_base_path<span class="token punctuation">,</span>    embeddings_file_name<span class="token punctuation">,</span>    round_base_path<span class="token punctuation">,</span>    round_file_names<span class="token punctuation">,</span>    wt_fasta_path<span class="token punctuation">,</span>    rename_WT<span class="token punctuation">,</span>    number_of_variants<span class="token punctuation">,</span>    output_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Processing kelsic - Round5   Embeddings loaded: (1369, 1280)   Loaded experimental data for kelsic_Round1.xlsx: (12, 3)   Loaded experimental data for kelsic_Round2.xlsx: (12, 3)   Loaded experimental data for kelsic_Round3.xlsx: (12, 3)   Loaded experimental data for kelsic_Round4.xlsx: (12, 3)   Loaded experimental data for kelsic_Round5.xlsx: (12, 3)   iteration shape: (60, 2)   Labels shape: (1369, 5)   Embeddings and labels are aligned   (1309,)      Tested variants in this round: 60   18       M1W   43       K3F   58       E4A   59       E4C   61       E4F   63       E4H   64       E4I   66       E4L   67       E4M   68       E4N   69       E4P   70       E4Q   72       E4S   73       E4T   74       E4V   75       E4W   76       E4Y   77       D5A   78       D5C   80       D5F   82       D5H   83       D5I   85       D5L   86       D5M   87       D5N   88       D5P   89       D5Q   91       D5S   92       D5T   93       D5V   94       D5W   95       D5Y   115      I7A   135      E8C   137      E8F   139      E8H   141      E8K   146      E8Q   178     Q10H   184     Q10P   211     T12C   220     T12M   368     T20H   390     M21L   427     R23K   430     R23N   445     V24I   469     E25Q   496     E27C   503     E27L   504     E27M   507     E27Q   572     V31C   668     I36D   707     G38E   1034    V55I   1087    T58E   1158    D61W   1332    S71C   1339    S71K   Name: variant, dtype: object      Top 12 variants predicted by the model:        variant    y_pred  y_actual  y_actual_scaled  y_actual_binary  \   114      N6Y  0.954242       NaN              NaN              NaN      373     T20N  0.950471       NaN              NaN              NaN      65       E4K  0.950415       NaN              NaN              NaN      226     T12V  0.949447       NaN              NaN              NaN      1281    V68I  0.947393       NaN              NaN              NaN      464     E25K  0.947118       NaN              NaN              NaN      71       E4R  0.946143       NaN              NaN              NaN      144      E8N  0.940163       NaN              NaN              NaN      628     A34C  0.937827       NaN              NaN              NaN      1349    S71Y  0.936767       NaN              NaN              NaN      1169    L62M  0.934671       NaN              NaN              NaN      370     T20K  0.934475       NaN              NaN              NaN              dist_metric  std_predictions     114         None              0.0     373         None              0.0     65          None              0.0     226         None              0.0     1281        None              0.0     464         None              0.0     71          None              0.0     144         None              0.0     628         None              0.0     1349        None              0.0     1169        None              0.0     370         None              0.0        Data saved to ./kelsic/Round5   /data/chaofan/software/EvolvePro/evolvepro/src/model.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.     df_all = pd.concat([df_train, df_test])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-6-plot"><a href="#2-3-6-plot" class="headerlink" title="2.3.6 plot"></a>2.3.6 plot</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> evolvepro<span class="token punctuation">.</span>src<span class="token punctuation">.</span>plot <span class="token keyword">import</span> read_exp_data<span class="token punctuation">,</span> plot_variants_by_iterationround_base_path <span class="token operator">=</span> <span class="token string">'/data/chaofan/software/EvolvePro/colab/rounds_data'</span>round_file_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'kelsic_Round1.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round2.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round3.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round4.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'kelsic_Round5.xlsx'</span><span class="token punctuation">]</span>wt_fasta_path <span class="token operator">=</span> <span class="token string">"./kelsic_WT.fasta"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> read_exp_data<span class="token punctuation">(</span>round_base_path<span class="token punctuation">,</span> round_file_names<span class="token punctuation">,</span> wt_fasta_path<span class="token punctuation">)</span>plot_variants_by_iteration<span class="token punctuation">(</span>df<span class="token punctuation">,</span> activity_column<span class="token operator">=</span><span class="token string">'activity'</span><span class="token punctuation">,</span> output_dir<span class="token operator">=</span>output_dir<span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">"kelsic"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pEv2D54"><img src="https://s21.ax1x.com/2025/05/18/pEv2D54.png" alt="pEv2D54.png"></a></p><h2 id="3-代码实现-Deep-Mutational-Scanning-Workflow"><a href="#3-代码实现-Deep-Mutational-Scanning-Workflow" class="headerlink" title="3. 代码实现 (Deep Mutational Scanning Workflow)"></a>3. 代码实现 (Deep Mutational Scanning Workflow)</h2><p>DMS数据集包含具体的突变位点和表型数据，我们需要生成突变体文库对应的fasta和embedding特征矩阵，才能进行下游的迭代训练。</p><h3 id="3-1-生成突变体序列和对应表型表格"><a href="#3-1-生成突变体序列和对应表型表格" class="headerlink" title="3.1 生成突变体序列和对应表型表格"></a>3.1 生成突变体序列和对应表型表格</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">!cp <span class="token operator">-</span>r <span class="token operator">/</span>data<span class="token operator">/</span>chaofan<span class="token operator">/</span>software<span class="token operator">/</span>EvolvePro<span class="token operator">/</span>data <span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对<code>scripts/process/dms_process.py</code>代码的<code>project_root</code>进行修改</p><p><a href="https://imgse.com/i/pEvAZlQ"><img src="https://s21.ax1x.com/2025/05/16/pEvAZlQ.png" alt="pEvAZlQ.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">!python <span class="token operator">/</span>data<span class="token operator">/</span>chaofan<span class="token operator">/</span>software<span class="token operator">/</span>EvolvePro<span class="token operator">/</span>scripts<span class="token operator">/</span>process<span class="token operator">/</span>dms_process<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="https://imgse.com/i/pEvAmOs"><img src="https://s21.ax1x.com/2025/05/16/pEvAmOs.png" alt="pEvAmOs.png"></a></p><h3 id="3-2-获取氨基酸序列的embedding特征矩阵"><a href="#3-2-获取氨基酸序列的embedding特征矩阵" class="headerlink" title="3.2 获取氨基酸序列的embedding特征矩阵"></a>3.2 获取氨基酸序列的embedding特征矩阵</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">!sbatch esm2_650M_dms<span class="token punctuation">.</span>sh<span class="token comment"># 运行时大概占3G显存</span><span class="token comment"># 这一步运行时间非常长</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>esm2_650M_dms.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;bash# Configuration values for SLURM job submission.# One leading hash ahead of the word SBATCH is not a comment, but two are.#SBATCH --job-name&#x3D;esm#SBATCH --gres&#x3D;gpu:1#SBATCH --cpus-per-task&#x3D;1   #SBATCH --mem&#x3D;200gb  #SBATCH --output out&#x2F;esm-%j.out study_names&#x3D;(&quot;brenan&quot; &quot;jones&quot; &quot;stiffler&quot; &quot;haddox&quot; &quot;doud&quot; &quot;giacomelli&quot; &quot;kelsic&quot; &quot;lee&quot; &quot;markin&quot; &quot;cas12f&quot; &quot;cov2_S&quot; &quot;zikv_E&quot;)model_names&#x3D;(&quot;esm2_t33_650M_UR50D&quot;)fasta_path&#x3D;&quot;output&#x2F;dms&#x2F;&quot;results_path&#x3D;&quot;output&#x2F;plm&#x2F;esm&#x2F;&quot;repr_layers&#x3D;33toks_per_batch&#x3D;2000mkdir -p $&#123;results_path&#125;for model_name in &quot;$&#123;model_names[@]&#125;&quot;; do  for study in &quot;$&#123;study_names[@]&#125;&quot;; do    command&#x3D;&quot;python3 &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;EvolvePro&#x2F;evolvepro&#x2F;plm&#x2F;esm&#x2F;extract.py $&#123;model_name&#125;.pt $&#123;fasta_path&#125;$&#123;study&#125;.fasta $&#123;results_path&#125;$&#123;study&#125;&#x2F;$&#123;model_name&#125; --toks_per_batch $&#123;toks_per_batch&#125; --include mean --concatenate_dir $&#123;results_path&#125;&quot;    echo &quot;Running command: $&#123;command&#125;&quot;    eval &quot;$&#123;command&#125;&quot;  donedone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pEvuqRP"><img src="https://s21.ax1x.com/2025/05/17/pEvuqRP.png" alt="pEvuqRP.png"></a></p><h3 id="3-3-DMS数据验证定向进化"><a href="#3-3-DMS数据验证定向进化" class="headerlink" title="3.3 DMS数据验证定向进化"></a>3.3 DMS数据验证定向进化</h3><p>因为我们输入的是<code>$&#123;model_name&#125;.pt</code>文件，会导致输出文件名都变为<code>$&#123;dataset_name&#125;_esm2_t33_650M_UR50D.pt.csv</code>，但是后续文件的输入又要求是<code>$&#123;dataset_name&#125;_esm2_t33_650M_UR50D.csv</code>，需要进行文件名的批量修改再进行下一步。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">!ls output<span class="token operator">/</span>plm<span class="token operator">/</span>esm<span class="token operator">/</span><span class="token operator">*</span><span class="token punctuation">.</span>csv <span class="token operator">|</span> <span class="token keyword">while</span> read line<span class="token punctuation">;</span> do re_name<span class="token operator">=</span>`echo $line<span class="token operator">|</span>cut <span class="token operator">-</span>d <span class="token string">"/"</span> <span class="token operator">-</span>f4<span class="token operator">|</span>cut <span class="token operator">-</span>d <span class="token string">"."</span> <span class="token operator">-</span>f1`<span class="token punctuation">;</span> mv $<span class="token punctuation">&#123;</span>line<span class="token punctuation">&#125;</span> output<span class="token operator">/</span>plm<span class="token operator">/</span>esm<span class="token operator">/</span>$<span class="token punctuation">&#123;</span>re_name<span class="token punctuation">&#125;</span><span class="token punctuation">.</span>csv<span class="token punctuation">;</span> done<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">!sbatch esm2_650M<span class="token punctuation">.</span>sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>esm2_650M.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;bash# Configuration values for SLURM job submission.# One leading hash ahead of the word SBATCH is not a comment, but two are.#SBATCH --time&#x3D;12:00:00 #SBATCH --job-name&#x3D;esm2_650M_optimal#SBATCH -n 12#SBATCH -N 1   #SBATCH --cpus-per-task&#x3D;5  #SBATCH --mem&#x3D;20gb  #SBATCH --output out&#x2F;esm2_650M_optimal-%j.out source ~&#x2F;.bashrcconda activate evolvepro# module load openmind8&#x2F;gnu-parallel&#x2F;20240222datasets&#x3D;(&quot;brenan&quot; &quot;stiffler&quot; &quot;doud&quot; &quot;haddox&quot; &quot;giacomelli&quot; &quot;jones&quot; &quot;kelsic&quot; &quot;lee&quot; &quot;markin&quot; &quot;zikv_E&quot; &quot;cas12f&quot; &quot;cov2_S&quot;)# Function to run dms_main for a given datasetrun_dms_main() &#123;    dataset_name&#x3D;$1    output_file&#x3D;&quot;out&#x2F;$&#123;dataset_name&#125;-esm2_650M_optimal.out&quot;    echo &quot;Running $&#123;dataset_name&#125; dataset:&quot; &gt; $&#123;output_file&#125;    python3 -u &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;EvolvePro&#x2F;scripts&#x2F;dms&#x2F;dms_main.py \        --dataset_name $&#123;dataset_name&#125; \        --experiment_name &quot;esm2_650M_optimal&quot; \        --model_name &quot;esm2_t33_650M_UR50D&quot; \        --embeddings_path &quot;.&#x2F;output&#x2F;plm&#x2F;esm&quot; \        --labels_path &quot;.&#x2F;output&#x2F;dms&quot; \        --num_simulations 10 \        --num_iterations 10 \        --measured_var &quot;activity&quot; \        --learning_strategies &quot;topn&quot; \        --num_mutants_per_round 16 \        --num_final_round_mutants 16 \        --first_round_strategies &quot;random&quot; \        --embedding_types &quot;embeddings&quot; \        --regression_types &quot;randomforest&quot; \        --embeddings_file_type &quot;csv&quot; \        --output_dir &quot;.&#x2F;output&#x2F;dms_results&quot; \        &gt;&gt; $&#123;output_file&#125; 2&gt;&amp;1    echo &quot;Done running $&#123;dataset_name&#125; dataset:&quot; &gt;&gt; $&#123;output_file&#125;&#125;# Export the function so it&#39;s available to GNU Parallelexport -f run_dms_main# Use GNU Parallel to run the dms_main function in parallel for each datasetparallel -j12 run_dms_main ::: &quot;$&#123;datasets[@]&#125;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pEvKno9"><img src="https://s21.ax1x.com/2025/05/17/pEvKno9.png" alt="pEvKno9.png"></a></p><p>这是其中一个结果表格，还是很清晰的。原文主要利用DMS数据集中大量的突变体和对应的表型数据进行方法可行性的验证，当然也可以从DMS大量的数据基础上去探索更广阔的突变空间。</p><p><a href="https://imgse.com/i/pEv1RBT"><img src="https://s21.ax1x.com/2025/05/17/pEv1RBT.png" alt="pEv1RBT.png"></a></p><p>&emsp;&emsp;好了，你已经学会了目前最热门的借助深度学习辅助定向进化进行蛋白分子的理性设计。</p><center><span style="color:#ff0000;">本人能力有限，难免出现错误，恳请批评指正</span></center>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Directed evolution </tag>
            
            <tag> Molecular design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Read Fasta File</title>
      <link href="2025/01/09/read-fasta-file/"/>
      <url>2025/01/09/read-fasta-file/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;我们在平时的工作中经常会遇到对生物序列进行提取或修改，不管是基因组DNA序列还是编码蛋白序列，它们都是fasta格式。一般都是将fasta序列存储为dict格式再进行操作，下面就介绍下我常用或遇到的一些处理方式：</p><h3 id="1-比较原始的逐行处理"><a href="#1-比较原始的逐行处理" class="headerlink" title="1.比较原始的逐行处理"></a>1.比较原始的逐行处理</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#read a fasta file and return a dictionary, the key is entry id and the value is the sequence in upcase</span><span class="token keyword">def</span> <span class="token function">readFasta</span><span class="token punctuation">(</span>fastaFile<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">import</span> gzip    f1 <span class="token operator">=</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>fastaFile<span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> fastaFile<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'gz'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fastaFile<span class="token punctuation">)</span>    line <span class="token operator">=</span> f1<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    sequence <span class="token operator">=</span> <span class="token string">""</span>    fasta_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    header <span class="token operator">=</span> <span class="token string">""</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">:</span>            <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'>'</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sequence<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>                    fasta_dict<span class="token punctuation">[</span>header<span class="token punctuation">]</span> <span class="token operator">=</span> sequence                    sequence <span class="token operator">=</span> <span class="token string">""</span>                header <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                sequence <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>         line <span class="token operator">=</span> f1<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>    f1<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> header <span class="token keyword">and</span> sequence<span class="token punctuation">:</span>        fasta_dict<span class="token punctuation">[</span>header<span class="token punctuation">]</span> <span class="token operator">=</span> sequence    <span class="token keyword">return</span> fasta_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-比较优雅的借助Biopython-API"><a href="#2-比较优雅的借助Biopython-API" class="headerlink" title="2.比较优雅的借助Biopython API"></a>2.比较优雅的借助Biopython API</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_fasta</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> subset_chroms<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> Bio <span class="token keyword">import</span> SeqIO    <span class="token keyword">import</span> gzip    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">"rt"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> path<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">".gz"</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span> <span class="token keyword">as</span> handle<span class="token punctuation">:</span>        genome <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>            <span class="token punctuation">&#123;</span>                rec<span class="token punctuation">.</span><span class="token builtin">id</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>rec<span class="token punctuation">.</span>seq<span class="token punctuation">)</span>                <span class="token keyword">for</span> rec <span class="token keyword">in</span> SeqIO<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>handle<span class="token punctuation">,</span> <span class="token string">"fasta"</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> subset_chroms <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> rec<span class="token punctuation">.</span><span class="token builtin">id</span> <span class="token keyword">in</span> subset_chroms            <span class="token punctuation">&#125;</span>        <span class="token punctuation">)</span>    <span class="token keyword">return</span> genome<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（未完待续）</p>]]></content>
      
      
      
        <tags>
            
            <tag> Bioinformatics </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GATK_time_compare</title>
      <link href="2024/12/14/gatk-time-compare/"/>
      <url>2024/12/14/gatk-time-compare/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;事情的起因主要是群里有老哥说INTEL的CPU(有avx512指令集）在用GATK call SNP的时候比AMD(EPYC3代 没有avx512指令集)快8-15倍，直接把我震惊到了。买INTEL，赢在起跑线.jpg<br>&emsp;&emsp;我们现在来测试下</p><h3 id="1-工具下载"><a href="#1-工具下载" class="headerlink" title="1.工具下载"></a>1.工具下载</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir Softwares &amp;&amp; cd Softwares# sra-tools 89.20M # 我们服务器是centos系统，自己下载自己服务器对应的版本wget https:&#x2F;&#x2F;ftp-trace.ncbi.nlm.nih.gov&#x2F;sra&#x2F;sdk&#x2F;3.1.1&#x2F;sratoolkit.3.1.1-centos_linux64.tar.gztar -zxvf sratoolkit.3.1.1-centos_linux64.tar.gz# bwa-mem2curl -L https:&#x2F;&#x2F;github.com&#x2F;bwa-mem2&#x2F;bwa-mem2&#x2F;releases&#x2F;download&#x2F;v2.2.1&#x2F;bwa-mem2-2.2.1_x64-linux.tar.bz2 \  | tar jxf -# fastpwget http:&#x2F;&#x2F;opengene.org&#x2F;fastp&#x2F;fastpchmod a+x .&#x2F;fastp# samtoolsconda activate gatkconda install samtools -c bioconda python <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-原始数据下载"><a href="#2-原始数据下载" class="headerlink" title="2.原始数据下载"></a>2.原始数据下载</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 下载参考基因组文件# https:&#x2F;&#x2F;doi.org&#x2F;10.1126&#x2F;science.adq8191 数据来源mkdir Reference &amp;&amp; cd Referencewget https:&#x2F;&#x2F;github.com&#x2F;yulab-ql&#x2F;mhaESC_genome&#x2F;releases&#x2F;download&#x2F;upd_rmvector&#x2F;mouse.241018.v1.1.0.combined.fasta.gzwget https:&#x2F;&#x2F;github.com&#x2F;yulab-ql&#x2F;mhaESC_genome&#x2F;releases&#x2F;download&#x2F;upd_rmvector&#x2F;mhaESC.annotation.v1.1.0.20241018.gff3.gz# 下载原始测序文件cd ..mdkir 00.raw_data &amp;&amp; cd 00.raw_data# 94GB ..&#x2F;Softwares&#x2F;sratoolkit.3.1.1-centos_linux64&#x2F;bin&#x2F;prefetch SRR28702443 -O .&#x2F; --max-size 1000G..&#x2F;Softwares&#x2F;sratoolkit.3.1.1-centos_linux64&#x2F;bin&#x2F;fastq-dump --gzip --split-files SRR28702443&#x2F;SRR28702443.sra# 原始文件太大了，截取一部分来做测试seqkit sample -n 10000000 00.raw_data&#x2F;SRR28702443_1.fastq.gz | seqkit seq -ni &gt; selected_ids.txt# 过滤 input_1.fastqseqkit grep -f selected_ids.txt input_1.fastq -o output_1.fastq# 过滤 input_2.fastqseqkit grep -f selected_ids.txt input_2.fastq -o output_2.fastq<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-数据前处理"><a href="#3-数据前处理" class="headerlink" title="3.数据前处理"></a>3.数据前处理</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">bwa-mem2-2.2.1_x64-linux&#x2F;bwa-mem2 index ref.fabwa-mem2-2.2.1_x64-linux&#x2F;bwa-mem2 mem ref.fa read1.fq read2.fq &gt; out.sam<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Bioinformatics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Variational_AutoEncoders</title>
      <link href="2024/12/12/variational-autoencoders/"/>
      <url>2024/12/12/variational-autoencoders/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pickle<span class="token keyword">import</span> datasets<span class="token comment"># windows 本地下载并保存</span><span class="token comment"># minist = load_dataset("mnist")</span><span class="token comment"># with open("minist_dataset.pkl", "wb") as f:</span><span class="token comment">#     pickle.dump(minist, f)</span>mnist <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">"./mnist/"</span><span class="token punctuation">)</span>mnist<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>   DatasetDict({<br>       train: Dataset({<br>           features: [‘image’, ‘label’],<br>           num_rows: 60000<br>       })<br>       test: Dataset({<br>           features: [‘image’, ‘label’],<br>           num_rows: 10000<br>       })<br>   })</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> genaibook<span class="token punctuation">.</span>core <span class="token keyword">import</span> show_images show_images<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdqX9"><img src="https://s21.ax1x.com/2024/12/12/pAbdqX9.png" alt="pAbdqX9.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib <span class="token keyword">as</span> mpl mpl<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"image.cmap"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"gray_r"</span>show_images<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdOmR"><img src="https://s21.ax1x.com/2024/12/12/pAbdOmR.png" alt="pAbdOmR.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">def</span> <span class="token function">mnist_to_tensor</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span><span class="token punctuation">:</span>    t <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    samples<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>t<span class="token punctuation">(</span>image<span class="token punctuation">)</span> <span class="token keyword">for</span> image <span class="token keyword">in</span> samples<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> samples mnist <span class="token operator">=</span> mnist<span class="token punctuation">.</span>with_transform<span class="token punctuation">(</span>mnist_to_tensor<span class="token punctuation">)</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span> <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">1337</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>x<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdX01"><img src="https://s21.ax1x.com/2024/12/12/pAbdX01.png" alt="pAbdX01.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader bs <span class="token operator">=</span> <span class="token number">64</span> train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>     batch_size<span class="token operator">=</span>bs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="1-AutoEncoders"><a href="#1-AutoEncoders" class="headerlink" title="1 | AutoEncoders"></a><div style="padding: 30px;color:white;margin:30;font-size:70%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1 |</span></b> <b>AutoEncoders</b></div></h1><p><a href="https://imgse.com/i/pAbZsud"><img src="https://s21.ax1x.com/2024/12/12/pAbZsud.png" alt="pAbZsud.png"></a></p><h1 id="1-1-Encoder-model"><a href="#1-1-Encoder-model" class="headerlink" title="1.1 | Encoder model"></a><div style="padding: 20px;color:white;margin:10;font-size:50%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1.1 |</span></b> <b>Encoder model</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn <span class="token keyword">def</span> <span class="token function">conv_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernal_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>               stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>            in_channels<span class="token punctuation">,</span>            out_channels<span class="token punctuation">,</span>            kernel_size<span class="token operator">=</span>kernal_size<span class="token punctuation">,</span>            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>            padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>        <span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv4 <span class="token operator">=</span> conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>               x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>torch.Size([1, 28, 28])</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">in_channels <span class="token operator">=</span> <span class="token number">1</span> x <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>encoded <span class="token operator">=</span> encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>encoded<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>torch.Size([1, 16])</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">encoded<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>   tensor([[-0.0048, -0.0199,  0.0006,  0.0168,  0.0034, -0.0012, -0.0046,  0.0108,<br>            -0.0039, -0.0243,  0.0268, -0.0117, -0.0271, -0.0337, -0.0243, -0.0285]],<br>          grad_fn=<AddmmBackward0>)</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>encoded <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span>batch<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> encoded<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>(torch.Size([64, 1, 28, 28]), torch.Size([64, 16]))</p></blockquote><h1 id="1-2-Decoder-model"><a href="#1-2-Decoder-model" class="headerlink" title="1.2 | Decoder model"></a><div style="padding: 20px;color:white;margin:10;font-size:50%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1.2 |</span></b> <b>Decoder model</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">conv_transpose_block</span><span class="token punctuation">(</span>    in_channels<span class="token punctuation">,</span>    out_channels<span class="token punctuation">,</span>    kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>    stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>    output_padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>    with_act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    modules <span class="token operator">=</span> <span class="token punctuation">[</span>        nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>            in_channels<span class="token punctuation">,</span>            out_channels<span class="token punctuation">,</span>            kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>            stride<span class="token operator">=</span>stride<span class="token punctuation">,</span>            padding<span class="token operator">=</span>padding<span class="token punctuation">,</span>            output_padding<span class="token operator">=</span>output_padding<span class="token punctuation">,</span>        <span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span>    <span class="token keyword">if</span> with_act<span class="token punctuation">:</span>        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>            <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv1 <span class="token operator">=</span> conv_transpose_block<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv2 <span class="token operator">=</span> conv_transpose_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span>                                            output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv3 <span class="token operator">=</span> conv_transpose_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span>                                            output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x     decoded_batch <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>encoded<span class="token punctuation">)</span>decoded_batch<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>torch.Size([64, 1, 28, 28])</p></blockquote><h1 id="1-3-AutoEncoder-training"><a href="#1-3-AutoEncoder-training" class="headerlink" title="1.3 | AutoEncoder training"></a><div style="padding: 20px;color:white;margin:10;font-size:50%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>1.3 |</span></b> <b>AutoEncoder training</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> AutoEncoder<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchsummarytorchsummary<span class="token punctuation">.</span>summary<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>   -—————————————————————<br>           Layer (type)               Output Shape         Param #<br>   ================================================================<br>               Conv2d-1          [-1, 128, 14, 14]           2,176<br>          BatchNorm2d-2          [-1, 128, 14, 14]             256<br>                 ReLU-3          [-1, 128, 14, 14]               0<br>               Conv2d-4            [-1, 256, 7, 7]         524,544<br>          BatchNorm2d-5            [-1, 256, 7, 7]             512<br>                 ReLU-6            [-1, 256, 7, 7]               0<br>               Conv2d-7            [-1, 512, 3, 3]       2,097,664<br>          BatchNorm2d-8            [-1, 512, 3, 3]           1,024<br>                 ReLU-9            [-1, 512, 3, 3]               0<br>              Conv2d-10           [-1, 1024, 1, 1]       8,389,632<br>         BatchNorm2d-11           [-1, 1024, 1, 1]           2,048<br>                ReLU-12           [-1, 1024, 1, 1]               0<br>              Linear-13                   [-1, 16]          16,400<br>             Encoder-14                   [-1, 16]               0<br>              Linear-15                [-1, 16384]         278,528<br>     ConvTranspose2d-16            [-1, 512, 7, 7]       4,719,104<br>         BatchNorm2d-17            [-1, 512, 7, 7]           1,024<br>                ReLU-18            [-1, 512, 7, 7]               0<br>     ConvTranspose2d-19          [-1, 256, 14, 14]       1,179,904<br>         BatchNorm2d-20          [-1, 256, 14, 14]             512<br>                ReLU-21          [-1, 256, 14, 14]               0<br>     ConvTranspose2d-22            [-1, 1, 28, 28]           2,305<br>         BatchNorm2d-23            [-1, 1, 28, 28]               2<br>                ReLU-24            [-1, 1, 28, 28]               0<br>             Decoder-25            [-1, 1, 28, 28]               0<br>   ================================================================<br>   Total params: 17,215,635<br>   Trainable params: 17,215,635<br>   Non-trainable params: 0  </p><hr><p>   Input size (MB): 0.00<br>   Forward/backward pass size (MB): 2.86<br>   Params size (MB): 65.67<br>   Estimated Total Size (MB): 68.54  </p><hr></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt <span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F <span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>notebook <span class="token keyword">import</span> tqdm<span class="token punctuation">,</span> trange <span class="token keyword">from</span> genaibook<span class="token punctuation">.</span>core <span class="token keyword">import</span> get_device num_epochs <span class="token operator">=</span> <span class="token number">10</span>lr <span class="token operator">=</span> <span class="token number">1e-4</span>device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>     eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span>losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token punctuation">(</span>process <span class="token operator">:=</span> trange<span class="token punctuation">(</span>num_epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> _<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token punctuation">(</span>        inner <span class="token operator">:=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>                      total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token punctuation">:</span>        batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        preds <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>        inner<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>        losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    process<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>lr<span class="token punctuation">:</span><span class="token format-spec">.0e</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>  Training:   0%|          | 0/10 [00:00&lt;?, ?it/s]</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Step"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"AutoEncoder - Training Loss Curve"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdjTx"><img src="https://s21.ax1x.com/2024/12/12/pAbdjTx.png" alt="pAbdjTx.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">eval_bs <span class="token operator">=</span> <span class="token number">16</span>eval_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>eval_bs<span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 只需要获取数据集的第一个批次，而不是遍历整个数据集</span>    eval_batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>eval_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>    batch_vs_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>eval_batch<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span><span class="token punctuation">)</span>    show_images<span class="token punctuation">(</span>batch_vs_preds<span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAbdxk6"><img src="https://s21.ax1x.com/2024/12/12/pAbdxk6.png" alt="pAbdxk6.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x     <span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dims<span class="token punctuation">,</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t_conv_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            conv_transpose_block<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_transpose_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_transpose_block<span class="token punctuation">(</span>                <span class="token number">256</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> with_act<span class="token operator">=</span><span class="token boolean">False</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>t_conv_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x <span class="token keyword">class</span> <span class="token class-name">AutoEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>                                  eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token punctuation">(</span>process <span class="token operator">:=</span> trange<span class="token punctuation">(</span>num_epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> _<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token punctuation">(</span>            inner <span class="token operator">:=</span> tqdm<span class="token punctuation">(</span>                <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token punctuation">:</span>            batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            preds <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>            inner<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>            losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        process<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>lr<span class="token punctuation">:</span><span class="token format-spec">.0e</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> losses     ae_model <span class="token operator">=</span> AutoEncoder<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> latent_dims<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>ae_model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>losses <span class="token operator">=</span> train<span class="token punctuation">(</span>ae_model<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Step"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Training Loss Curve (two latent dimensions)"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training:   0%|          | 0/10 [00:00&lt;?, ?it/s]</p></blockquote><p><img src="/blog_pics/VAE/VAE_22_11.png" alt="png">    </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ae_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    predicted <span class="token operator">=</span> ae_model<span class="token punctuation">(</span>eval_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>    batch_vs_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>eval_batch<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>batch_vs_preds<span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_23_0.png" alt="png"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images_labels_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>    <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>    <span class="token builtin">iter</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>     total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded <span class="token operator">=</span> ae_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>    new_items <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> encoded<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> encoded<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> batch<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>new_items<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    points <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span><span class="token string">"y"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>0%|          | 0/20 [00:00&lt;?, ?it/s]</p></blockquote><p><img src="/blog_pics/VAE/VAE_24_1.png" alt="png">    </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">N <span class="token operator">=</span> <span class="token number">16</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">8</span> <span class="token operator">-</span> <span class="token number">4</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    points <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span><span class="token string">"y"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"z"</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"s"</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"black"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_25_0.png" alt="png"> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ae_decoded <span class="token operator">=</span> ae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>ae_decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> suptitle<span class="token operator">=</span><span class="token string">"AutoEncoder"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_26_0.png" alt="png"> </p><h1 id="2-Variational-AutoEncoders"><a href="#2-Variational-AutoEncoders" class="headerlink" title="2 | Variational AutoEncoders"></a><div style="padding: 30px;color:white;margin:30;font-size:70%;text-align:left;display:fill;border-radius:20px;background-color:#FFFFFF;overflow:hidden;background-color:#E888BB"><b><span style='color:#FFFFFF'>2 |</span></b> <b>Variational AutoEncoders</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">VAEEncoeder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mu <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>logvar <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        bs <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        mu <span class="token operator">=</span> self<span class="token punctuation">.</span>mu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        logvar <span class="token operator">=</span> self<span class="token punctuation">.</span>logvar<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>mu<span class="token punctuation">,</span> logvar<span class="token punctuation">)</span>        <span class="token keyword">class</span> <span class="token class-name">VAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> VAEEncoeder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> latent_dims<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mu<span class="token punctuation">,</span> logvar <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        std <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">*</span> logvar<span class="token punctuation">)</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> std<span class="token punctuation">)</span>        reconstructed <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token keyword">return</span> reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar        <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> std<span class="token punctuation">)</span><span class="token punctuation">:</span>        eps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>std<span class="token punctuation">)</span>        <span class="token keyword">return</span> mu <span class="token operator">+</span> eps <span class="token operator">*</span> std     <span class="token keyword">def</span> <span class="token function">vae_loss</span><span class="token punctuation">(</span>batch<span class="token punctuation">,</span> reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar<span class="token punctuation">)</span><span class="token punctuation">:</span>    bs <span class="token operator">=</span> batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    reconstruction_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>        reconstructed<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        batch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        reduction<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        kl_loss <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>logvar<span class="token operator">-</span>mu<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">-</span>logvar<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>reconstruction_loss<span class="token operator">+</span>kl_loss<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>loss<span class="token punctuation">,</span> reconstruction_loss<span class="token punctuation">,</span> kl_loss<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">train_vae</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"loss"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"reconstruction_loss"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"kl_loss"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>        eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token punctuation">(</span>progress <span class="token operator">:=</span> trange<span class="token punctuation">(</span>num_epochs<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Training"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> _<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token punctuation">(</span>            inner <span class="token operator">:=</span> tqdm<span class="token punctuation">(</span>                <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span>                total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token punctuation">:</span>            batch <span class="token operator">=</span> batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>            loss<span class="token punctuation">,</span> reconstruction_loss<span class="token punctuation">,</span> kl_loss <span class="token operator">=</span> vae_loss<span class="token punctuation">(</span>                batch<span class="token punctuation">,</span> reconstructed<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar            <span class="token punctuation">)</span>            inner<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>            losses<span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            losses<span class="token punctuation">[</span><span class="token string">"reconstruction_loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>                reconstruction_loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>            losses<span class="token punctuation">[</span><span class="token string">"kl_loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>kl_loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        process<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>loss<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>lr<span class="token punctuation">:</span><span class="token format-spec">.0e</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> losses vae_model <span class="token operator">=</span> VAE<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> latent_dims<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>losses <span class="token operator">=</span> train_vae<span class="token punctuation">(</span>vae_model<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> losses<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>v<span class="token punctuation">,</span> label<span class="token operator">=</span>k<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training:   0%|          | 0/10 [00:00&lt;?, ?it/s]</p></blockquote><p><img src="/blog_pics/VAE/VAE_28_11.png" alt="png"> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">vae_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_batch <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>eval_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>    predicted<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> logvar <span class="token operator">=</span> <span class="token punctuation">(</span>v<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> \        vae_model<span class="token punctuation">(</span>eval_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>batch_vs_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>eval_batch<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>batch_vs_preds<span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_29_0.png" alt="png">   </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>    <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">for</span> batch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>    <span class="token builtin">iter</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>images_labels_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    mu<span class="token punctuation">,</span> _ <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>    mu <span class="token operator">=</span> mu<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>    new_items <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"x"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> mu<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"y"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> mu<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"label"</span><span class="token punctuation">:</span> batch<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>new_items<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    points <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span><span class="token string">"y"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_30_1.png" alt="png">   </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">z <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ae_decoded <span class="token operator">=</span> ae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>vae_decoded <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>ae_decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>vae_decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_31_0.png" alt="png">       </p><p><img src="/blog_pics/VAE/VAE_31_1.png" alt="png">       </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> y <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>    z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    decoded <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_32_0.png" alt="png"> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> x <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> y <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>decoded <span class="token operator">=</span> vae_model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>show_images<span class="token punctuation">(</span>decoded<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> imsize<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/blog_pics/VAE/VAE_33_0.png" alt="png"> </p>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GROMACS_complex_system</title>
      <link href="2024/11/02/gromacs-complex-system/"/>
      <url>2024/11/02/gromacs-complex-system/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在一般的分子动力学模拟体系中，都是在研究相互作用，比如蛋白-蛋白，蛋白-分子和蛋白-细胞膜等。所以我们会将不同的分子组合到一起。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># raw_data wget http:&#x2F;&#x2F;www.mdtutorials.com&#x2F;gmx&#x2F;biphasic&#x2F;Files&#x2F;chx.growget http:&#x2F;&#x2F;www.mdtutorials.com&#x2F;gmx&#x2F;biphasic&#x2F;Files&#x2F;chx.top# 512 (8^3) cyclohexane moleculesgmx genconf -f chx.gro -nbox 8 8 8 -o chx_box.gro# build box 同时指定chx_10ns的中心位置http:&#x2F;&#x2F;www.mdtutorials.com&#x2F;gmx&#x2F;biphasic&#x2F;Files&#x2F;chx_10ns.grogmx editconf -f chx_10ns.gro -o chx_newbox.gro -box 4.30795 4.30795 8.6159 -center 2.153975 2.153975 2.153975# add watergmx solvate -cp chx_newbox.gro -cs spc216.gro -p chx.top -o chx_solv.gro# 创建一样大小盒子，并将蛋白放置到指定位置wget https:&#x2F;&#x2F;files.rcsb.org&#x2F;view&#x2F;1AL1.pdb# pdb2grogmx editconf -f 1AL1.pdb -o 1AL1.grogmx editconf -f 1AL1.gro -o peptide_newbox.gro -box 4.30795 4.30795 8.6159 -center 2.153975 2.153975 6.461925# 将蛋白和环己烷分子层结合在一个box里gmx solvate -cp peptide_newbox.gro -cs chx_newbox.gro -o peptide_chx.gro# Expanding the Boxgmx genconf -f chx_10ns.gro -nbox 2 2 2 -o chx_bigbox.gro# an expanded layer can be created along the x-y plane with a slightly different commandgmx genconf -f chx_10ns.gro -nbox 2 2 1 -o chx_biglayer.gro<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pADL2ZV"><img src="https://s21.ax1x.com/2024/11/02/pADL2ZV.png" alt="pADL2ZV.png"></a><br><strong>Reference：</strong><br><a href="http://www.mdtutorials.com/gmx/biphasic/">http://www.mdtutorials.com/gmx/biphasic/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GROMACS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GROMACS_files</title>
      <link href="2024/11/01/gromacs-files/"/>
      <url>2024/11/01/gromacs-files/</url>
      
        <content type="html"><![CDATA[<h2 id="1-GROMACS-TOP文件"><a href="#1-GROMACS-TOP文件" class="headerlink" title="1.GROMACS TOP文件"></a>1.GROMACS <strong>TOP</strong>文件</h2><p><code>TOP</code>文件（也称为拓扑文件），用于定义分子系统的拓扑结构和力场参数。<code>TOP</code>文件包含了分子系统的原子类型、键合类型、非键合相互作用参数等信息，是进行分子动力学模拟的基础。<code>TOP</code>文件由多个部分组成，每个部分定义了不同的信息。<br>你可以发现文件头除了一些注释信息外，还有一行<code>#include &quot;gromos43a1.ff/forcefield.itp&quot;</code>,表明当前体系基于该力场。</p><h3 id="1-1-moleculetype"><a href="#1-1-moleculetype" class="headerlink" title="1.1 [ moleculetype ]"></a>1.1 <strong>[ moleculetype ]</strong></h3><p>定义分子类型及其名称，以及非键合相互作用的处理方式。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ moleculetype ]; Name            nrexclProtein_chain_A     3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>molname：分子类型的名称(这里的蛋白名称)。</li><li>nrexcl：决定了在计算非键合相互作用时，哪些原子对之间的相互作用会被忽略。<br>通常为 3，可以避免短程相互作用，减少计算量和避免重复计算。</li><li>qtot N端到当前pos肽段所带电荷<h3 id="1-2-atoms"><a href="#1-2-atoms" class="headerlink" title="1.2 [ atoms ]"></a>1.2 <strong>[ atoms ]</strong></h3>定义了分子系统中每个原子的详细信息, 如原子类型、电荷、质量等。</li></ul><p><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ atoms ];   nr       type  resnr residue  atom   cgnr     charge       mass  typeB    chargeB      massB; residue   4 CYS rtp NCYX q +1.0     1         N3      4    CYS      N      1     0.2069      14.01     2          H      4    CYS     H1      2     0.1815      1.008     3          H      4    CYS     H2      3     0.1815      1.008     4          H      4    CYS     H3      4     0.1815      1.008     5         CT      4    CYS     CA      5     0.1055      12.01     6         HP      4    CYS     HA      6     0.0922      1.008     7         CT      4    CYS     CB      7    -0.0277      12.01     8         H1      4    CYS    HB1      8      0.068      1.008     9         H1      4    CYS    HB2      9      0.068      1.008    10          S      4    CYS     SG     10    -0.0984      32.06    11          C      4    CYS      C     11     0.6123      12.01    12          O      4    CYS      O     12    -0.5713         16   ; qtot 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>nr: 原子编号</li><li>type: 原子类型</li><li>resnr: 残基编号</li><li>residue: 氨基酸残基名称</li><li>atom: 原子名称</li><li>cgnr: 电荷组编号</li><li>charge: 原子电荷</li><li>mass: 原子质量</li><li>typeB: 备用原子类型（通常用于双力场设置）</li><li>chargeB: 备用原子电荷（通常用于双力场设置）</li><li>massB: 备用原子质量（通常用于双力场设置）</li></ul><h3 id="1-3-bonds"><a href="#1-3-bonds" class="headerlink" title="1.3 [ bonds ]"></a>1.3 <strong>[ bonds ]</strong></h3><p>定义分子中的键及其参数，如键长、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ bonds ];  ai    aj funct            c0            c1            c2            c3    1     2     1     1     3     1     1     4     1     1     5     1     5     6     1     5     7     1     5    11     1     7     8     1     7     9     1     7    10     1    10   234     1 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai: 第一个原子的编号</li><li>aj: 第二个原子的编号</li><li>func: 键的函数类型，通常为 1（谐振势）或 2（Morse势）</li><li>c0: 键长（单位：nm）</li><li>c1: 力常数（单位：kJ/mol/nm²）</li><li>c2: 其它</li><li>c3: 其它</li></ul><h3 id="1-4-pairs"><a href="#1-4-pairs" class="headerlink" title="1.4 [ pairs ]"></a>1.4 <strong>[ pairs ]</strong></h3><p>定义分子中的键及其参数，如键长、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ pairs ];  ai    aj funct            c0            c1            c2            c3    1     8     1     1     9     1     1    10     1     1    12     1     1    13     1     2     6     1     2     7     1     2    11     1     3     6     1     3     7     1     3    11     1     4     6     1     4     7     1     4    11     1     5    14     1     5    15     1     5   234     1     6     8     1     6     9     1     6    10     1     6    12     1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai: 第一个原子编号 </li><li>aj: 第二个原子编号</li><li>func: 1（Lennard-Jones 12-6 势能）；2（Buckingham 势能）；3（Morse 势能）</li><li>c0: 其它（通常在 funct 为 1 时省略）</li><li>c1: 其它（通常在 funct 为 1 时省略）</li><li>c2: 其它（通常在 funct 为 1 时省略）</li><li>c3: 其它（通常在 funct 为 1 时省略）</li></ul><h3 id="1-5-angles"><a href="#1-5-angles" class="headerlink" title="1.5 [ angles ]"></a>1.5 <strong>[ angles ]</strong></h3><p>定义分子中的键角及其参数，如角度、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ angles ];  ai    aj    ak funct            c0            c1            c2            c3    2     1     3     1     2     1     4     1     2     1     5     1     3     1     4     1     3     1     5     1     4     1     5     1     1     5     6     1     1     5     7     1     1     5    11     1     6     5     7     1     6     5    11     1     7     5    11     1     5     7     8     1     5     7     9     1     5     7    10     1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai：第一个原子的编号，用于标识键角的起始原子</li><li>aj：中心原子的编号，用于标识键角的中心原子</li><li>ak：第三个原子的编号，用于标识键角的终止原子</li><li>funct：键角的函数类型，通常为 1（谐振势）</li><li>c0：键角（单位：度），通常在 funct 为 1 时省略</li><li>c1：力常数（单位：kJ/mol/rad²），通常在 funct 为 1 时省略</li><li>c2 和 c3：其他参数，通常在 funct 为 1 时省略</li></ul><h3 id="1-6-dihedrals"><a href="#1-6-dihedrals" class="headerlink" title="1.6 [ dihedrals ]"></a>1.6 <strong>[ dihedrals ]</strong></h3><p>定义分子中的二面角（扭转角）及其参数，如角度、力常数等。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ dihedrals ];  ai    aj    ak    al funct            c0            c1            c2            c3            c4            c5    2     1     5     6     9     2     1     5     7     9     2     1     5    11     9     3     1     5     6     9     3     1     5     7     9     3     1     5    11     9     4     1     5     6     9     4     1     5     7     9     4     1     5    11     9     1     5     7     8     9     1     5     7     9     9     1     5     7    10     9 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ai：第一个原子的编号，用于标识二面角的起始原子</li><li>aj：第二个原子的编号，用于标识二面角的第二个原子</li><li>ak：第三个原子的编号，用于标识二面角的第三个原子</li><li>al：第四个原子的编号，用于标识二面角的终止原子</li><li>funct：二面角的函数类型，通常为 1（周期性势能）或 3（Ryckaert-Bellemans 势能）,这里是周期性势能（Periodic potential）</li><li>c0、c1、c2、c3、c4 和 c5：其他参数，通常在 funct 为 1 或 3 时省略</li></ul><h3 id="1-7-system"><a href="#1-7-system" class="headerlink" title="1.7 [ system ]"></a>1.7 <strong>[ system ]</strong></h3><p>系统的名称。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ system ]; NameOMEGA-AGA-IVB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="1-8-molecules"><a href="#1-8-molecules" class="headerlink" title="1.8 [ molecules ]"></a>1.8 <strong>[ molecules ]</strong></h3><p>定义系统中包含的分子类型及其数量。<br><strong>示例：</strong></p><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">[ molecules ]; Compound        #molsProtein_chain_A     1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>Compound：分子类型的名称</li><li>#mols：分子类型的数量</li></ul><h3 id="1-9-文件末尾的其它定义"><a href="#1-9-文件末尾的其它定义" class="headerlink" title="1.9 文件末尾的其它定义"></a>1.9 <strong>文件末尾的其它定义</strong></h3><pre class="line-numbers language-JavaScript" data-language="JavaScript"><code class="language-JavaScript">## 定义了一个力常数，用来在平衡过程中使原子保持在原位; Include Position restraint file#ifdef POSRES#include &quot;posre.itp&quot;#endif## 溶剂 其它水：SPCE, TIP3P, and TIP4P; include water#include &quot;spc.itp&quot;## 离子参数; Include generic topology for ions#include &quot;oplsaa.ff&#x2F;ions.itp&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-GROMACS-GRO文件"><a href="#2-GROMACS-GRO文件" class="headerlink" title="2.GROMACS GRO文件"></a>2.GROMACS <strong>GRO</strong>文件</h2><p>gro格式的输出结构。结果是一个坐标文件，其中结构的每个原子都有x、y和z坐标，很像一个简单的PDB文件。</p><h2 id="3-GROMACS-ITP文件"><a href="#3-GROMACS-ITP文件" class="headerlink" title="3.GROMACS ITP文件"></a>3.GROMACS <strong>ITP</strong>文件</h2><p>一个位置约束文件，将在我们模拟的平衡步骤中有用。</p><h2 id="4-GROMACS-TPR文件"><a href="#4-GROMACS-TPR文件" class="headerlink" title="4.GROMACS TPR文件"></a>4.GROMACS <strong>TPR</strong>文件</h2><p><strong>References:</strong><br><a href="https://www.compchems.com/gromacs-file-formats-understanding-topology-itp-and-gro-files/#gro-file-format">https://www.compchems.com/gromacs-file-formats-understanding-topology-itp-and-gro-files/#gro-file-format</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GROMACS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Install_GROMACS_GPU</title>
      <link href="2024/11/01/install-gromacs-gpu/"/>
      <url>2024/11/01/install-gromacs-gpu/</url>
      
        <content type="html"><![CDATA[<h2 id="GROMACS的安装"><a href="#GROMACS的安装" class="headerlink" title="GROMACS的安装"></a>GROMACS的安装</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n GROMACSconda activate GROMACSconda install cmake -yconda install gcc&#x3D;12 gxx&#x3D;12 -c conda-forge -y conda install -c conda-forge openmpi fftw# install GROMACSwget https:&#x2F;&#x2F;ftp.gromacs.org&#x2F;gromacs&#x2F;gromacs-2022.6.tar.gztar xfz gromacs-2022.6.tar.gzcd gromacs-2022.6mkdir buildcd buildcmake .. -DGMX_MPI&#x3D;OFF \-DGMX_GPU&#x3D;CUDA \-DCUDA_TOOLKIT_ROOT_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda \-DCUDA_INCLUDE_DIRS&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include \-DCUDA_CUDART_LIBRARY&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64 \-DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;GROMACS22 \-DCMAKE_C_COMPILER&#x3D;&#x2F;data&#x2F;chaofan&#x2F;miniconda3&#x2F;envs&#x2F;GROMACS&#x2F;bin&#x2F;gcc \-DCMAKE_CXX_COMPILER&#x3D;&#x2F;data&#x2F;chaofan&#x2F;miniconda3&#x2F;envs&#x2F;GROMACS&#x2F;bin&#x2F;g++make -j 40 make checkmake installsource &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;GROMACS&#x2F;bin&#x2F;GMXRC<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> GROMACS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT_fine_tuning</title>
      <link href="2024/10/29/gpt-fine-tuning/"/>
      <url>2024/10/29/gpt-fine-tuning/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Downloading-and-unzipping-the-dataset"><a href="#1-Downloading-and-unzipping-the-dataset" class="headerlink" title="1 | Downloading and unzipping the dataset"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>1 |</span></b> <b><span style='color:#95cf92'>Downloading and unzipping the dataset</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os <span class="token keyword">import</span> json <span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request<span class="token keyword">import</span> zipfile <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">url <span class="token operator">=</span> <span class="token string">"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip"</span>zip_path <span class="token operator">=</span> <span class="token string">"sms_spam_collection.zip"</span>extracted_path <span class="token operator">=</span> <span class="token string">"sms_spam_collection"</span> data_file_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>extracted_path<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"SMSSpamCollection.tsv"</span>data_file_path<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>WindowsPath(‘sms_spam_collection/SMSSpamCollection.tsv’)</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">download_and_unzip_spam_data</span><span class="token punctuation">(</span>    url<span class="token punctuation">,</span> zip_path<span class="token punctuation">,</span> extracted_path<span class="token punctuation">,</span> data_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> data_file_path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>data_file_path<span class="token punctuation">&#125;</span></span><span class="token string"> already exists. Skipping download "</span></span>            <span class="token string">"and extraction."</span><span class="token punctuation">)</span>        <span class="token keyword">return</span>    <span class="token keyword">with</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">as</span> response<span class="token punctuation">:</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>zip_path<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> out_file<span class="token punctuation">:</span>            out_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">with</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span>zip_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> zip_ref<span class="token punctuation">:</span>        zip_ref<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span>extracted_path<span class="token punctuation">)</span>        original_file_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>extracted_path<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"SMSSpamCollection"</span>    os<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>original_file_path<span class="token punctuation">,</span> data_file_path<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"File download and saved as </span><span class="token interpolation"><span class="token punctuation">&#123;</span>data_file_path<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    download_and_unzip_spam_data<span class="token punctuation">(</span>url<span class="token punctuation">,</span> zip_path<span class="token punctuation">,</span> extracted_path<span class="token punctuation">,</span> data_file_path<span class="token punctuation">)</span>        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>sms_spam_collection\SMSSpamCollection.tsv already exists. Skipping download and extraction.</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>    data_file_path<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">,</span> <span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>df<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Label</th>      <th>Text</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>ham</td>      <td>Go until jurong point, crazy.. Available only ...</td>    </tr>    <tr>      <th>1</th>      <td>ham</td>      <td>Ok lar... Joking wif u oni...</td>    </tr>    <tr>      <th>2</th>      <td>spam</td>      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>    </tr>    <tr>      <th>3</th>      <td>ham</td>      <td>U dun say so early hor... U c already then say...</td>    </tr>    <tr>      <th>4</th>      <td>ham</td>      <td>Nah I don't think he goes to usf, he lives aro...</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>5567</th>      <td>spam</td>      <td>This is the 2nd time we have tried 2 contact u...</td>    </tr>    <tr>      <th>5568</th>      <td>ham</td>      <td>Will ü b going to esplanade fr home?</td>    </tr>    <tr>      <th>5569</th>      <td>ham</td>      <td>Pity, * was in mood for that. So...any other s...</td>    </tr>    <tr>      <th>5570</th>      <td>ham</td>      <td>The guy did some bitching but I acted like i'd...</td>    </tr>    <tr>      <th>5571</th>      <td>ham</td>      <td>Rofl. Its true to its name</td>    </tr>  </tbody></table><p>5572 rows × 2 columns</p></div><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>Label<br>ham     4825<br>spam     747<br>Name: count, dtype: int64</p></blockquote><h1 id="2-Creating-a-balanced-dataset"><a href="#2-Creating-a-balanced-dataset" class="headerlink" title="2 | Creating a balanced dataset"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>2 |</span></b> <b><span style='color:#95cf92'>Creating a balanced dataset</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_balanced_dataset</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>    num_spam <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"spam"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    ham_subset <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"ham"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span>        num_spam<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">123</span>    <span class="token punctuation">)</span>    balanced_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>ham_subset<span class="token punctuation">,</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"spam"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> balanced_dfbalanced_df <span class="token operator">=</span> create_balanced_dataset<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>balanced_df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Label<br>ham     747<br>spam    747<br>Name: count, dtype: int64  </p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">balanced_df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span> <span class="token operator">=</span> balanced_df<span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"ham"</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"spam"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">random_split</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> train_frac<span class="token punctuation">,</span> validation_frac<span class="token punctuation">)</span><span class="token punctuation">:</span>    df <span class="token operator">=</span> df<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">123</span>        <span class="token punctuation">)</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    train_end <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">*</span> train_frac<span class="token punctuation">)</span>    validation_end <span class="token operator">=</span> train_end <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">*</span> validation_frac<span class="token punctuation">)</span>    train_df <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">:</span>train_end<span class="token punctuation">]</span>    validation_df <span class="token operator">=</span> df<span class="token punctuation">[</span>train_end<span class="token punctuation">:</span>validation_end<span class="token punctuation">]</span>    test_df <span class="token operator">=</span> df<span class="token punctuation">[</span>validation_end<span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> train_df<span class="token punctuation">,</span> validation_df<span class="token punctuation">,</span> test_dftrain_df<span class="token punctuation">,</span> validation_df<span class="token punctuation">,</span> test_df <span class="token operator">=</span> random_split<span class="token punctuation">(</span>    balanced_df<span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"train.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>validation_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"validation.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>test_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"test.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tiktokentokenizer <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"&lt;|endoftext|>"</span><span class="token punctuation">,</span> allowed_special<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">"&lt;|endoftext|>"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>[50256]</p></blockquote><h1 id="3-Setting-up-a-Pytorch-Dataset-class"><a href="#3-Setting-up-a-Pytorch-Dataset-class" class="headerlink" title="3 | Setting up a Pytorch Dataset class"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>3 |</span></b> <b><span style='color:#95cf92'>Setting up a Pytorch Dataset class</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">class</span> <span class="token class-name">SpamDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> csv_file<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                pad_token_id<span class="token operator">=</span><span class="token number">50256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoded_texts <span class="token operator">=</span> <span class="token punctuation">[</span>            tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span>        <span class="token punctuation">]</span>        <span class="token keyword">if</span> max_length <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> self<span class="token punctuation">.</span>_longest_encoded_length<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> max_length            self<span class="token punctuation">.</span>encoded_texts <span class="token operator">=</span> <span class="token punctuation">[</span>                encoded_text<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>max_length<span class="token punctuation">]</span>                <span class="token keyword">for</span> encoded_text <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoded_texts            <span class="token punctuation">]</span>        self<span class="token punctuation">.</span>encoded_texts <span class="token operator">=</span> <span class="token punctuation">[</span>            encoded_text <span class="token operator">+</span> <span class="token punctuation">[</span>pad_token_id<span class="token punctuation">]</span> <span class="token operator">*</span>             <span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_length <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>encoded_text<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> encoded_text <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoded_texts        <span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        encoded <span class="token operator">=</span> self<span class="token punctuation">.</span>encoded_texts<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        label <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"Label"</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>encoded<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">_longest_encoded_length</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        max_length <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> encoded_text <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoded_texts<span class="token punctuation">:</span>            encoded_length <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>encoded_text<span class="token punctuation">)</span>            <span class="token keyword">if</span> encoded_length <span class="token operator">></span> max_length<span class="token punctuation">:</span>                max_length <span class="token operator">=</span> encoded_length        <span class="token keyword">return</span> max_length    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_dataset <span class="token operator">=</span> SpamDataset<span class="token punctuation">(</span>    csv_file<span class="token operator">=</span><span class="token string">"train.csv"</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>120</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">val_dataset <span class="token operator">=</span> SpamDataset<span class="token punctuation">(</span>    csv_file<span class="token operator">=</span><span class="token string">"validation.csv"</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> SpamDataset<span class="token punctuation">(</span>    csv_file<span class="token operator">=</span><span class="token string">"test.csv"</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-Creating-PyTorch-data-loaders"><a href="#4-Creating-PyTorch-data-loaders" class="headerlink" title="4 | Creating PyTorch data loaders"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>4 |</span></b> <b><span style='color:#95cf92'>Creating PyTorch data loaders</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoadernum_workers <span class="token operator">=</span> <span class="token number">0</span>batch_size <span class="token operator">=</span> <span class="token number">8</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>val_dataset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">False</span> <span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span>     batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>    num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="5-Initializing-a-model-with-pretrained-weights"><a href="#5-Initializing-a-model-with-pretrained-weights" class="headerlink" title="5 | Initializing a model with pretrained weights"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>5 |</span></b> <b><span style='color:#95cf92'>Initializing a model with pretrained weights</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">CHOOSE_MODEL <span class="token operator">=</span> <span class="token string">"gpt2-small (124M)"</span>INPUT_PROMPT <span class="token operator">=</span> <span class="token string">"Every effort moves"</span>BASE_CONFIG <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"vocab_size"</span><span class="token punctuation">:</span> <span class="token number">50257</span><span class="token punctuation">,</span>    <span class="token string">"context_length"</span><span class="token punctuation">:</span> <span class="token number">1024</span><span class="token punctuation">,</span>    <span class="token string">"drop_rate"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>    <span class="token string">"qkv_bias"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span>model_configs <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"gpt2-small (124M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"gpt2-medium (355M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"gpt2-large (774M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">1280</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token string">"gpt2-xl (1558M)"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">1600</span><span class="token punctuation">,</span> <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span>BASE_CONFIG<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_configs<span class="token punctuation">[</span>CHOOSE_MODEL<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="6-Loading-pretrained-GPT-model"><a href="#6-Loading-pretrained-GPT-model" class="headerlink" title="6 | Loading pretrained GPT model"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>6 |</span></b> <b><span style='color:#95cf92'>Loading pretrained GPT model</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LayerNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> <span class="token number">1e-5</span>        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shift <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        var <span class="token operator">=</span> x<span class="token punctuation">.</span>var<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>scale <span class="token operator">*</span> norm_x <span class="token operator">+</span> self<span class="token punctuation">.</span>shift <span class="token keyword">class</span> <span class="token class-name">GELU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> x <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>pi<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span>            <span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token number">0.44715</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">FeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span>        context_length<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token punctuation">(</span>d_out <span class="token operator">%</span> num_heads <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \            <span class="token string">'d_out must divisible by num_heads'</span>        self<span class="token punctuation">.</span>d_out <span class="token operator">=</span> d_out        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        self<span class="token punctuation">.</span>head_dim <span class="token operator">=</span> d_out <span class="token operator">//</span> num_heads        self<span class="token punctuation">.</span>W_query <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_out<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span>            <span class="token string">"mask"</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>context_length<span class="token punctuation">,</span> context_length<span class="token punctuation">)</span><span class="token punctuation">,</span>                diagonal<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> d_in <span class="token operator">=</span> x<span class="token punctuation">.</span>shape         queries <span class="token operator">=</span> self<span class="token punctuation">.</span>W_query<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        keys <span class="token operator">=</span> self<span class="token punctuation">.</span>W_key<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        values <span class="token operator">=</span> self<span class="token punctuation">.</span>W_value<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        attn_scores <span class="token operator">=</span> queries @ keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        mask_bool <span class="token operator">=</span> self<span class="token punctuation">.</span>mask<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>num_tokens<span class="token punctuation">,</span> <span class="token punctuation">:</span>num_tokens<span class="token punctuation">]</span>        attn_scores<span class="token punctuation">.</span>masked_fill_<span class="token punctuation">(</span>mask_bool<span class="token punctuation">,</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>inf<span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>            attn_scores <span class="token operator">/</span> keys<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attn_weights<span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> <span class="token punctuation">(</span>attn_weights @ values<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> context_vec<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>            b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_out<span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>out_proj<span class="token punctuation">(</span>context_vec<span class="token punctuation">)</span>        <span class="token keyword">return</span> context_vec<span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>att <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>            d_in<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            d_out<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            context_length<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            num_heads<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"n_heads"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            dropout<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            qkv_bias<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"qkv_bias"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ff <span class="token operator">=</span> FeedForward<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        shortcut <span class="token operator">=</span> x        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>att<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut        shortcut <span class="token operator">=</span> x         x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ff<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">GPTModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>tok_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>trf_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span><span class="token punctuation">[</span>TransformerBlock<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"n_layers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>final_norm <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>            cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch_size<span class="token punctuation">,</span> seq_len <span class="token operator">=</span> in_idx<span class="token punctuation">.</span>shape        tok_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>tok_emb<span class="token punctuation">(</span>in_idx<span class="token punctuation">)</span>        pos_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_emb<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> device<span class="token operator">=</span>in_idx<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tok_embeds <span class="token operator">+</span> pos_embeds        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_emb<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>final_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>out_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py#L17-L44</span><span class="token keyword">def</span> <span class="token function">download_and_load_gpt2</span><span class="token punctuation">(</span>model_size<span class="token punctuation">,</span> models_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># Validate model size</span>    allowed_sizes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"124M"</span><span class="token punctuation">,</span> <span class="token string">"355M"</span><span class="token punctuation">,</span> <span class="token string">"774M"</span><span class="token punctuation">,</span> <span class="token string">"1558M"</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> model_size <span class="token keyword">not</span> <span class="token keyword">in</span> allowed_sizes<span class="token punctuation">:</span>        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Model size not in </span><span class="token interpolation"><span class="token punctuation">&#123;</span>allowed_sizes<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token comment"># Define paths</span>    model_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>models_dir<span class="token punctuation">,</span> model_size<span class="token punctuation">)</span>    base_url <span class="token operator">=</span> <span class="token string">"https://openaipublic.blob.core.windows.net/gpt-2/models"</span>    filenames <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token string">"checkpoint"</span><span class="token punctuation">,</span> <span class="token string">"encoder.json"</span><span class="token punctuation">,</span> <span class="token string">"hparams.json"</span><span class="token punctuation">,</span>        <span class="token string">"model.ckpt.data-00000-of-00001"</span><span class="token punctuation">,</span> <span class="token string">"model.ckpt.index"</span><span class="token punctuation">,</span>        <span class="token string">"model.ckpt.meta"</span><span class="token punctuation">,</span> <span class="token string">"vocab.bpe"</span>    <span class="token punctuation">]</span>    <span class="token comment"># Download files</span>    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> filename <span class="token keyword">in</span> filenames<span class="token punctuation">:</span>        file_url <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_url<span class="token punctuation">,</span> model_size<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>        file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>        download_file<span class="token punctuation">(</span>file_url<span class="token punctuation">,</span> file_path<span class="token punctuation">)</span>    <span class="token comment"># Load settings and params</span>    tf_ckpt_path <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>latest_checkpoint<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>    settings <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> <span class="token string">"hparams.json"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    params <span class="token operator">=</span> load_gpt2_params_from_tf_ckpt<span class="token punctuation">(</span>tf_ckpt_path<span class="token punctuation">,</span> settings<span class="token punctuation">)</span>    <span class="token keyword">return</span> settings<span class="token punctuation">,</span> params<span class="token comment"># https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py#L47-L82</span><span class="token keyword">def</span> <span class="token function">download_file</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> destination<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># Send a GET request to download the file</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">as</span> response<span class="token punctuation">:</span>            <span class="token comment"># Get the total file size from headers, defaulting to 0 if not present</span>            file_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>headers<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"Content-Length"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># Check if file exists and has the same size</span>            <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>destination<span class="token punctuation">)</span><span class="token punctuation">:</span>                file_size_local <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>getsize<span class="token punctuation">(</span>destination<span class="token punctuation">)</span>                <span class="token keyword">if</span> file_size <span class="token operator">==</span> file_size_local<span class="token punctuation">:</span>                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"File already exists and is up-to-date: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>destination<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>                    <span class="token keyword">return</span>            <span class="token comment"># Define the block size for reading the file</span>            block_size <span class="token operator">=</span> <span class="token number">1024</span>  <span class="token comment"># 1 Kilobyte</span>            <span class="token comment"># Initialize the progress bar with total file size</span>            progress_bar_description <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>url<span class="token punctuation">)</span>  <span class="token comment"># Extract filename from URL</span>            <span class="token keyword">with</span> tqdm<span class="token punctuation">(</span>total<span class="token operator">=</span>file_size<span class="token punctuation">,</span> unit<span class="token operator">=</span><span class="token string">"iB"</span><span class="token punctuation">,</span> unit_scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> desc<span class="token operator">=</span>progress_bar_description<span class="token punctuation">)</span> <span class="token keyword">as</span> progress_bar<span class="token punctuation">:</span>                <span class="token comment"># Open the destination file in binary write mode</span>                <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>destination<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>                    <span class="token comment"># Read the file in chunks and write to destination</span>                    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                        chunk <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span>block_size<span class="token punctuation">)</span>                        <span class="token keyword">if</span> <span class="token keyword">not</span> chunk<span class="token punctuation">:</span>                            <span class="token keyword">break</span>                        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>                        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Update progress bar</span>    <span class="token keyword">except</span> urllib<span class="token punctuation">.</span>error<span class="token punctuation">.</span>HTTPError<span class="token punctuation">:</span>        s <span class="token operator">=</span> <span class="token punctuation">(</span>            <span class="token string-interpolation"><span class="token string">f"The specified URL (</span><span class="token interpolation"><span class="token punctuation">&#123;</span>url<span class="token punctuation">&#125;</span></span><span class="token string">) is incorrect, the internet connection cannot be established,"</span></span>            <span class="token string">"\nor the requested file is temporarily unavailable.\nPlease visit the following website"</span>            <span class="token string">" for help: https://github.com/rasbt/LLMs-from-scratch/discussions/273"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token comment"># https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py#L116-L142</span><span class="token keyword">def</span> <span class="token function">load_gpt2_params_from_tf_ckpt</span><span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> settings<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># Initialize parameters dictionary with empty blocks for each layer</span>    params <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"blocks"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>settings<span class="token punctuation">[</span><span class="token string">"n_layer"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span>    <span class="token comment"># Iterate over each variable in the checkpoint</span>    <span class="token keyword">for</span> name<span class="token punctuation">,</span> _ <span class="token keyword">in</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>list_variables<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Load the variable and remove singleton dimensions</span>        variable_array <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>load_variable<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># Process the variable name to extract relevant parts</span>        variable_name_parts <span class="token operator">=</span> name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># Skip the 'model/' prefix</span>        <span class="token comment"># Identify the target dictionary for the variable</span>        target_dict <span class="token operator">=</span> params        <span class="token keyword">if</span> variable_name_parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"h"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            layer_number <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>variable_name_parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            target_dict <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>layer_number<span class="token punctuation">]</span>        <span class="token comment"># Recursively access or create nested dictionaries</span>        <span class="token keyword">for</span> key <span class="token keyword">in</span> variable_name_parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            target_dict <span class="token operator">=</span> target_dict<span class="token punctuation">.</span>setdefault<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        <span class="token comment"># Assign the variable array to the last key</span>        last_key <span class="token operator">=</span> variable_name_parts<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        target_dict<span class="token punctuation">[</span>last_key<span class="token punctuation">]</span> <span class="token operator">=</span> variable_array    <span class="token keyword">return</span> params<span class="token keyword">def</span> <span class="token function">assign</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span> right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> left<span class="token punctuation">.</span>shape <span class="token operator">!=</span> right<span class="token punctuation">.</span>shape<span class="token punctuation">:</span>        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Shape mismatch. left: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>left<span class="token punctuation">.</span>shape<span class="token punctuation">&#125;</span></span><span class="token string">, "</span></span>                        <span class="token string">"Right: &#123;right.shape&#125;"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>right<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">load_weights_into_gpt</span><span class="token punctuation">(</span>gpt<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>    gpt<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'wpe'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>tok_emb<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>tok_emb<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">'wte'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        q_w<span class="token punctuation">,</span> k_w<span class="token punctuation">,</span> v_w <span class="token operator">=</span> np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>        <span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_attn"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> q_w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> k_w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> v_w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>        q_b<span class="token punctuation">,</span> k_b<span class="token punctuation">,</span> v_b <span class="token operator">=</span> np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>        <span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_attn"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_query<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> q_b<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_key<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> k_b<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>W_value<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> v_b<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>att<span class="token punctuation">.</span>out_proj<span class="token punctuation">.</span>bias<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"attn"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_fc"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_fc"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"w"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>ff<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"mlp"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"c_proj"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>scale <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>scale<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_1"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"g"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>shift <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm1<span class="token punctuation">.</span>shift<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_1"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>scale <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>scale<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_2"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"g"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>shift <span class="token operator">=</span> assign<span class="token punctuation">(</span>            gpt<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">.</span>norm2<span class="token punctuation">.</span>shift<span class="token punctuation">,</span>            params<span class="token punctuation">[</span><span class="token string">"blocks"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ln_2"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>scale <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>scale<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">"g"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>shift <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>shift<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">"b"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    gpt<span class="token punctuation">.</span>out_head<span class="token punctuation">.</span>weight <span class="token operator">=</span> assign<span class="token punctuation">(</span>gpt<span class="token punctuation">.</span>out_head<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> params<span class="token punctuation">[</span><span class="token string">"wte"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">generate_text_simple</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> idx<span class="token punctuation">,</span>    max_new_tokens<span class="token punctuation">,</span> context_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_new_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>        idx_cond <span class="token operator">=</span> idx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>context_size<span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            logits <span class="token operator">=</span> model<span class="token punctuation">(</span>idx_cond<span class="token punctuation">)</span>        logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>        probas <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        idx_next <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>probas<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> idx_next<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> idx <span class="token keyword">def</span> <span class="token function">text_to_token_ids</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> allowed_special<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'&lt;|endoftext|>'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>    encoded_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>encoded<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> encoded_tensor<span class="token keyword">def</span> <span class="token function">token_ids_to_text</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    flat <span class="token operator">=</span> token_ids<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>flat<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model_size <span class="token operator">=</span> CHOOSE_MODEL<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">"("</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">")"</span><span class="token punctuation">)</span>settings<span class="token punctuation">,</span> params <span class="token operator">=</span> download_and_load_gpt2<span class="token punctuation">(</span>    model_size<span class="token operator">=</span>model_size<span class="token punctuation">,</span> models_dir<span class="token operator">=</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span>model <span class="token operator">=</span> GPTModel<span class="token punctuation">(</span>BASE_CONFIG<span class="token punctuation">)</span>load_weights_into_gpt<span class="token punctuation">(</span>model<span class="token punctuation">,</span> params<span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>File already exists and is up-to-date: gpt2\124M\checkpoint<br>    File already exists and is up-to-date: gpt2\124M\encoder.json<br>    File already exists and is up-to-date: gpt2\124M\hparams.json<br>    File already exists and is up-to-date: gpt2\124M\model.ckpt.data-00000-of-00001<br>    File already exists and is up-to-date: gpt2\124M\model.ckpt.index<br>    File already exists and is up-to-date: gpt2\124M\model.ckpt.meta<br>    File already exists and is up-to-date: gpt2\124M\vocab.bpe  </p></blockquote><pre class="line-numbers language-text" data-language="text"><code class="language-text">GPTModel(  (tok_emb): Embedding(50257, 768)  (pos_emb): Embedding(1024, 768)  (drop_emb): Dropout(p=0.0, inplace=False)  (trf_blocks): Sequential(    (0): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (1): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (2): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (3): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (4): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (5): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (6): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (7): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (8): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (9): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (10): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )    (11): TransformerBlock(      (att): MultiHeadAttention(        (W_query): Linear(in_features=768, out_features=768, bias=True)        (W_key): Linear(in_features=768, out_features=768, bias=True)        (W_value): Linear(in_features=768, out_features=768, bias=True)        (out_proj): Linear(in_features=768, out_features=768, bias=True)        (dropout): Dropout(p=0.0, inplace=False)      )      (ff): FeedForward(        (layers): Sequential(          (0): Linear(in_features=768, out_features=3072, bias=True)          (1): GELU()          (2): Linear(in_features=3072, out_features=768, bias=True)        )      )      (norm1): LayerNorm()      (norm2): LayerNorm()      (drop_shortcut): Dropout(p=0.0, inplace=False)    )  )  (final_norm): LayerNorm()  (out_head): Linear(in_features=768, out_features=50257, bias=False))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">text_1 <span class="token operator">=</span> <span class="token string">"Every effort moves you"</span>token_ids <span class="token operator">=</span> generate_text_simple<span class="token punctuation">(</span>    model<span class="token operator">=</span>model<span class="token punctuation">,</span>    idx <span class="token operator">=</span> text_to_token_ids<span class="token punctuation">(</span>text_1<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>    max_new_tokens<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span>    context_size <span class="token operator">=</span> BASE_CONFIG<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>token_ids_to_text<span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Every effort moves you to the point of the &quot;I-don-it-from-the</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">text_2 <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token string">"Is the following text 'spam'? Answer the 'yes' or 'no':"</span>    <span class="token string">" 'You are a winner you have been specially"</span>    <span class="token string">" selected to receive $1000 cash or a $2000 award."</span><span class="token punctuation">)</span>token_ids <span class="token operator">=</span> generate_text_simple<span class="token punctuation">(</span>    model<span class="token operator">=</span>model<span class="token punctuation">,</span>    idx<span class="token operator">=</span>text_to_token_ids<span class="token punctuation">(</span>text_2<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>    max_new_tokens<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">,</span>    context_size<span class="token operator">=</span>BASE_CONFIG<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>token_ids_to_text<span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Is the following text ‘spam’? Answer the ‘yes’ or ‘no’: ‘You are a winner you have   been specially selected to receive $1000 cash or a $2000 award.’’’’’’’</p></blockquote><h1 id="7-Adding-a-classification-head"><a href="#7-Adding-a-classification-head" class="headerlink" title="7 | Adding a classification head"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>7 |</span></b> <b><span style='color:#95cf92'>Adding a classification head</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>required_grad <span class="token operator">=</span> <span class="token boolean">False</span>     torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>num_classes <span class="token operator">=</span> <span class="token number">2</span> model<span class="token punctuation">.</span>out_head <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>    in_features<span class="token operator">=</span>BASE_CONFIG<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    out_features<span class="token operator">=</span>num_classes<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>required_grad <span class="token operator">=</span> <span class="token boolean">True</span>     <span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>final_norm<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>required_grad <span class="token operator">=</span> <span class="token boolean">True</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="8-Calculating-the-classification-accuracy"><a href="#8-Calculating-the-classification-accuracy" class="headerlink" title="8 | Calculating the classification accuracy"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>8 |</span></b> <b><span style='color:#95cf92'>Calculating the classification accuracy</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_accuracy_loader</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    correct_predictions<span class="token punctuation">,</span> num_examples <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>         <span class="token keyword">if</span> num_batches <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> num_batches<span class="token punctuation">:</span>            input_batch <span class="token operator">=</span> input_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            target_batch <span class="token operator">=</span> target_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>            predicted_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            num_examples <span class="token operator">+=</span> predicted_labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            correct_predictions <span class="token operator">+=</span> <span class="token punctuation">(</span>                <span class="token punctuation">(</span>predicted_labels <span class="token operator">==</span> target_batch<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> correct_predictions <span class="token operator">/</span> num_examples            <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>train_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>val_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>test_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training accuracy: 45.31%<br>    Validation accuracy: 45.31%<br>    Test accuracy: 53.12% </p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_loss_batch</span><span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_batch <span class="token operator">=</span> input_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    target_batch <span class="token operator">=</span> target_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token keyword">def</span> <span class="token function">calc_loss_loader</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>     <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">"nan"</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> num_batches <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> num_batches<span class="token punctuation">:</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device            <span class="token punctuation">)</span>            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> num_batches    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>        train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">5</span>    <span class="token punctuation">)</span>    val_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    test_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test loss: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training loss: 2.991<br>    Validation loss: 2.955<br>    Test loss: 2.877 </p></blockquote><h1 id="9-Fine-tuning-the-model-to-classify-spam"><a href="#9-Fine-tuning-the-model-to-classify-spam" class="headerlink" title="9 | Fine-tuning the model to classify spam"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>9 |</span></b> <b><span style='color:#95cf92'>Fine-tuning the model to classify spam</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_classifier_simple</span><span class="token punctuation">(</span>    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span>    num_epochs<span class="token punctuation">,</span> eval_freq<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    examples_seen<span class="token punctuation">,</span> global_step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span>     <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> input_batch<span class="token punctuation">,</span> target_batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device            <span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            examples_seen <span class="token operator">+=</span> input_batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            global_step <span class="token operator">+=</span> <span class="token number">1</span>                        <span class="token keyword">if</span> global_step <span class="token operator">%</span> eval_freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                train_loss<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>                    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span>                train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>                val_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ep </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string"> (step </span><span class="token interpolation"><span class="token punctuation">&#123;</span>global_step<span class="token punctuation">:</span><span class="token format-spec">06d</span><span class="token punctuation">&#125;</span></span><span class="token string">) :"</span></span>                    <span class="token string-interpolation"><span class="token string">f"Train loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">, "</span></span>                    <span class="token string-interpolation"><span class="token string">f"Val loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>        train_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>            train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>        val_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>            val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">% | "</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span>        train_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_accuracy<span class="token punctuation">)</span>        val_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_accuracy<span class="token punctuation">)</span>    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs<span class="token punctuation">,</span> examples_seen<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>        val_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> train_loss<span class="token punctuation">,</span> val_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">%</span><span class="token operator">%</span>time<span class="token keyword">import</span> time start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">5e-5</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>num_epochs <span class="token operator">=</span> <span class="token number">5</span>train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs<span class="token punctuation">,</span> examples_seen <span class="token operator">=</span> \    train_classifier_simple<span class="token punctuation">(</span>        model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span>        num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_freq<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>        eval_iter<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>execution_time_minutes <span class="token operator">=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training completed in </span><span class="token interpolation"><span class="token punctuation">&#123;</span>execution_time_minutes<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string"> minutes."</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Ep 1 (step 000000) :Train loss 0.850, Val loss 0.963<br>    Ep 1 (step 000050) :Train loss 0.390, Val loss 0.375<br>    Ep 1 (step 000100) :Train loss 0.167, Val loss 0.609<br>    Training accuracy: 95.00% | Validation accuracy: 95.00%<br>    Ep 2 (step 000150) :Train loss 0.136, Val loss 0.135<br>    Ep 2 (step 000200) :Train loss 0.032, Val loss 0.047<br>    Ep 2 (step 000250) :Train loss 0.018, Val loss 0.081<br>    Training accuracy: 100.00% | Validation accuracy: 92.50%<br>    Ep 3 (step 000300) :Train loss 0.117, Val loss 0.030<br>    Ep 3 (step 000350) :Train loss 0.013, Val loss 0.102<br>    Training accuracy: 100.00% | Validation accuracy: 97.50%<br>    Ep 4 (step 000400) :Train loss 0.019, Val loss 0.023<br>    Ep 4 (step 000450) :Train loss 0.023, Val loss 0.173<br>    Ep 4 (step 000500) :Train loss 0.108, Val loss 0.104<br>    Training accuracy: 100.00% | Validation accuracy: 95.00%<br>    Ep 5 (step 000550) :Train loss 0.075, Val loss 0.009<br>    Ep 5 (step 000600) :Train loss 0.001, Val loss 0.007<br>    Training accuracy: 97.50% | Validation accuracy: 97.50%<br>    Training completed in 14.45 minutes.<br>    CPU times: total: 6min 58s<br>    Wall time: 14min 26s  </p></blockquote><h1 id="10-Plotting-the-classification-loss"><a href="#10-Plotting-the-classification-loss" class="headerlink" title="10 | Plotting the classification loss"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>10 |</span></b> <b><span style='color:#95cf92'>Plotting the classification loss</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">def</span> <span class="token function">plot_values</span><span class="token punctuation">(</span>    epochs_seen<span class="token punctuation">,</span> examples_seen<span class="token punctuation">,</span> train_values<span class="token punctuation">,</span> val_values<span class="token punctuation">,</span>    label<span class="token operator">=</span><span class="token string">"loss"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    fig<span class="token punctuation">,</span> axl <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_seen<span class="token punctuation">,</span> train_values<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"Training </span><span class="token interpolation"><span class="token punctuation">&#123;</span>label<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>        epochs_seen<span class="token punctuation">,</span> val_values<span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">"-."</span><span class="token punctuation">,</span>        label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"Validation </span><span class="token interpolation"><span class="token punctuation">&#123;</span>label<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>    <span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"Epochs"</span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>label<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    axl<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>        ax2 <span class="token operator">=</span> axl<span class="token punctuation">.</span>twiny<span class="token punctuation">(</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>examples_seen<span class="token punctuation">,</span> train_values<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"Examples seen"</span><span class="token punctuation">)</span>        fig<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>label<span class="token punctuation">&#125;</span></span><span class="token string">-plot.pdf"</span></span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 假设你已经定义了 num_epochs, examples_seen, train_losses, val_losses</span>epochs_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_losses<span class="token punctuation">)</span><span class="token punctuation">)</span>examples_seen_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> examples_seen<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_losses<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 调用 plot_values 函数</span>plot_values<span class="token punctuation">(</span>epochs_tensor<span class="token punctuation">,</span> examples_seen_tensor<span class="token punctuation">,</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pA0qutJ"><img src="https://s21.ax1x.com/2024/10/29/pA0qutJ.png" alt="pA0qutJ.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">epochs_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_accs<span class="token punctuation">)</span><span class="token punctuation">)</span>examples_seen_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> examples_seen<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_accs<span class="token punctuation">)</span><span class="token punctuation">)</span>plot_values<span class="token punctuation">(</span>    epochs_tensor<span class="token punctuation">,</span> examples_seen_tensor<span class="token punctuation">,</span> train_accs<span class="token punctuation">,</span> val_accs<span class="token punctuation">,</span>    label<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pA0qKh9"><img src="https://s21.ax1x.com/2024/10/29/pA0qKh9.png" alt="pA0qKh9.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>val_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>test_accuracy <span class="token operator">=</span> calc_accuracy_loader<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Validation accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>Training accuracy: 98.27%<br>    Validation accuracy: 97.32%<br>    Test accuracy: 94.67%</p></blockquote><h1 id="11-Using-the-model-to-classify-new-texts"><a href="#11-Using-the-model-to-classify-new-texts" class="headerlink" title="11 | Using the model to classify new texts"></a><div style="padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#95cf92;overflow:hidden;background-color:#1982c4"><b><span style='color:#95cf92'>11 |</span></b> <b><span style='color:#95cf92'>Using the model to classify new texts</b></div></h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">classify_review</span><span class="token punctuation">(</span>    text<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    pad_token_id<span class="token operator">=</span><span class="token number">50256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        input_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    supprted_context_length <span class="token operator">=</span> model<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        input_ids <span class="token operator">=</span> input_ids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">min</span><span class="token punctuation">(</span>        max_length<span class="token punctuation">,</span> supprted_context_length    <span class="token punctuation">)</span><span class="token punctuation">]</span>        input_ids <span class="token operator">+=</span> <span class="token punctuation">[</span>pad_token_id<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>max_length <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">)</span>    input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>        input_ids<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    predicted_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">"spam"</span> <span class="token keyword">if</span> predicted_label <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">"not spam"</span>text_1 <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token string">"You are a winner you have been specially"</span>    <span class="token string">" selected to receive $1000 cash or $200 award."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>classify_review<span class="token punctuation">(</span>    text_1<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> max_length<span class="token operator">=</span>train_dataset<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>spam</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">text_2 <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"Hey, just wanted to check if we're still on"</span><span class="token string">" for dinner tonight? Let me know!"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>classify_review<span class="token punctuation">(</span>text_2<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> max_length<span class="token operator">=</span>train_dataset<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>not spam</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"review_classifier.pth"</span><span class="token punctuation">)</span>model_state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"review_classifier.pth"</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_state_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>&lt;All keys matched successfully&gt;</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT_model</title>
      <link href="2024/10/23/gpt-model/"/>
      <url>2024/10/23/gpt-model/</url>
      
        <content type="html"><![CDATA[<p><strong>GPT架构总览</strong>如下图所示，我们这里简单创建了一个GPT模型，它是ChatGPT的基础架构。</p><p><a href="https://imgse.com/i/pAdEp40"><img src="https://s21.ax1x.com/2024/10/22/pAdEp40.png" alt="pAdEp40.png"></a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tiktoken<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="MultiHeadAttention"><a href="#MultiHeadAttention" class="headerlink" title="MultiHeadAttention"></a>MultiHeadAttention</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span>        context_length<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token punctuation">(</span>d_out <span class="token operator">%</span> num_heads <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \            <span class="token string">"d_out must divisible by num_heads"</span>        self<span class="token punctuation">.</span>d_out <span class="token operator">=</span> d_out         self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        self<span class="token punctuation">.</span>head_dim <span class="token operator">=</span> d_out <span class="token operator">//</span> num_heads        self<span class="token punctuation">.</span>W_query <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_out<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span>            <span class="token string">"mask"</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>context_length<span class="token punctuation">,</span> context_length<span class="token punctuation">)</span><span class="token punctuation">,</span>                diagonal<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> d_in <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        queries <span class="token operator">=</span> self<span class="token punctuation">.</span>W_query<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        keys <span class="token operator">=</span> self<span class="token punctuation">.</span>W_key<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        values <span class="token operator">=</span> self<span class="token punctuation">.</span>W_value<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>head_dim<span class="token punctuation">)</span>        <span class="token comment"># (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)</span>        keys <span class="token operator">=</span> keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        queries <span class="token operator">=</span> queries<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        values <span class="token operator">=</span> values<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># attn_scores: (b, num_heads, num_tokens, num_tokens)</span>        attn_scores <span class="token operator">=</span> queries @ keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        mask_bool <span class="token operator">=</span> self<span class="token punctuation">.</span>mask<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>num_tokens<span class="token punctuation">,</span> <span class="token punctuation">:</span>num_tokens<span class="token punctuation">]</span>        attn_scores<span class="token punctuation">.</span>masked_fill_<span class="token punctuation">(</span>mask_bool<span class="token punctuation">,</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>inf<span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>            attn_scores <span class="token operator">/</span> keys<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attn_weights<span class="token punctuation">)</span>        <span class="token comment"># (b, num_heads, num_tokens, num_tokens) * (b, num_heads, num_tokens, head_dim)</span>        <span class="token comment"># (b, num_heads, num_tokens, head_dim) -> (b, num_tokens, num_heads, head_dim)</span>        context_vec <span class="token operator">=</span> <span class="token punctuation">(</span>attn_weights @ values<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> context_vec<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>            b<span class="token punctuation">,</span> num_tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_out        <span class="token punctuation">)</span>        context_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>out_proj<span class="token punctuation">(</span>context_vec<span class="token punctuation">)</span>        <span class="token keyword">return</span> context_vec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="GELU激活函数"><a href="#GELU激活函数" class="headerlink" title="GELU激活函数"></a>GELU激活函数</h3><p>GELU激活函数在大模型中运用较多，相比RELU，GELU更平滑，有利于减少梯度爆炸或梯度消失的情况。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GELU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> x <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>pi<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span>             <span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token number">0.44715</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="FeedForward"><a href="#FeedForward" class="headerlink" title="FeedForward"></a>FeedForward</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            GELU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a>LayerNorm</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LayerNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> <span class="token number">1e-5</span>        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shift <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>emb_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        var <span class="token operator">=</span> x<span class="token punctuation">.</span>var<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        norm_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>scale <span class="token operator">*</span> norm_x <span class="token operator">+</span> self<span class="token punctuation">.</span>shift<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="TransformerBlock"><a href="#TransformerBlock" class="headerlink" title="TransformerBlock"></a>TransformerBlock</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>att <span class="token operator">=</span> MultiHeadAttention<span class="token punctuation">(</span>            d_in<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            d_out<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            context_length<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            num_heads<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"n_heads"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            dropout<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            qkv_bias<span class="token operator">=</span>cfg<span class="token punctuation">[</span><span class="token string">"qkv_bias"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ff <span class="token operator">=</span> FeedForward<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        shortcut <span class="token operator">=</span> x         x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>att<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut                shortcut <span class="token operator">=</span> x         x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ff<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x <span class="token operator">+</span> shortcut        <span class="token keyword">return</span> x <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GPTModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>tok_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>drop_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"drop_rate"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>trf_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span><span class="token punctuation">[</span>TransformerBlock<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"n_layers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>final_norm <span class="token operator">=</span> LayerNorm<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out_head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>            cfg<span class="token punctuation">[</span><span class="token string">"emb_dim"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cfg<span class="token punctuation">[</span><span class="token string">"vocab_size"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch_size<span class="token punctuation">,</span> seq_len <span class="token operator">=</span> in_idx<span class="token punctuation">.</span>shape        tok_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>tok_emb<span class="token punctuation">(</span>in_idx<span class="token punctuation">)</span>        pos_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_emb<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> device<span class="token operator">=</span>in_idx<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        <span class="token punctuation">)</span>        x <span class="token operator">=</span> tok_embeds <span class="token operator">+</span> pos_embeds        x <span class="token operator">=</span> self<span class="token punctuation">.</span>drop_emb<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>trf_blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>final_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>out_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">GPT_CONFIG_124M <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">"vocab_size"</span><span class="token punctuation">:</span> <span class="token number">50257</span><span class="token punctuation">,</span> <span class="token comment"># Vocabulary size</span>    <span class="token string">"context_length"</span><span class="token punctuation">:</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token comment"># Context length</span>    <span class="token string">"emb_dim"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span> <span class="token comment"># Embedding dimension</span>    <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token comment"># Number of attention heads</span>    <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token comment"># Number of layers</span>    <span class="token string">"drop_rate"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token comment"># Dropout rate</span>    <span class="token string">"qkv_bias"</span><span class="token punctuation">:</span> <span class="token boolean">False</span> <span class="token comment"># Query-Key-Value bias</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generate_text_simple</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> idx<span class="token punctuation">,</span>                        max_new_tokens<span class="token punctuation">,</span> context_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 一次一次的迭代续写</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_new_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>        idx_cond <span class="token operator">=</span> idx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>context_size<span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            logits <span class="token operator">=</span> model<span class="token punctuation">(</span>idx_cond<span class="token punctuation">)</span>                    logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># The last time step</span>        probas <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        idx_next <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>probas<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> idx_next<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> idx<span class="token keyword">def</span> <span class="token function">text_to_token_ids</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoded <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> allowed_special<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'&lt;|endoftext|>'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>    encoded_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>encoded<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> encoded_tensor<span class="token keyword">def</span> <span class="token function">token_ids_to_text</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    flat <span class="token operator">=</span> token_ids<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>flat<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_loss_batch</span><span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_batch <span class="token operator">=</span> input_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    target_batch <span class="token operator">=</span> target_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>input_batch<span class="token punctuation">)</span>    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>        logits<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target_batch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token keyword">def</span> <span class="token function">calc_loss_loader</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0.</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">"nan"</span><span class="token punctuation">)</span>    <span class="token keyword">elif</span> num_batches <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        num_batches <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> num_batches<span class="token punctuation">:</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device             <span class="token punctuation">)</span>            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> num_batches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="预训练函数"><a href="#预训练函数" class="headerlink" title="预训练函数"></a>预训练函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_model_simple</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span>                    optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span>                    eval_freq<span class="token punctuation">,</span> eval_iter<span class="token punctuation">,</span> start_context<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> track_tokens_seen <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    tokens_seen<span class="token punctuation">,</span> global_step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> input_batch<span class="token punctuation">,</span> target_batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> calc_loss_batch<span class="token punctuation">(</span>                input_batch<span class="token punctuation">,</span> target_batch<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device            <span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            tokens_seen <span class="token operator">+=</span> input_batch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span>            global_step <span class="token operator">+=</span> <span class="token number">1</span>                        <span class="token keyword">if</span> global_step <span class="token operator">%</span> eval_freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                train_loss<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>                    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter                <span class="token punctuation">)</span>                train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>                val_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span>                track_tokens_seen<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokens_seen<span class="token punctuation">)</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ep </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string"> (Step </span><span class="token interpolation"><span class="token punctuation">&#123;</span>global_step<span class="token punctuation">:</span><span class="token format-spec">06d</span><span class="token punctuation">&#125;</span></span><span class="token string">): "</span></span>                    <span class="token string-interpolation"><span class="token string">f"Train loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">, "</span></span>                    <span class="token string-interpolation"><span class="token string">f"Val loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>        generate_and_print_sample<span class="token punctuation">(</span>            model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> start_context        <span class="token punctuation">)</span>    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> track_tokens_seen<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> device<span class="token punctuation">,</span> eval_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter        <span class="token punctuation">)</span>        val_loss <span class="token operator">=</span> calc_loss_loader<span class="token punctuation">(</span>            val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> num_batches<span class="token operator">=</span>eval_iter        <span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> train_loss<span class="token punctuation">,</span> val_loss<span class="token keyword">def</span> <span class="token function">generate_and_print_sample</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> start_context<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    context_size <span class="token operator">=</span> model<span class="token punctuation">.</span>pos_emb<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    encoded <span class="token operator">=</span> text_to_token_ids<span class="token punctuation">(</span>start_context<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        token_ids <span class="token operator">=</span> generate_text_simple<span class="token punctuation">(</span>            model<span class="token operator">=</span>model<span class="token punctuation">,</span> idx<span class="token operator">=</span>encoded<span class="token punctuation">,</span>            max_new_tokens<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> context_size<span class="token operator">=</span>context_size        <span class="token punctuation">)</span>    decoded_text <span class="token operator">=</span> token_ids_to_text<span class="token punctuation">(</span>token_ids<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>decoded_text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="加载数据类"><a href="#加载数据类" class="headerlink" title="加载数据类"></a>加载数据类</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GPTDatasetV1</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> txt<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>input_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>target_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                token_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>txt<span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token_ids<span class="token punctuation">)</span> <span class="token operator">-</span> max_length<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>            input_chunk <span class="token operator">=</span> token_ids<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>max_length<span class="token punctuation">]</span>            target_chunk <span class="token operator">=</span> token_ids<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span>i<span class="token operator">+</span>max_length<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>                self<span class="token punctuation">.</span>input_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>input_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>target_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_ids<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>input_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>target_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">create_dataloader_v1</span><span class="token punctuation">(</span>txt<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>                        stride<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                        num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tokenizer <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span>    dataset <span class="token operator">=</span> GPTDatasetV1<span class="token punctuation">(</span>txt<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> max_length<span class="token punctuation">,</span> stride<span class="token punctuation">)</span>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        dataset<span class="token punctuation">,</span>        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>        shuffle<span class="token operator">=</span>shuffle<span class="token punctuation">,</span>        drop_last<span class="token operator">=</span>drop_last<span class="token punctuation">,</span>        num_workers<span class="token operator">=</span>num_workers    <span class="token punctuation">)</span>    <span class="token keyword">return</span> dataloader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="下载预训练数据"><a href="#下载预训练数据" class="headerlink" title="下载预训练数据"></a>下载预训练数据</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>requesturl <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"https://raw.githubusercontent.com/rasbt/"</span>    <span class="token string">"LLMs-from-scratch/main/ch02/01_main-chapter-code/"</span>    <span class="token string">"the-verdict.txt"</span><span class="token punctuation">)</span>file_path <span class="token operator">=</span> <span class="token string">"the-verdict.txt"</span>urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span> file_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">file_path <span class="token operator">=</span> <span class="token string">"the-verdict.txt"</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>    text_data <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    tokenizer <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"gpt2"</span><span class="token punctuation">)</span>total_characters <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text_data<span class="token punctuation">)</span>total_tokens <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_ratio <span class="token operator">=</span> <span class="token number">0.90</span>split_idx <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>train_ratio <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text_data<span class="token punctuation">)</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> text_data<span class="token punctuation">[</span><span class="token punctuation">:</span>split_idx<span class="token punctuation">]</span>val_data <span class="token operator">=</span> text_data<span class="token punctuation">[</span>split_idx<span class="token punctuation">:</span><span class="token punctuation">]</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> create_dataloader_v1<span class="token punctuation">(</span>    train_data<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    stride<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> create_dataloader_v1<span class="token punctuation">(</span>    val_data<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    max_length<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    stride<span class="token operator">=</span>GPT_CONFIG_124M<span class="token punctuation">[</span><span class="token string">"context_length"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Train loader:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nValidation loader:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> val_loader<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">    Train loader:    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])    torch.Size([2, 256]) torch.Size([2, 256])        Validation loader:    torch.Size([2, 256]) torch.Size([2, 256])    ```   ### 预训练```pythontorch.manual_seed(123)model = GPTModel(GPT_CONFIG_124M)# model.eval()device = torch.device("cuda" if torch.cuda.is_available() else "cpu")model.to(device)with torch.no_grad():    train_loss = calc_loss_loader(train_loader, model, device)    val_loss = calc_loss_loader(val_loader, model, device)    print("Training loss:", train_loss)print("Validation loss:", val_loss)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Training loss: 10.995166460673014Validation loss: 10.99630355834961</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>    model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    lr<span class="token operator">=</span><span class="token number">0.0004</span><span class="token punctuation">,</span>    weight_decay<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>num_epochs <span class="token operator">=</span> <span class="token number">10</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> tokens_seen <span class="token operator">=</span> train_model_simple<span class="token punctuation">(</span>    model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span>    num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_freq<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> eval_iter<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>    start_context<span class="token operator">=</span><span class="token string">"Every effort moves you"</span><span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">Ep 1 (Step 000000): Train loss 9.973, Val loss 9.913    Ep 1 (Step 000005): Train loss 8.197, Val loss 8.290    Every effort moves you                                                      Ep 2 (Step 000010): Train loss 6.802, Val loss 7.059    Ep 2 (Step 000015): Train loss 6.140, Val loss 6.640    Every effort moves you, the, the, the, the, the, the.                                         Ep 3 (Step 000020): Train loss 5.688, Val loss 6.512    Ep 3 (Step 000025): Train loss 5.370, Val loss 6.407    Every effort moves you.                                                     Ep 4 (Step 000030): Train loss 4.856, Val loss 6.393    Ep 4 (Step 000035): Train loss 4.330, Val loss 6.221    Every effort moves you know the, and my the fact--I had the fact of the fact--his, and I had been the fact--I had been, and, and I had been, and--his, and Mrs.           Ep 5 (Step 000040): Train loss 3.943, Val loss 6.078    Every effort moves you know," was one of the ax.                                              Ep 6 (Step 000045): Train loss 3.061, Val loss 6.133    Ep 6 (Step 000050): Train loss 2.863, Val loss 6.081    Every effort moves you know," was not that the axioms he was not the the Sevres and silver of an exquisburn, I had to see a smile, and I looked at the donkey again.               Ep 7 (Step 000055): Train loss 2.209, Val loss 6.160    Ep 7 (Step 000060): Train loss 1.692, Val loss 6.160    Every effort moves you know," was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his painting.                    Ep 8 (Step 000065): Train loss 1.277, Val loss 6.224    Ep 8 (Step 000070): Train loss 0.978, Val loss 6.216    Every effort moves you?"  "Yes--quite insensible to the fact with the Sevres and silver of an exquisburn's an unusual degree to the display of his close grayish beard--as if he had the donkey. "There were days when I    Ep 9 (Step 000075): Train loss 0.666, Val loss 6.302    Ep 9 (Step 000080): Train loss 0.533, Val loss 6.382    Every effort moves you?"  "Yes--quite insensible to the fact with a laugh: "Yes--and by me!"  "Oh, and Mrs. Stroud. She, one might put it, the donkey. "strongest," as his    Ep 10 (Step 000085): Train loss 0.347, Val loss 6.424    Every effort moves you?"  "Yes--quite insensible to the irony. She wanted him vindicated--and by me!"  He laughed again, and threw back his head to look up at the sketch of the donkey. "There were days when I```           ### matplotlib```pythonimport matplotlib.pyplot as plt from matplotlib.ticker import MaxNLocatordef plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):    fig, axl = plt.subplots(figsize=(5,3))    axl.plot(epochs_seen, train_losses, label="Training loss")    axl.plot(        epochs_seen, val_losses, linestyle="-.", label="Validation loss"    )    axl.set_xlabel("Epochs")    axl.set_ylabel("Loss")    axl.legend(loc="upper right")    axl.xaxis.set_major_locator(MaxNLocator(integer=True))    ax2 = axl.twiny()    ax2.plot(tokens_seen, train_losses, alpha=0)    ax2.set_xlabel("Tokens seen")    fig.tight_layout()    plt.show()    epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAdIPYV"><img src="https://s21.ax1x.com/2024/10/23/pAdIPYV.png" alt="pAdIPYV.png"></a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>alphafold2_install</title>
      <link href="2024/10/18/alphafold2-install/"/>
      <url>2024/10/18/alphafold2-install/</url>
      
        <content type="html"><![CDATA[<p>原始的AlphaFold2需要docker环境，目前我们服务器还没有配置docker，就先用conda环境替代吧。</p><h2 id="1-软件下载"><a href="#1-软件下载" class="headerlink" title="1.软件下载"></a>1.软件下载</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;kalininalab&#x2F;alphafold_non_docker.gitwget https:&#x2F;&#x2F;github.com&#x2F;google-deepmind&#x2F;alphafold&#x2F;archive&#x2F;refs&#x2F;tags&#x2F;v2.3.2.tar.gztar -zxvf v2.3.2.tar.gz# 环境配置建议参考alphafold_non_docker里的README.md，特别注意CUDA版本相关的包conda create -n alphafold2conda activate alphafold2conda install -y -c conda-forge openmm&#x3D;8.0.0 pdbfixer python&#x3D;3.10 -c conda-forgeconda install nvidia&#x2F;label&#x2F;cuda-12.4.0::cuda-toolkit conda install cudnn&#x3D;8.9.2.26&#x3D;cuda12_0 -c nvidiaconda install -y -c bioconda hmmer hhsuite&#x3D;&#x3D;3.3.0 kalign2 cudnn&#x3D;8.9pip install absl-py&#x3D;&#x3D;1.0.0 biopython&#x3D;&#x3D;1.79 chex&#x3D;&#x3D;0.0.7 dm-haiku&#x3D;&#x3D;0.0.13 dm-tree&#x3D;&#x3D;0.1.6 immutabledict&#x3D;&#x3D;2.0.0 ml-collections&#x3D;&#x3D;0.1.0 numpy&#x3D;&#x3D;1.22 pandas&#x3D;&#x3D;1.3.4 protobuf&#x3D;&#x3D;3.20.1 scipy&#x3D;&#x3D;1.11.4 tensorflow-cpu&#x3D;&#x3D;2.9.0pip3 install --upgrade --no-cache-dir jax&#x3D;&#x3D;0.4.23 jaxlib&#x3D;&#x3D;0.4.23+cuda12.cudnn89 -f https:&#x2F;&#x2F;storage.googleapis.com&#x2F;jax-releases&#x2F;jax_cuda_releases.html# 下载依赖数据库(非常大)bash alphafold_non_docker&#x2F;download_db.sh -d database<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装的时候非常混乱，这里给出我的环境，基于<code>CUDA12.4</code>, 可以直接通过<code>conda</code>安装：<br><code>conda env create -f alphafold2.yml</code></p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>alphafold2.yml(CUDA12.4)</span></div><code class="language-shell">name: alphafold2channels:  - bioconda  - nvidia  - nvidia&#x2F;label&#x2F;cuda-12.4.0  - conda-forge  - defaultsdependencies:  - _libgcc_mutex&#x3D;0.1&#x3D;conda_forge  - _openmp_mutex&#x3D;4.5&#x3D;2_gnu  - bzip2&#x3D;1.0.8&#x3D;h4bc722e_7  - ca-certificates&#x3D;2024.9.24&#x3D;h06a4308_0  - cuda-cccl&#x3D;12.4.99&#x3D;0  - cuda-command-line-tools&#x3D;12.4.0&#x3D;0  - cuda-compiler&#x3D;12.4.0&#x3D;0  - cuda-cudart&#x3D;12.4.99&#x3D;0  - cuda-cudart-dev&#x3D;12.4.99&#x3D;0  - cuda-cudart-static&#x3D;12.4.99&#x3D;0  - cuda-cuobjdump&#x3D;12.4.99&#x3D;0  - cuda-cupti&#x3D;12.4.99&#x3D;0  - cuda-cupti-static&#x3D;12.4.99&#x3D;0  - cuda-cuxxfilt&#x3D;12.4.99&#x3D;0  - cuda-documentation&#x3D;12.4.99&#x3D;0  - cuda-driver-dev&#x3D;12.4.99&#x3D;0  - cuda-gdb&#x3D;12.4.99&#x3D;0  - cuda-libraries&#x3D;12.4.0&#x3D;0  - cuda-libraries-dev&#x3D;12.4.0&#x3D;0  - cuda-libraries-static&#x3D;12.4.0&#x3D;0  - cuda-nsight&#x3D;12.4.99&#x3D;0  - cuda-nsight-compute&#x3D;12.4.0&#x3D;0  - cuda-nvcc&#x3D;12.4.99&#x3D;0  - cuda-nvdisasm&#x3D;12.4.99&#x3D;0  - cuda-nvml-dev&#x3D;12.4.99&#x3D;0  - cuda-nvprof&#x3D;12.4.99&#x3D;0  - cuda-nvprune&#x3D;12.4.99&#x3D;0  - cuda-nvrtc&#x3D;12.4.99&#x3D;0  - cuda-nvrtc-dev&#x3D;12.4.99&#x3D;0  - cuda-nvrtc-static&#x3D;12.4.99&#x3D;0  - cuda-nvtx&#x3D;12.4.99&#x3D;0  - cuda-nvvp&#x3D;12.4.99&#x3D;0  - cuda-opencl&#x3D;12.4.99&#x3D;0  - cuda-opencl-dev&#x3D;12.4.99&#x3D;0  - cuda-profiler-api&#x3D;12.4.99&#x3D;0  - cuda-sanitizer-api&#x3D;12.4.99&#x3D;0  - cuda-toolkit&#x3D;12.4.0&#x3D;0  - cuda-tools&#x3D;12.4.0&#x3D;0  - cuda-version&#x3D;12.6&#x3D;3  - cuda-visual-tools&#x3D;12.4.0&#x3D;0  - cudnn&#x3D;8.9.2.26&#x3D;cuda12_0  - gds-tools&#x3D;1.9.0.20&#x3D;0  - hhsuite&#x3D;3.3.0&#x3D;py310pl5321hc31ed2c_13  - hmmer&#x3D;3.4&#x3D;hdbdd923_2  - kalign2&#x3D;2.04&#x3D;h031d066_7  - ld_impl_linux-64&#x3D;2.43&#x3D;h712a8e2_1  - libblas&#x3D;3.9.0&#x3D;24_linux64_openblas  - libcblas&#x3D;3.9.0&#x3D;24_linux64_openblas  - libcublas&#x3D;12.4.2.65&#x3D;0  - libcublas-dev&#x3D;12.4.2.65&#x3D;0  - libcublas-static&#x3D;12.4.2.65&#x3D;0  - libcufft&#x3D;11.2.0.44&#x3D;0  - libcufft-dev&#x3D;11.2.0.44&#x3D;0  - libcufft-static&#x3D;11.2.0.44&#x3D;0  - libcufile&#x3D;1.9.0.20&#x3D;0  - libcufile-dev&#x3D;1.9.0.20&#x3D;0  - libcufile-static&#x3D;1.9.0.20&#x3D;0  - libcurand&#x3D;10.3.5.119&#x3D;0  - libcurand-dev&#x3D;10.3.5.119&#x3D;0  - libcurand-static&#x3D;10.3.5.119&#x3D;0  - libcusolver&#x3D;11.6.0.99&#x3D;0  - libcusolver-dev&#x3D;11.6.0.99&#x3D;0  - libcusolver-static&#x3D;11.6.0.99&#x3D;0  - libcusparse&#x3D;12.3.0.142&#x3D;0  - libcusparse-dev&#x3D;12.3.0.142&#x3D;0  - libcusparse-static&#x3D;12.3.0.142&#x3D;0  - libffi&#x3D;3.4.2&#x3D;h7f98852_5  - libgcc&#x3D;14.2.0&#x3D;h77fa898_1  - libgcc-ng&#x3D;14.2.0&#x3D;h69a702a_1  - libgfortran&#x3D;14.2.0&#x3D;h69a702a_1  - libgfortran-ng&#x3D;14.2.0&#x3D;h69a702a_1  - libgfortran5&#x3D;14.2.0&#x3D;hd5240d6_1  - libgomp&#x3D;14.2.0&#x3D;h77fa898_1  - liblapack&#x3D;3.9.0&#x3D;24_linux64_openblas  - libnpp&#x3D;12.2.5.2&#x3D;0  - libnpp-dev&#x3D;12.2.5.2&#x3D;0  - libnpp-static&#x3D;12.2.5.2&#x3D;0  - libnsl&#x3D;2.0.1&#x3D;hd590300_0  - libnvfatbin&#x3D;12.4.99&#x3D;0  - libnvfatbin-dev&#x3D;12.4.99&#x3D;0  - libnvjitlink&#x3D;12.4.99&#x3D;0  - libnvjitlink-dev&#x3D;12.4.99&#x3D;0  - libnvjpeg&#x3D;12.3.1.89&#x3D;0  - libnvjpeg-dev&#x3D;12.3.1.89&#x3D;0  - libnvjpeg-static&#x3D;12.3.1.89&#x3D;0  - libopenblas&#x3D;0.3.27&#x3D;pthreads_hac2b453_1  - libsqlite&#x3D;3.46.1&#x3D;hadc24fc_0  - libstdcxx&#x3D;14.2.0&#x3D;hc0a3c3a_1  - libstdcxx-ng&#x3D;14.2.0&#x3D;h4852527_1  - libuuid&#x3D;2.38.1&#x3D;h0b41bf4_0  - libxcrypt&#x3D;4.4.36&#x3D;hd590300_1  - libzlib&#x3D;1.3.1&#x3D;hb9d3cd8_2  - ncurses&#x3D;6.5&#x3D;he02047a_1  - nsight-compute&#x3D;2024.1.0.13&#x3D;0  - ocl-icd&#x3D;2.3.2&#x3D;hd590300_1  - ocl-icd-system&#x3D;1.0.0&#x3D;1  - openmm&#x3D;8.0.0&#x3D;py310h9995159_4  - openssl&#x3D;3.3.2&#x3D;hb9d3cd8_0  - pdbfixer&#x3D;1.9&#x3D;pyh1a96a4e_0  - perl&#x3D;5.32.1&#x3D;0_h5eee18b_perl5  - pip&#x3D;24.2&#x3D;pyh8b19718_1  - python&#x3D;3.10.15&#x3D;h4a871b0_2_cpython  - python_abi&#x3D;3.10&#x3D;5_cp310  - readline&#x3D;8.2&#x3D;h8228510_1  - setuptools&#x3D;75.1.0&#x3D;pyhd8ed1ab_0  - tk&#x3D;8.6.13&#x3D;noxft_h4845f30_101  - tzdata&#x3D;2024b&#x3D;hc8b5060_0  - wheel&#x3D;0.44.0&#x3D;pyhd8ed1ab_0  - xz&#x3D;5.2.6&#x3D;h166bdaf_0  - pip:      - absl-py&#x3D;&#x3D;1.0.0      - astunparse&#x3D;&#x3D;1.6.3      - biopython&#x3D;&#x3D;1.79      - cachetools&#x3D;&#x3D;5.5.0      - certifi&#x3D;&#x3D;2024.8.30      - charset-normalizer&#x3D;&#x3D;3.4.0      - chex&#x3D;&#x3D;0.0.7      - contextlib2&#x3D;&#x3D;21.6.0      - dm-haiku&#x3D;&#x3D;0.0.13      - dm-tree&#x3D;&#x3D;0.1.6      - flatbuffers&#x3D;&#x3D;1.12      - gast&#x3D;&#x3D;0.4.0      - google-auth&#x3D;&#x3D;2.35.0      - google-auth-oauthlib&#x3D;&#x3D;0.4.6      - google-pasta&#x3D;&#x3D;0.2.0      - grpcio&#x3D;&#x3D;1.67.0      - h5py&#x3D;&#x3D;3.12.1      - idna&#x3D;&#x3D;3.10      - immutabledict&#x3D;&#x3D;2.0.0      - jax&#x3D;&#x3D;0.4.23      - jaxlib&#x3D;&#x3D;0.4.23+cuda12.cudnn89      - jmp&#x3D;&#x3D;0.0.4      - keras&#x3D;&#x3D;2.9.0      - keras-preprocessing&#x3D;&#x3D;1.1.2      - libclang&#x3D;&#x3D;18.1.1      - markdown&#x3D;&#x3D;3.7      - markupsafe&#x3D;&#x3D;3.0.1      - ml-collections&#x3D;&#x3D;0.1.0      - ml-dtypes&#x3D;&#x3D;0.5.0      - numpy&#x3D;&#x3D;1.22.0      - oauthlib&#x3D;&#x3D;3.2.2      - opt-einsum&#x3D;&#x3D;3.4.0      - packaging&#x3D;&#x3D;24.1      - pandas&#x3D;&#x3D;1.3.4      - protobuf&#x3D;&#x3D;3.20.1      - pyasn1&#x3D;&#x3D;0.6.1      - pyasn1-modules&#x3D;&#x3D;0.4.1      - python-dateutil&#x3D;&#x3D;2.9.0.post0      - pytz&#x3D;&#x3D;2024.2      - pyyaml&#x3D;&#x3D;6.0.2      - requests&#x3D;&#x3D;2.32.3      - requests-oauthlib&#x3D;&#x3D;2.0.0      - rsa&#x3D;&#x3D;4.9      - scipy&#x3D;&#x3D;1.11.4      - six&#x3D;&#x3D;1.16.0      - tabulate&#x3D;&#x3D;0.9.0      - tensorboard&#x3D;&#x3D;2.9.0      - tensorboard-data-server&#x3D;&#x3D;0.6.1      - tensorboard-plugin-wit&#x3D;&#x3D;1.8.1      - tensorflow-cpu&#x3D;&#x3D;2.9.0      - tensorflow-estimator&#x3D;&#x3D;2.9.0      - tensorflow-io-gcs-filesystem&#x3D;&#x3D;0.37.1      - termcolor&#x3D;&#x3D;2.5.0      - toolz&#x3D;&#x3D;1.0.0      - typing-extensions&#x3D;&#x3D;4.12.2      - urllib3&#x3D;&#x3D;2.2.3      - werkzeug&#x3D;&#x3D;3.0.4      - wrapt&#x3D;&#x3D;1.16.0prefix: &#x2F;data&#x2F;chaofan&#x2F;miniconda3&#x2F;envs&#x2F;alphafold2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个是我之前基于<code>CUDA11.6</code>的环境：</p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>alphafold2.yml(CUDA11.6)</span></div><code class="language-shell">name: alphafold2channels:  - nvidia  - conda-forge  - bioconda  - defaultsdependencies:  - _libgcc_mutex&#x3D;0.1&#x3D;main  - _openmp_mutex&#x3D;5.1&#x3D;1_gnu  - blas&#x3D;1.0&#x3D;mkl  - ca-certificates&#x3D;2023.7.22&#x3D;hbcca054_0  - cuda-nvcc&#x3D;11.6.124&#x3D;hbba6d2d_0  - cudatoolkit&#x3D;11.2.2&#x3D;hbe64b41_10  - fftw&#x3D;3.3.9&#x3D;h27cfd23_1  - hhsuite&#x3D;3.3.0&#x3D;py38pl5321h8ded8fe_5  - hmmer&#x3D;3.3.2&#x3D;h87f3376_2  - intel-openmp&#x3D;2021.4.0&#x3D;h06a4308_3561  - kalign2&#x3D;2.04&#x3D;hec16e2b_3  - libedit&#x3D;3.1.20221030&#x3D;h5eee18b_0  - libffi&#x3D;3.2.1&#x3D;hf484d3e_1007  - libgcc-ng&#x3D;11.2.0&#x3D;h1234567_1  - libgomp&#x3D;11.2.0&#x3D;h1234567_1  - libnsl&#x3D;2.0.0&#x3D;h5eee18b_0  - libstdcxx-ng&#x3D;11.2.0&#x3D;h1234567_1  - mkl&#x3D;2021.4.0&#x3D;h06a4308_640  - mkl-service&#x3D;2.4.0&#x3D;py38h7f8727e_0  - mkl_fft&#x3D;1.3.1&#x3D;py38hd3c417c_0  - mkl_random&#x3D;1.2.2&#x3D;py38h51133e4_0  - ncurses&#x3D;6.4&#x3D;h6a678d5_0  - numpy-base&#x3D;1.24.3&#x3D;py38h31eccc5_0  - ocl-icd&#x3D;2.3.1&#x3D;h7f98852_0  - ocl-icd-system&#x3D;1.0.0&#x3D;1  - openmm&#x3D;7.5.1&#x3D;py38ha082873_1  - openssl&#x3D;1.1.1l&#x3D;h7f98852_0  - parallel&#x3D;20230922&#x3D;ha770c72_0  - pdbfixer&#x3D;1.7&#x3D;pyhd3deb0d_0  - perl&#x3D;5.32.1&#x3D;0_h5eee18b_perl5  - pip&#x3D;23.2.1&#x3D;py38h06a4308_0  - python&#x3D;3.8.0&#x3D;h0371630_2  - python_abi&#x3D;3.8&#x3D;2_cp38  - readline&#x3D;7.0&#x3D;h7b6447c_5  - setuptools&#x3D;68.0.0&#x3D;py38h06a4308_0  - six&#x3D;1.16.0&#x3D;pyhd3eb1b0_1  - sqlite&#x3D;3.33.0&#x3D;h62c20be_0  - tk&#x3D;8.6.12&#x3D;h1ccaba5_0  - wheel&#x3D;0.41.2&#x3D;py38h06a4308_0  - xz&#x3D;5.4.2&#x3D;h5eee18b_0  - zlib&#x3D;1.2.13&#x3D;h5eee18b_0  - pip:      - absl-py&#x3D;&#x3D;1.0.0      - alphapulldown&#x3D;&#x3D;0.30.7      - anyio&#x3D;&#x3D;4.0.0      - appdirs&#x3D;&#x3D;1.4.4      - argon2-cffi&#x3D;&#x3D;23.1.0      - argon2-cffi-bindings&#x3D;&#x3D;21.2.0      - arrow&#x3D;&#x3D;1.3.0      - asttokens&#x3D;&#x3D;2.4.0      - astunparse&#x3D;&#x3D;1.6.3      - async-lru&#x3D;&#x3D;2.0.4      - attrs&#x3D;&#x3D;23.1.0      - babel&#x3D;&#x3D;2.13.0      - backcall&#x3D;&#x3D;0.2.0      - beautifulsoup4&#x3D;&#x3D;4.12.2      - biopython&#x3D;&#x3D;1.78      - bleach&#x3D;&#x3D;6.1.0      - cachetools&#x3D;&#x3D;5.3.1      - certifi&#x3D;&#x3D;2023.7.22      - cffi&#x3D;&#x3D;1.16.0      - charset-normalizer&#x3D;&#x3D;3.3.0      - chex&#x3D;&#x3D;0.0.7      - comm&#x3D;&#x3D;0.1.4      - contextlib2&#x3D;&#x3D;21.6.0      - cycler&#x3D;&#x3D;0.12.1      - debugpy&#x3D;&#x3D;1.8.0      - decorator&#x3D;&#x3D;5.1.1      - defusedxml&#x3D;&#x3D;0.7.1      - dm-haiku&#x3D;&#x3D;0.0.9      - dm-tree&#x3D;&#x3D;0.1.6      - exceptiongroup&#x3D;&#x3D;1.1.3      - executing&#x3D;&#x3D;2.0.0      - fastjsonschema&#x3D;&#x3D;2.18.1      - flatbuffers&#x3D;&#x3D;1.12      - fqdn&#x3D;&#x3D;1.5.1      - gast&#x3D;&#x3D;0.4.0      - google-auth&#x3D;&#x3D;2.23.2      - google-auth-oauthlib&#x3D;&#x3D;0.4.6      - google-pasta&#x3D;&#x3D;0.2.0      - grpcio&#x3D;&#x3D;1.59.0      - h5py&#x3D;&#x3D;3.1.0      - idna&#x3D;&#x3D;3.4      - immutabledict&#x3D;&#x3D;2.0.0      - importlib-metadata&#x3D;&#x3D;6.8.0      - importlib-resources&#x3D;&#x3D;5.8.0      - ipykernel&#x3D;&#x3D;6.25.2      - ipython&#x3D;&#x3D;8.12.3      - ipywidgets&#x3D;&#x3D;8.1.1      - isoduration&#x3D;&#x3D;20.11.0      - jax&#x3D;&#x3D;0.3.25      - jaxlib&#x3D;&#x3D;0.3.25+cuda11.cudnn805      - jedi&#x3D;&#x3D;0.19.1      - jinja2&#x3D;&#x3D;3.1.2      - jmp&#x3D;&#x3D;0.0.4      - json5&#x3D;&#x3D;0.9.14      - jsonpointer&#x3D;&#x3D;2.4      - jsonschema&#x3D;&#x3D;4.19.1      - jsonschema-specifications&#x3D;&#x3D;2023.7.1      - jupyter-client&#x3D;&#x3D;8.4.0      - jupyter-core&#x3D;&#x3D;5.4.0      - jupyter-events&#x3D;&#x3D;0.7.0      - jupyter-lsp&#x3D;&#x3D;2.2.0      - jupyter-server&#x3D;&#x3D;2.7.3      - jupyter-server-terminals&#x3D;&#x3D;0.4.4      - jupyterlab&#x3D;&#x3D;4.0.7      - jupyterlab-pygments&#x3D;&#x3D;0.2.2      - jupyterlab-server&#x3D;&#x3D;2.25.0      - jupyterlab-widgets&#x3D;&#x3D;3.0.9      - keras&#x3D;&#x3D;2.9.0      - keras-preprocessing&#x3D;&#x3D;1.1.2      - kiwisolver&#x3D;&#x3D;1.4.5      - libclang&#x3D;&#x3D;16.0.6      - markdown&#x3D;&#x3D;3.4.4      - markupsafe&#x3D;&#x3D;2.1.3      - matplotlib&#x3D;&#x3D;3.3.3      - matplotlib-inline&#x3D;&#x3D;0.1.6      - mistune&#x3D;&#x3D;2.0.5      - ml-collections&#x3D;&#x3D;0.1.0      - ml-dtypes&#x3D;&#x3D;0.2.0      - nbclient&#x3D;&#x3D;0.8.0      - nbconvert&#x3D;&#x3D;7.4.0      - nbformat&#x3D;&#x3D;5.4.0      - nest-asyncio&#x3D;&#x3D;1.5.8      - notebook-shim&#x3D;&#x3D;0.2.3      - numpy&#x3D;&#x3D;1.21.6      - oauthlib&#x3D;&#x3D;3.2.2      - opt-einsum&#x3D;&#x3D;3.3.0      - overrides&#x3D;&#x3D;7.4.0      - packaging&#x3D;&#x3D;23.2      - pandas&#x3D;&#x3D;1.3.4      - pandocfilters&#x3D;&#x3D;1.5.0      - parso&#x3D;&#x3D;0.8.3      - pexpect&#x3D;&#x3D;4.8.0      - pickleshare&#x3D;&#x3D;0.7.5      - pillow&#x3D;&#x3D;10.0.1      - pkgutil-resolve-name&#x3D;&#x3D;1.3.10      - platformdirs&#x3D;&#x3D;3.11.0      - prometheus-client&#x3D;&#x3D;0.17.1      - prompt-toolkit&#x3D;&#x3D;3.0.39      - protobuf&#x3D;&#x3D;3.20.1      - psutil&#x3D;&#x3D;5.9.5      - ptyprocess&#x3D;&#x3D;0.7.0      - pure-eval&#x3D;&#x3D;0.2.2      - py3dmol&#x3D;&#x3D;2.0.1      - pyasn1&#x3D;&#x3D;0.5.0      - pyasn1-modules&#x3D;&#x3D;0.3.0      - pycparser&#x3D;&#x3D;2.21      - pygments&#x3D;&#x3D;2.16.1      - pyparsing&#x3D;&#x3D;3.1.1      - python-dateutil&#x3D;&#x3D;2.8.2      - python-json-logger&#x3D;&#x3D;2.0.7      - pytz&#x3D;&#x3D;2023.3.post1      - pyyaml&#x3D;&#x3D;6.0.1      - pyzmq&#x3D;&#x3D;25.1.1      - referencing&#x3D;&#x3D;0.30.2      - requests&#x3D;&#x3D;2.31.0      - requests-oauthlib&#x3D;&#x3D;1.3.1      - rfc3339-validator&#x3D;&#x3D;0.1.4      - rfc3986-validator&#x3D;&#x3D;0.1.1      - rpds-py&#x3D;&#x3D;0.10.6      - rsa&#x3D;&#x3D;4.9      - scipy&#x3D;&#x3D;1.7.0      - send2trash&#x3D;&#x3D;1.8.2      - sniffio&#x3D;&#x3D;1.3.0      - soupsieve&#x3D;&#x3D;2.5      - stack-data&#x3D;&#x3D;0.6.3      - tabulate&#x3D;&#x3D;0.9.0      - tensorboard&#x3D;&#x3D;2.9.0      - tensorboard-data-server&#x3D;&#x3D;0.6.1      - tensorboard-plugin-wit&#x3D;&#x3D;1.8.1      - tensorflow&#x3D;&#x3D;2.9.0      - tensorflow-cpu&#x3D;&#x3D;2.9.0      - tensorflow-estimator&#x3D;&#x3D;2.9.0      - tensorflow-io-gcs-filesystem&#x3D;&#x3D;0.34.0      - termcolor&#x3D;&#x3D;2.3.0      - terminado&#x3D;&#x3D;0.17.1      - tinycss2&#x3D;&#x3D;1.2.1      - tomli&#x3D;&#x3D;2.0.1      - toolz&#x3D;&#x3D;0.12.0      - tornado&#x3D;&#x3D;6.3.3      - tqdm&#x3D;&#x3D;4.66.1      - traitlets&#x3D;&#x3D;5.11.2      - types-python-dateutil&#x3D;&#x3D;2.8.19.14      - typing-extensions&#x3D;&#x3D;4.8.0      - uri-template&#x3D;&#x3D;1.3.0      - urllib3&#x3D;&#x3D;2.0.6      - wcwidth&#x3D;&#x3D;0.2.8      - webcolors&#x3D;&#x3D;1.13      - webencodings&#x3D;&#x3D;0.5.1      - websocket-client&#x3D;&#x3D;1.6.4      - werkzeug&#x3D;&#x3D;3.0.0      - widgetsnbextension&#x3D;&#x3D;4.0.9      - wrapt&#x3D;&#x3D;1.15.0      - zipp&#x3D;&#x3D;3.17.0prefix: &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;miniconda3&#x2F;envs&#x2F;alphafold2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-测试"><a href="#2-测试" class="headerlink" title="2.测试"></a>2.测试</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">scp alphafold_non_docker&#x2F;run_alphafold.sh alphafold-2.3.2&#x2F;# 修改下相关文件地址vi alphafold-2.3.2&#x2F;run_alphafold.sh# bash alphafold-2.3.2&#x2F;run_alphafold.sh -c reduced_dbs -d .&#x2F;database&#x2F; -o .&#x2F;dummy_test&#x2F; -f t2.fa -t 2024-10-17 -m multimer -l 1 -n 40<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>t2.fa</span></div><code class="language-txt">>Pip1VTEVPNSMDWRKRGSVTGVKDQGVCGCCWAFSAAAAIEGAYQIANNELISLSEQQLLDCSTQNKGCEGGLMTVAYDFLLQNNGGGITTETNYPYEEAQNVCKTEQPAAVTINGYEVVPSDESSLLKAVVNQPISVGIAANDEFHMYGSGIYDGSCNSRLNHAVTVIGYGTSEEDGTKYWIVKNSWGSDWGEEGYMRIARDVGVDGGHCGIAKVASFPTA>EpiC2BQLNGYSKKEVTPEDTELLQKAQSNVSAYNSDVTSRICYLKVDSLETQVVSGENYKFHVSGCSVNSDKELGGCANQNCESSKYDIVIYSQSWTNTLKVTSITPAN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>结果与我们之前在<code>CUDA11.6</code>版本上的一致，也与原文章结果一致。</p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>result</span></div><code class="language-shell">&#123;    &quot;iptm+ptm&quot;: &#123;        &quot;model_1_multimer_v3_pred_0&quot;: 0.913495827158252,        &quot;model_2_multimer_v3_pred_0&quot;: 0.9082750066457126,        &quot;model_3_multimer_v3_pred_0&quot;: 0.9185924126209433,        &quot;model_4_multimer_v3_pred_0&quot;: 0.9199507589621323,        &quot;model_5_multimer_v3_pred_0&quot;: 0.9214059557649581    &#125;,    &quot;order&quot;: [        &quot;model_5_multimer_v3_pred_0&quot;,        &quot;model_4_multimer_v3_pred_0&quot;,        &quot;model_3_multimer_v3_pred_0&quot;,        &quot;model_1_multimer_v3_pred_0&quot;,        &quot;model_2_multimer_v3_pred_0&quot;    ]&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-安装过程中遇到的问题"><a href="#3-安装过程中遇到的问题" class="headerlink" title="3.安装过程中遇到的问题"></a>3.安装过程中遇到的问题</h2><p>1.</p><blockquote><p>Warning: importing ‘simtk.openmm’ is deprecated.  Import ‘openmm’ instead.<br>Traceback (most recent call last):<br>  File “/data/chaofan/software/alphafold2/alphafold-2.3.2/run_alphafold.py”, line 40, in <module><br>    from alphafold.relax import relax<br>  File “/data/chaofan/software/alphafold2/alphafold-2.3.2/alphafold/relax/relax.py”, line 18, in <module><br>    from alphafold.relax import amber_minimize<br>  File “/data/chaofan/software/alphafold2/alphafold-2.3.2/alphafold/relax/amber_minimize.py”, line 33, in <module><br>    from simtk.openmm.app.internal.pdbstructure import PdbStructure<br>ModuleNotFoundError: No module named ‘simtk.openmm.app.internal’   </p></blockquote><blockquote><p><a href="https://github.com/google-deepmind/alphafold/issues/410">https://github.com/google-deepmind/alphafold/issues/410</a>  </p></blockquote><p>2.</p><blockquote><p>Warning: importing ‘simtk.openmm’ is deprecated.  Import ‘openmm’ instead.<br>FATAL Flags parsing error: Unknown command line flag ‘run_relax’<br>Pass –helpshort or –helpfull to see help on flags.  </p></blockquote><blockquote><p>删掉<code>run_alphafold.sh</code>文件中的<code>--run_relax=$run_relax</code></p></blockquote><p>3.</p><blockquote><p>AttributeError: module ‘jax’ has no attribute ‘xla’  </p></blockquote><blockquote><p>pip install dm-haiku -U</p></blockquote><p>还有一种安装方法，自行配置CUDA驱动，参考<code>非root用户安装cuda与cudnn</code>,可以装个和<code>alphafold_non_docker</code>一样的CUDA的版本，配置conda启动时自动替换一些环境变量，可能就没那么麻烦了，这里只提供一种可能的方式，我没有试过。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>slurm单机部署</title>
      <link href="2024/10/10/slurm-dan-ji-bu-shu/"/>
      <url>2024/10/10/slurm-dan-ji-bu-shu/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近课题组新到了一台8卡GPU服务器，为了更有效的利用计算资源，准备安装一个slurm任务提交系统。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cat &#x2F;etc&#x2F;os-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>NAME=”CentOS Linux”<br>VERSION=”8”<br>ID=”centos”<br>ID_LIKE=”rhel fedora”<br>VERSION_ID=”8”<br>PLATFORM_ID=”platform:el8”<br>PRETTY_NAME=”CentOS Linux 8”<br>ANSI_COLOR=”0;31”<br>CPE_NAME=”cpe:/o:centos:centos:8”<br>HOME_URL=”<a href="https://centos.org/&quot;">https://centos.org/&quot;</a><br>BUG_REPORT_URL=”<a href="https://bugs.centos.org/&quot;">https://bugs.centos.org/&quot;</a><br>CENTOS_MANTISBT_PROJECT=”CentOS-8”<br>CENTOS_MANTISBT_PROJECT_VERSION=”8”  </p></blockquote><h3 id="1-换清华源-非必要"><a href="#1-换清华源-非必要" class="headerlink" title="1.换清华源(非必要)"></a>1.换清华源(非必要)</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#sudo cp &#x2F;etc&#x2F;apt&#x2F;sources.list &#x2F;etc&#x2F;apt&#x2F;sources.list.bakrm &#x2F;etc&#x2F;apt&#x2F;sources.listcat &gt;&gt; &#x2F;etc&#x2F;apt&#x2F;sources.list &lt;&lt; &quot;EOF&quot;#添加清华源deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-updates main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-backports main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-backports main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; focal-security main restricted universe multiverseEOF# 更新配置文件sudo apt-get updatesudo apt-get upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-安装slurm"><a href="#2-安装slurm" class="headerlink" title="2.安装slurm"></a>2.安装slurm</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 下载 slurm_install.sh 网络问题，我直接从github上粘贴过去的wget --no-check-certificate https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;NISP-GmbH&#x2F;SLURM&#x2F;main&#x2F;slurm_install.shexport VER&#x3D;23.02.0# line 1239: bc: command not foundsudo apt-get install bcbash slurm_install.sh# Do you want to enable Slurm accounting support? Possible answers: [yes&#x2F;no] &lt;- no# yes 要配置DB# 按要求修改配置文件vi &#x2F;etc&#x2F;slurm&#x2F;slurm.conf# 设置CPU数量和内存# 详细信息可以通过 systemctl status slurmd 得到，有冲突他会提示# 直接填提示的就行NodeName&#x3D;citrus CPUs&#x3D;256 RealMemory&#x3D;1031612 CoresPerSocket&#x3D;64 SocketsPerBoard&#x3D;2 ThreadsPerCore&#x3D;2 State&#x3D;idle Feature&#x3D;dcv2,other# 更新配置文件sudo systemctl restart slurmctldsudo systemctl restart slurmd# 检查服务运行状态sudo systemctl status slurmctldsudo systemctl status slurmd# 查看slurm 系统配置sinfo -o &quot;%P %D %c %m %C&quot;# 设置开机自启动sudo systemctl enable slurmctld # 守护进程sudo systemctl enable slurmdsudo systemctl enable munge # 一个用于安全认证的守护进程# sudo systemctl enable slurmdbd 没有装DB 不需要<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-GPU配置"><a href="#3-GPU配置" class="headerlink" title="3.GPU配置"></a>3.GPU配置</h3><p>&emsp;&emsp;我们服务器有8张GPUs，现在配置下GPU的设置，让slurm能正确识别GPUs。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># vi &#x2F;etc&#x2F;slurm&#x2F;slurm.conf&quot;GresTypes&#x3D;gpuNodeName&#x3D;citrus CPUs&#x3D;256 Gres&#x3D;gpu:8 RealMemory&#x3D;1031612 CoresPerSocket&#x3D;64 SocketsPerBoard&#x3D;2 ThreadsPerCore&#x3D;2 State&#x3D;idle Feature&#x3D;dcv2,other&quot;# Grescat &gt;&gt; &#x2F;etc&#x2F;slurm&#x2F;gres.conf &lt;&lt; &quot;EOF&quot;NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia0NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia1NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia2NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia3NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia4NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia5NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia6NodeName&#x3D;citrus Name&#x3D;gpu Type&#x3D;nvidia File&#x3D;&#x2F;dev&#x2F;nvidia7EOF# 更新配置文件sudo systemctl restart slurmctldsudo systemctl restart slurmdsystemctl restart munge.service# 检查是否识别GPUsinfo -o &quot;%n %T %C %G&quot; # 正确识别8张GPU卡# citrus idle 0&#x2F;256&#x2F;0&#x2F;256 gpu:8<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-测试"><a href="#4-测试" class="headerlink" title="4.测试"></a>4.测试</h3><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>resource_test.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;bash#SBATCH --job-name&#x3D;resource_test#SBATCH --output&#x3D;resource_test.out#SBATCH --error&#x3D;resource_test.err#SBATCH --ntasks&#x3D;1#SBATCH --mem&#x3D;40G#SBATCH --cpus-per-task&#x3D;10#SBATCH --gres&#x3D;gpu:1echo &quot;Hello world!&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sbatch resource_test.shsqueuescancel jobid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>有一种丰收的喜悦：<br><a href="https://imgse.com/i/pAYh6gI"><img src="https://s21.ax1x.com/2024/10/12/pAYh6gI.png" alt="pAYh6gI.png"></a><br><a href="https://imgse.com/i/pAYhObT"><img src="https://s21.ax1x.com/2024/10/12/pAYhObT.md.png" alt="pAYhObT.md.png"></a></p><h3 id="5-删除slurm"><a href="#5-删除slurm" class="headerlink" title="5.删除slurm"></a>5.删除slurm</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo systemctl stop slurmctldsudo systemctl stop slurmdsudo systemctl stop slurmdbd# sudo yum remove slurm*sudo apt-get remove --purge slurm*sudo rm -rf &#x2F;etc&#x2F;slurm&#x2F;sudo rm -rf &#x2F;var&#x2F;log&#x2F;slurm&#x2F;sudo rm -rf &#x2F;var&#x2F;spool&#x2F;slurm&#x2F;sudo userdel slurmsudo groupdel slurmsudo rm -rf &#x2F;var&#x2F;log&#x2F;slurm&#x2F;sudo rm &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;slurmctld.servicesudo rm &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;slurmd.servicesudo rm &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;slurmdbd.servicesudo systemctl daemon-reload# 谨慎sudo find &#x2F; -name &quot;*slurm*&quot; -exec rm -rf &#123;&#125; +<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>普通用户提交任务报错:  </p><blockquote><p><code>sbatch: error: Batch job submission failed: Unexpected message received</code><br>检查 <code>/var/log</code> <code>/var/log/slurmctld.log</code>是否有写入权限。<br>一个比较直接的方法是创建一个新的<code>group</code>，将用户提交到这个新的<code>group</code>里，将<code>/var/log</code>文件所属的group也改为这个，大部分的问题都是用户权限，仔细排查应该不会有什么难度。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>htseq-count的坑</title>
      <link href="2024/09/27/htseq-count-de-keng/"/>
      <url>2024/09/27/htseq-count-de-keng/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近在跑RNA-seq碰到一个自己挖的坑，samtools将sam文件转为二进制的bam文件并排序，默认是按照pos进行排序的。htseq-count默认的输入sam|bam是按照name排序的，这样就导致了一个问题，htseq-count会把不在相邻行的paried-end reads当成一条序列：</p><blockquote><p>Warning: 16607642 reads with missing mate encountered.  </p></blockquote><p>&emsp;&emsp;后果是导致虚假的输出： <a href="https://github.com/htseq/htseq/issues/35"><code>Notice that your BAM file is probably sorted by position, but you&#39;re not using the -r pos option. That will most likely result in bogus output.</code></a> 我们需要设置<code>htseq-count</code>的<code>-r pos</code>参数，或者在对bam文件进行排序时，保留按<code>name</code>进行排序。</p><pre class="line-numbers language-none"><code class="language-none">Usage: samtools sort [options...] [in.bam]Options:  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)  -u         Output uncompressed data (equivalent to -l 0)  -m INT     Set maximum memory per thread; suffix K&#x2F;M&#x2F;G recognized [768M]  -M         Use minimiser for clustering unaligned&#x2F;unplaced reads  -K INT     Kmer size to use for minimiser [20]  -n         Sort by read name (not compatible with samtools index command)  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)  -o FILE    Write final output to FILE rather than standard output  -T PREFIX  Write temporary files to PREFIX.nnnn.bam  --no-PG    do not add a PG line      --input-fmt-option OPT[&#x3D;VAL]               Specify a single input file format option in the form               of OPTION or OPTION&#x3D;VALUE  -O, --output-fmt FORMAT[,OPT[&#x3D;VAL]]...               Specify output format (SAM, BAM, CRAM)      --output-fmt-option OPT[&#x3D;VAL]               Specify a single output file format option in the form               of OPTION or OPTION&#x3D;VALUE      --reference FILE               Reference sequence FASTA FILE [null]  -@, --threads INT               Number of additional threads to use [0]      --write-index               Automatically index the output files [off]      --verbosity INT               Set level of verbosity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux查看GPU状态</title>
      <link href="2024/08/25/linux-cha-kan-gpu-zhuang-tai/"/>
      <url>2024/08/25/linux-cha-kan-gpu-zhuang-tai/</url>
      
        <content type="html"><![CDATA[<p>在日常的训练过程中，你可能需要经常查看当前GPU的使用状态(类似于Linux的Top)。有很多命令可以做到。</p><h3 id="1-nvidia-smi"><a href="#1-nvidia-smi" class="headerlink" title="1. nvidia-smi"></a>1. nvidia-smi</h3><p>&emsp;&emsp;这个命令是基础，一般你系统装完CUDA都会有。这里详细的记录了当前系统的GPU数量和相应GPU的具体信息，比如这里只有一张3090显卡，他的满载功耗为350W，显存为24G，当前正在运行一个任务，性能占用为14%。</p><pre class="line-numbers language-none"><code class="language-none">Sun Aug 25 14:44:25 2024       +-----------------------------------------------------------------------------+| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;||   0  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N&#x2F;A ||  0%   49C    P2   112W &#x2F; 350W |   1639MiB &#x2F; 24576MiB |     14%      Default ||                               |                      |                  N&#x2F;A |+-------------------------------+----------------------+----------------------+                                                                               +-----------------------------------------------------------------------------+| Processes:                                                                  ||  GPU   GI   CI        PID   Type   Process name                  GPU Memory ||        ID   ID                                                   Usage      ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;||    0   N&#x2F;A  N&#x2F;A    723829      C   python                           1637MiB |+-----------------------------------------------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;但是<code>nvidia-smi</code>只显示你运行命令时刻的GPU状态，你可以使用<code>watch</code>获得显卡每个时刻的状态：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 这里的1 是 每一秒刷新的意思watch -n 1 nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-gpustate"><a href="#2-gpustate" class="headerlink" title="2. gpustate"></a>2. gpustate</h3><p>&emsp;&emsp;你也可以使用<code>gpustate</code>命令来获取简洁的状态，也可以配合<code>watch</code>命令获得长时间的状态。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 首先得安装gpustatepip intall gpustategpustate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">AMP Sun Aug 25 14:49:10 2024  510.60.02[0] NVIDIA GeForce RTX 3090 | 44°C,   7 % |  1639 &#x2F; 24576 MB | chaofan(1637M)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-nvitop"><a href="#3-nvitop" class="headerlink" title="3. nvitop"></a>3. nvitop</h3><p>&emsp;&emsp;我最喜欢的则是<code>nvitop</code>,他的输出类似于<code>nvidia-smi</code>，但输出信息更丰富，会出来一个类似<code>top</code>命令的窗口，自动更新当前GPU+CPU状态。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 首先得安装</span>pip install nvitop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pAF7Ox0"><img src="https://s21.ax1x.com/2024/08/25/pAF7Ox0.png" alt="pAF7Ox0.png"></a></p>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Circos example</title>
      <link href="2023/12/29/circos-example/"/>
      <url>2023/12/29/circos-example/</url>
      
        <content type="html"><![CDATA[<h1 id="Circos流程记录"><a href="#Circos流程记录" class="headerlink" title="Circos流程记录"></a>Circos流程记录</h1><p>&emsp;&emsp;最近要用到Circos进行绘图，因此进行记录，方便下次绘图。</p><h2 id="0-软件安装"><a href="#0-软件安装" class="headerlink" title="0. 软件安装"></a>0. 软件安装</h2><p>&emsp;&emsp;<code>Circos</code>基于<code>Perl</code>，所以我们需要进行大量<code>Perl</code>包的安装。当然，秉着赌狗的心理，我们看看能不能直接通过<code>conda</code>装。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># conda新建名为 Circos 的环境(每次安装独立的软件时，都建议新建一个conda环境安装，不容易出现什么安装冲突)conda create -n Circos# 激活环境conda activate Circos# 通过bioconda源搜索circos，看看有哪些版本conda search circos -c bioconda# 这里我们安装最新的 0.69.9conda install circos&#x3D;0.69.9 -c bioconda# 这里没有报错，直接输入 y 进行安装# conda安装后 检查是否有依赖缺失circos --modules<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里我们缺少<code>GD</code>和<code>GD::Polyline</code>模块。</p><p><a href="https://imgse.com/i/piT0g76"><img src="https://s11.ax1x.com/2023/12/21/piT0g76.png" alt="piT0g76.png"></a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 通过 conda 安装 libgd 依赖conda install -c fastchan libgd# 通过 conda 安装 perl-gd (perl的gd模块)conda install -c bioconda perl-gd# 如果libwebp这个版本装不上，就直接把版本号去掉安装，然后在conda这个环境的lib文件夹下 &quot;骗软件&quot;# ln -s libwebp.so.7 libwebp.so.6conda install -c conda-forge libwebp&#x3D;0.5.2# 最后检查一遍，一般help文档能出来就说明装成功了circos -h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/piTB1UK"><img src="https://s11.ax1x.com/2023/12/21/piTB1UK.md.png" alt="piTB1UK.md.png"></a></p><h2 id="1-Circos的使用"><a href="#1-Circos的使用" class="headerlink" title="1. Circos的使用"></a>1. Circos的使用</h2><h3 id="1-1-绘制染色体-karyotype"><a href="#1-1-绘制染色体-karyotype" class="headerlink" title="1.1 绘制染色体(karyotype)"></a>1.1 绘制染色体(karyotype)</h3><p>&emsp;&emsp;我们首先需要准备一个<code>karyotype</code>文件，这个文件描述了所绘制染色体的基本信息。这个文件由七列构成，无表头，任意空白字符分割即可。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">faidx ..&#x2F;nextDevono.fa -i chromsizes | sort -nr -k2 | awk &#39;&#123;print &quot;chr&quot;, &quot;-&quot;, $1,NR,&quot;0&quot;,$2, &quot;169,69,255&quot;&#125;&#39; &gt; karyotype.txtfaidx &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;Z7.fa -i chromsizes | sort -n -k2 | awk &#39;&#123;print &quot;chr&quot;, &quot;-&quot;, $1,13-NR,&quot;0&quot;,$2, &quot;6,97,118&quot;&#125;&#39; &gt;&gt; karyotype.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;这里我们的结果文件如下所示:</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>karyotype.txt</span></div><code class="language-txt"># 这里前两列是karyotype固定的，代表绘制染色体# 第三列是染色体ID，也是其他配置文件的坐标锚点# 第四列是具体展示在图上的染色体名称# 第五、六列是染色体起始、终止位置 起着展示染色体长度的信息# 第七列则是染色体方块的颜色，这里名称为RGB颜色chr - ctg000130 1 0 6741225 169,69,255chr - ctg000050 2 0 5683444 169,69,255chr - ctg000120 3 0 3309307 169,69,255chr - ctg000020 4 0 3201804 169,69,255chr - ctg000100 5 0 2838009 169,69,255chr - ctg000040 6 0 2659068 169,69,255chr - ctg000030 7 0 2635818 169,69,255chr - ctg000110 8 0 2444020 169,69,255chr - ctg000010 9 0 2417686 169,69,255chr - ctg000000 10 0 1868462 169,69,255chr - ctg000090 11 0 561846 169,69,255chr - ctg000070 12 0 75900 169,69,255chr - ctg000080 13 0 72450 169,69,255chr - ctg000060 14 0 61073 169,69,255chr - 12 12 0 416412 6,97,118chr - 11 11 0 561391 6,97,118chr - 10 10 0 1841737 6,97,118chr - 9 9 0 2401432 6,97,118chr - 8 8 0 2464928 6,97,118chr - 7 7 0 2519108 6,97,118chr - 6 6 0 2544158 6,97,118chr - 5 5 0 2863349 6,97,118chr - 4 4 0 3085453 6,97,118chr - 3 3 0 3269484 6,97,118chr - 2 2 0 5542836 6,97,118chr - 1 1 0 6770053 6,97,118<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;我们先生成一个染色体的配置文件<code>ideogram.conf</code>，将以下内容放到这个文件中，展示我们上面生成的染色体形状。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>ideogram.conf</span></div><code class="language-txt">#指定染色体文件（绝对/相对路径+文件名）##########################################################################&lt;ideogram>                #这是定义染色体相关参数的标签，相当于HTML的一个条目&lt;spacing>                 #定义染色体间隙宽度的标签，以&lt;/spacing>，其中包括要设置的参数default = 0.006r          #r指的是圆的周长，设置0.5%圆的周长为间隙&lt;pairwise 1;ctg000130>       #可以用&lt;pairwise>标签特别指定某些染色体的间隙（用的是ID），因为在大多数文章中，都会留一个大间隙，来放labelspacing = 5r            #这里20r表示是相对default = 0.005r的20倍，也就是10%的圆的周长&lt;/pairwise>              #标签都要以&lt;/>结尾，&lt;pairwise 12;ctg000060>spacing = 5r&lt;/pairwise>&lt;/spacing>                #间隙定义结束，下面是对染色体样式的调整radius           = 0.65r  #轮廓的位置，这里的r指的是半径，由圆心到圆周上范围依次是0-1r，，超出部分将不再显示。thickness        = 20p    #染色体整体的宽度，这里p指的是像素大小，也可以用r表示，1r=1500pfill             = yes    #是否为染色体填充颜色，如果为yes，自动用第七列定义的颜色着色stroke_color     = dgrey  #染色体边框的颜色，支持多种格式的输入，如：red或255,182,106stroke_thickness = 2p     #染色体边框的粗细show_label     = yes # 展示染色体IDlabel_with_tag = yes # tag 标识是否包含到 label 中label_font     = bold # label 的字体label_center   = yeslabel_size     = 32plabel_color    = greylabel_parallel = yes # label方向， 是否与圆外圈平行label_case     = upper # label 的大小写：upper,lowerlabel_radius = 0.98r&lt;/ideogram>               #定义染色体属性的标签结束##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们再配置一个基础的运行<code>conf</code>文件: Alternaria.conf</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>Alternaria.conf</span></div><code class="language-txt">##########################################################################chromosomes_units           = 100000 # 设置u的单位，1u = 100kbpkaryotype = ./karyotype.txt&lt;&lt;include ideogram.conf>>#下面是每次都要复制粘贴上去的，他们属于circos自带的配置文件，用于调用颜色，距离，报错等信息&lt;image>                    #注意路径&lt;&lt;include etc/image.conf>> #注意引用外部配置文件需要使用&lt;&lt;#>>&lt;/image>&lt;&lt;include etc/colors_fonts_patterns.conf>> &lt;&lt;include etc/housekeeping.conf>>##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">circos -conf Alternaria.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们得到了初步的染色体结果:</p><p><a href="https://imgse.com/i/pi7E1Pg"><img src="https://s11.ax1x.com/2023/12/22/pi7E1Pg.png" alt="pi7E1Pg.png"></a></p><p>我们再配置一个<code>ticks.conf</code>文件，加上染色体ID及刻度线。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>ticks.conf</span></div><code class="language-txt">########################################################################### 配置染色体标签和刻度线show_ticks          = yes  #选择yes表示要显示刻度线show_tick_labels    = yes  #选择yes表示要显示刻度线的数值#定义刻度线的整体位置与形状&lt;ticks>                    #刻度线的转用标签，但凡是复数出现的，其下面的参数都表示全局参数，像下面的&lt;tick>单数形式，都表示局部参数radius           = 1r      #刻度线的位置，1r为最远距离，超过1r不再显示color            = blackthickness        = 3pmultiplier       = 1e-6    #刻度标签的大小，这里我们一个标签=10u，这里大刻度就是1=1M,如果multiplier=1e-5,那这里的刻度就是10format           = %d      #然后以整数的形式标记在刻度线上#定义小的刻度线，且不显示数值&lt;tick>spacing        = 1u        #最开始我们定义1u = multiplier = 100000，表示一个小刻度为100kbpsize           = 8pshow_label     = no        # 是否展示小刻度线&lt;/tick>#定义大的刻度线，显示数值&lt;tick>spacing        = 10u # 这里设置一个大刻度为10个小刻度size           = 20pshow_label     = yeslabel_size     = 30plabel_offset   = 10p      #设置数值和刻度线之间的间隔format         = %d&lt;/tick>&lt;/ticks>##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们再在Alternaria.conf中加入这个<code>ticks.conf</code></p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>Alternaria.conf</span></div><code class="language-txt">##########################################################################chromosomes_units           = 100000 # 设置u的单位，1u = 100kbpkaryotype = ./karyotype.txt&lt;&lt;include ideogram.conf>>&lt;&lt;include ticks.conf>>#下面是每次都要复制粘贴上去的，他们属于circos自带的配置文件，用于调用颜色，距离，报错等信息&lt;image>                    #注意路径&lt;&lt;include etc/image.conf>> #注意引用外部配置文件需要使用&lt;&lt;#>>&lt;/image>&lt;&lt;include etc/colors_fonts_patterns.conf>> &lt;&lt;include etc/housekeeping.conf>>##########################################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 运行circos -conf Alternaria.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7EBiF"><img src="https://s11.ax1x.com/2023/12/22/pi7EBiF.png" alt="pi7EBiF.png"></a></p><h3 id="1-2-外圈展示GC含量"><a href="#1-2-外圈展示GC含量" class="headerlink" title="1.2 外圈展示GC含量"></a>1.2 外圈展示GC含量</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">faidx ..&#x2F;nextDevono.fa -i chromsizes &gt;  nextDevono.txtfaidx &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;Z7.fa -i chromsizes &gt;  Z7.txtbedtools makewindows -g nextDevono.txt -w 20000 &gt; gaisen.20kb.winbedtools makewindows -g Z7.txt -w 20000 | sort -n -k 1 -n -k 2  &gt; Z7.20kb.winbedtools nuc -fi ..&#x2F;nextDevono.fa -bed gaisen.20kb.win | \cut -f 1-3,5 | grep -v &quot;#&quot; | \awk -vFS&#x3D;&quot;\t&quot; -vOFS&#x3D;&quot;\t&quot; &#39;&#123;print $1,$2,$3,$4*(100)-50&#125;&#39; &gt; gc.density.txtbedtools nuc -fi &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;Z7.fa -bed Z7.20kb.win | \cut -f 1-3,5 | grep -v &quot;#&quot; | \awk -vFS&#x3D;&quot;\t&quot; -vOFS&#x3D;&quot;\t&quot; &#39;&#123;print $1,$2,$3,$4*(100)-50&#125;&#39; &gt;&gt; gc.density.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们另外生成一个<code>GC.conf</code>文件。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>GC.conf</span></div><code class="language-txt">&lt;plots>    &lt;plot>        type      = line #设定显示类型        thickness = 2p #折线图的粗细        max_gap = 1u         file    = gc.density.txt #输入数据        color   = vdgrey #折线颜色        min     = -5 #环道内圈代表的数值下限，超出下限的数值不会显示，下同        max     = 5 #环道外圈代表的数值上限        r0      = 1.06r #环道内圈位置        r1      = 1.18r #环道外圈位置        fill_color = vdgrey_a3        &lt;rules>            &lt;rule> #设置折线图大于0部分显示为蓝色                condition    = var(value) > 0                color        = blue                fill_color   = blue_a1            &lt;/rule>            &lt;rule> #设置折线图小于0部分显示为红色                condition    = var(value) &lt; 0                color        = red                fill_color   = red_a1            &lt;/rule>        &lt;/rules>    &lt;/plot>&lt;/plots><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7mvBn"><img src="https://s11.ax1x.com/2023/12/22/pi7mvBn.png" alt="pi7mvBn.png"></a></p><h3 id="1-3-外圈展示基因含量"><a href="#1-3-外圈展示基因含量" class="headerlink" title="1.3 外圈展示基因含量"></a>1.3 外圈展示基因含量</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">grep &#39;[[:blank:]]gene[[:blank:]]&#39; ..&#x2F;fungap_out.gff3 | \awk &#39;&#123;print $1&quot;\t&quot;$4&quot;\t&quot;$5&#125;&#39; |bedtools coverage -a gaisen.20kb.win -b - | \cut -f 1-4 &gt; gene.density.txtgrep &#39;[[:blank:]]gene[[:blank:]]&#39; &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;2023-10-05.corrected.gff3 | \awk &#39;&#123;print $1&quot;\t&quot;$4&quot;\t&quot;$5&#125;&#39; |bedtools coverage -a Z7.20kb.win -b - | \cut -f 1-4 &gt;&gt; gene.density.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们把gene_density信息也加到<code>GC.conf</code>文件。</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>GC.conf</span></div><code class="language-txt">&lt;plots>    &lt;plot>        type      = line #设定显示类型        thickness = 2p #折线图的粗细        max_gap = 1u         file    = gc.density.txt #输入数据        color   = vdgrey #折线颜色        min     = -5 #环道内圈代表的数值下限，超出下限的数值不会显示，下同        max     = 5 #环道外圈代表的数值上限        r0      = 1.08r #环道内圈位置        r1      = 1.16r #环道外圈位置        fill_color = vdgrey_a3        &lt;rules>            &lt;rule> #设置折线图大于0部分显示为蓝色                condition    = var(value) > 0                color        = blue                fill_color   = blue_a1            &lt;/rule>            &lt;rule> #设置折线图小于0部分显示为红色                condition    = var(value) &lt; 0                color        = red                fill_color   = red_a1            &lt;/rule>        &lt;/rules>    &lt;/plot>    ########################################## NEW ##########################    &lt;plot>    type      = histogram #设定显示类型    thickness = 2p #折线图的粗细file = gene.density.txtr0 = 1.18rr1 = 1.26rcolor = 114,176,67    &lt;/plot>    ########################################## NEW ##########################&lt;/plots><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7uvF0"><img src="https://s11.ax1x.com/2023/12/22/pi7uvF0.png" alt="pi7uvF0.png"></a></p><h3 id="1-4-展示共线性基因"><a href="#1-4-展示共线性基因" class="headerlink" title="1.4 展示共线性基因"></a>1.4 展示共线性基因</h3><p>&emsp;&emsp;我们首先通过<code>JCVI</code>鉴定两个基因组上的共线性区域，通过<code>simple</code>文件提取共线性区域。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python -m jcvi.formats.gff bed --type&#x3D;mRNA --key&#x3D;ID Gaisen.gff &gt; Gaisen.bedpython -m jcvi.formats.gff bed --type&#x3D;mRNA --key&#x3D;ID Z7.gff &gt; Z7.bed# 鉴定两个基因组间的共线性基因python -m jcvi.compara.catalog ortholog --dbtype prot Z7 Gaisen --cscore&#x3D;.98 --no_strip_names  # 创建simple文件python -m jcvi.compara.synteny screen --minspan&#x3D;25 --simple Z7.Gaisen.anchors Z7.Gaisen.simple# 从gff文件中提取simple block的区间python jcvi2link.py &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;20.Alternata_gff&#x2F;04.final_res&#x2F;2023-10-05.corrected.gff3 ..&#x2F;fungap_out.gff3 &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;07.genome_assemble&#x2F;07.JCVI&#x2F;Z7.Gaisen.simple link.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>jcvi2link.py</span></div><code class="language-python"><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span>exit <span class="token keyword">def</span> <span class="token function">gene_dic</span><span class="token punctuation">(</span>gff<span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>gff<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"#"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"mRNA"</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> tmp_dic<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">5</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"python </span><span class="token interpolation"><span class="token punctuation">&#123;</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string"> [Z7_gff] [Gaisen_gff] [simple_file] [link_txt]"</span></span><span class="token punctuation">)</span>    Z7_dic <span class="token operator">=</span> gene_dic<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    Gaisen_dic <span class="token operator">=</span> gene_dic<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    colors <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"+"</span><span class="token punctuation">:</span><span class="token string">"62,169,8"</span><span class="token punctuation">,</span><span class="token string">"-"</span><span class="token punctuation">:</span><span class="token string">"65,182,230"</span><span class="token punctuation">&#125;</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>        Z7_min <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Z7_max <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Gaisen_min <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Gaisen_max <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span>Z7_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Z7_min<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Z7_max<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>Gaisen_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Gaisen_min<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>Gaisen_max<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"\tcolor="</span><span class="token operator">+</span>colors<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>得到这样的结果文件:<br><a href="https://imgse.com/i/pi7BPdx"><img src="https://s11.ax1x.com/2023/12/23/pi7BPdx.png" alt="pi7BPdx.png"></a></p><p>我们再配置<code>link.conf</code>文件:</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>link.conf</span></div><code class="language-txt">&lt;links>&lt;link>file          = link.txtribbon        = yesradius        = 0.95rbezier_radius = 0rflat   = yes # 强制条带不扭转bezier_radius_purity = 0.5thickness     = 1&lt;/link>&lt;/links><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/pi7Dp9S"><img src="https://s11.ax1x.com/2023/12/23/pi7Dp9S.png" alt="pi7Dp9S.png"></a></p><p>当然，还有很多进阶的配置，后面慢慢改。</p><h3 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程:"></a><strong>参考教程</strong>:</h3><ul><li><a href="https://irenexzwen.gitbooks.io/hello-gitbook/content">https://irenexzwen.gitbooks.io/hello-gitbook/content</a></li><li><a href="https://www.jianshu.com/p/9c0d2b9d724e">https://www.jianshu.com/p/9c0d2b9d724e</a></li><li><a href="https://www.jianshu.com/p/e63292c1001c">https://www.jianshu.com/p/e63292c1001c</a></li><li><a href="https://www.jianshu.com/p/78f4ae15d22a">https://www.jianshu.com/p/78f4ae15d22a</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SYRI Synteny and Rearrangement Identifier</title>
      <link href="2023/12/29/syri-synteny-and-rearrangement-identifier/"/>
      <url>2023/12/29/syri-synteny-and-rearrangement-identifier/</url>
      
        <content type="html"><![CDATA[<h1 id="使用SYRI鉴定基因组变异及可视化"><a href="#使用SYRI鉴定基因组变异及可视化" class="headerlink" title="使用SYRI鉴定基因组变异及可视化"></a>使用SYRI鉴定基因组变异及可视化</h1><h3 id="1-调整两条比对基因组的染色体方向"><a href="#1-调整两条比对基因组的染色体方向" class="headerlink" title="1.调整两条比对基因组的染色体方向"></a>1.调整两条比对基因组的染色体方向</h3><p><code>SYRI</code>对比对的基因组有非常严格的要求：</p><ol><li>两个基因组的染色体ID必须一一对应(同源染色体ID必须一致，染色体数量也必须一致，染色体ID不能是数字)； </li><li>同源染色体strand方向必须一致。</li></ol><p>&emsp;&emsp;我们根据之前已有的共线性关系，手动生成一个染色体操作表格，然后用<code>pythpn</code>代码进行ID替换与strand方向的改变。</p><p>&emsp;&emsp;这里<code>RAW_ID</code>是其中一个样基因组染色体ID，<code>NEW_ID</code>是新的染色体ID，这个与另外一个样本的染色体ID是一一对应的(另外一个样本的染色体ID就是这种1,2,3,4..11), <code>STRAND</code>为链的方向，<code>+</code>代表两个样本这条染色体方向一致，<code>-</code>代表方向相反，需手动生成反向互补链。<br><strong>替换表格</strong>:</p><table><thead><tr><th>RAW_ID</th><th>NEW_ID</th><th>STRAND</th></tr></thead><tbody><tr><td>ctg000130</td><td>Chr1</td><td>+</td></tr><tr><td>ctg000050</td><td>Chr2</td><td>-</td></tr><tr><td>ctg000120</td><td>Chr3</td><td>+</td></tr><tr><td>ctg000020</td><td>Chr4</td><td>-</td></tr><tr><td>ctg000100</td><td>Chr5</td><td>+</td></tr><tr><td>ctg000040</td><td>Chr6</td><td>-</td></tr><tr><td>ctg000030</td><td>Chr7</td><td>+</td></tr><tr><td>ctg000110</td><td>Chr8</td><td>-</td></tr><tr><td>ctg000010</td><td>Chr9</td><td>+</td></tr><tr><td>ctg000000</td><td>Chr10</td><td>-</td></tr><tr><td>ctg000090</td><td>Chr11</td><td>-</td></tr></tbody></table><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">def</span> <span class="token function">read_fa</span><span class="token punctuation">(</span>fa_file<span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fa_file<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'\n'</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'>'</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span>t_lst<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>t_lst<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> t_lst <span class="token keyword">in</span> tmp_dic<span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> tmp_dic<span class="token keyword">def</span> <span class="token function">reverse_complement</span><span class="token punctuation">(</span>dna_sequence<span class="token punctuation">)</span><span class="token punctuation">:</span>    complement_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token string">'T'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">:</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">:</span> <span class="token string">'G'</span><span class="token punctuation">,</span> <span class="token string">'G'</span><span class="token punctuation">:</span> <span class="token string">'C'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">:</span><span class="token string">'N'</span><span class="token punctuation">&#125;</span>    reverse_sequence <span class="token operator">=</span> dna_sequence<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    complement_sequence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>complement_dict<span class="token punctuation">[</span>base<span class="token punctuation">]</span> <span class="token keyword">for</span> base <span class="token keyword">in</span> reverse_sequence<span class="token punctuation">)</span>    <span class="token keyword">return</span> complement_sequence<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"python </span><span class="token interpolation"><span class="token punctuation">&#123;</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string"> [raw_fa] [info_tab] [paired_fa]"</span></span><span class="token punctuation">)</span>        info_tab <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"RAW_ID"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>        info_tab<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>     raw_fas <span class="token operator">=</span> read_fa<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> seq_id <span class="token keyword">in</span> info_tab<span class="token punctuation">:</span>        <span class="token keyword">if</span> info_tab<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'+'</span><span class="token punctuation">:</span>            tmp_seq <span class="token operator">=</span> raw_fas<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 输出反向互补链</span>            tmp_seq <span class="token operator">=</span> reverse_complement<span class="token punctuation">(</span>raw_fas<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">">"</span><span class="token operator">+</span>info_tab<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span> <span class="token operator">+</span> tmp_seq<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>                ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 直接运行python pair_chr.py ..&#x2F;nextDevono.fa info.tab gaisen.fa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-SYRI鉴定SV并可视化"><a href="#2-SYRI鉴定SV并可视化" class="headerlink" title="2.SYRI鉴定SV并可视化"></a>2.SYRI鉴定SV并可视化</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># nucmer比对nucmer -c 100 -l 50 -t 8 -p Z7.gaisen Z7.fa gaisen.fa# 比对结果过滤delta-filter -m -i 90 -l 100 Z7.gaisen.delta &gt; Z7.gaisen.filtered.delta# 比对格式转换show-coords -THrd Z7.gaisen.filtered.delta &gt; Z7.gaisen.filtered.coords# SYRI鉴定基因组变异python3 &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;miniconda&#x2F;envs&#x2F;syri_env&#x2F;bin&#x2F;syri -s &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;miniconda&#x2F;envs&#x2F;syri_env&#x2F;bin&#x2F;show-snps -c Z7.gaisen.filtered.coords -d Z7.gaisen.filtered.delta -r Z7.fa -q gaisen.fa --prefix Z7.gaisen.# 生成基因组信息文件，tab分隔(详细内容见代码框下)vi genome.txt# plotsr可视化 -H：输出图形高 -W： 输出图形高plotsr \    --sr Z7.gaisen.syri.out \    --genomes genome.txt -o genome.pdf -b pdf -H 16 -W 12<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>genome.txt</code>文件内容：</p><pre class="line-numbers language-txt" data-language="txt"><div class="caption"><span>genome.txt</span></div><code class="language-txt">#filenametagsZ7.faZ7lw:2gaisen.faGaisenlw:2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/piL4hZt"><img src="https://s11.ax1x.com/2023/12/29/piL4hZt.png" alt="piL4hZt.png"></a></p><p>&emsp;&emsp;嗯，结果看着还行。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> Python </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ncRNA-annotation</title>
      <link href="2023/10/02/ncrna-annotation/"/>
      <url>2023/10/02/ncrna-annotation/</url>
      
        <content type="html"><![CDATA[<h2 id="1-conda-环境配置"><a href="#1-conda-环境配置" class="headerlink" title="1.conda 环境配置"></a>1.conda 环境配置</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># conda envconda create -n ncRNAconda activate ncRNA# download infernalconda install -c bioconda infernal<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-注释-DB-配置"><a href="#2-注释-DB-配置" class="headerlink" title="2.注释 DB 配置"></a>2.注释 DB 配置</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#  download Rfam datacd &#x2F;data&#x2F;chaofan&#x2F;sourcemkdir 04.ncRNA &amp;&amp; cd 04.ncRNAwget ftp:&#x2F;&#x2F;ftp.ebi.ac.uk&#x2F;pub&#x2F;databases&#x2F;Rfam&#x2F;CURRENT&#x2F;Rfam.cm.gzgzip -d Rfam.cm.gzwget ftp:&#x2F;&#x2F;ftp.ebi.ac.uk&#x2F;pub&#x2F;databases&#x2F;Rfam&#x2F;CURRENT&#x2F;Rfam.clanin# cmpress 索引cmpress Rfam.cm# 从https:&#x2F;&#x2F;rfam.org&#x2F;search&#x2F;type下载相应RF-number对应的注释# 地址为: &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;RF.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-开始注释-ncRNA"><a href="#3-开始注释-ncRNA" class="headerlink" title="3.开始注释 ncRNA"></a>3.开始注释 ncRNA</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 开始注释cd &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;13.Alternaria_Z7&#x2F;08.gaisen_genome&#x2F;l0cmscan -Z 66 --cut_ga --rfam --nohmmonly --tblout gaisen.asm.primer.tblout  \  --fmt 2 --cpu 40 --clanin &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.clanin \  &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.cm gaisen.asm.primer.fa &gt; gaisen.asm.primer.cmscancd &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;13.Alternaria_Z7&#x2F;08.gaisen_genome&#x2F;nextDenovocmscan -Z 66 --cut_ga --rfam --nohmmonly --tblout nextDevono.tblout  \  --fmt 2 --cpu 40 --clanin &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.clanin \  &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;Rfam.cm nextDevono.fa &gt; nextDevono.cmscan# -Z：根据基因组大小来定，基因组大小的2倍，Mb单位，选一个整数# –tblout 指定table格式输出文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-注释结果整理"><a href="#4-注释结果整理" class="headerlink" title="4.注释结果整理"></a>4.注释结果整理</h2><p>保留非重叠区及重叠区最佳 hit(可以不做)</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">awk &#39;BEGIN&#123;OFS&#x3D;&quot;\t&quot;;&#125;&#123;if(FNR&#x3D;&#x3D;1) print &quot;target_name\taccession\tquery_name\tquery_start\tquery_end\tstrand\tscore\tEvalue&quot;; if(FNR&gt;2 &amp;&amp; $20!&#x3D;&quot;&#x3D;&quot; &amp;&amp; $0!~&#x2F;^#&#x2F;) print $2,$3,$4,$10,$11,$12,$17,$18; &#125;&#39; nextDevono.tblout &gt; nextDevono.tblout.xls<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注释结果整理为 gff 格式, 有些具体的细节我按照自己喜欢的格式进行生成，也可以进行调整。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python &#x2F;data&#x2F;chaofan&#x2F;scripts&#x2F;infernal-tblout2gff.py nextDevono.tblout nextDevono.infernal.ncRNA.gff3 &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;RF.txtpython &#x2F;data&#x2F;chaofan&#x2F;scripts&#x2F;infernal-tblout2gff.py gaisen.asm.primer.tblout gaisen.asm.primer.infernal.ncRNA.gff3 &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;04.ncRNA&#x2F;RF.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="5-所用脚本"><a href="#5-所用脚本" class="headerlink" title="5.所用脚本"></a>5.所用脚本</h2><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>infernal-tblout2gff.py</span></div><code class="language-python"><span class="token comment">#!/data/chaofan/software/miniconda/bin/python</span><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">import</span> os<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Usage: python </span><span class="token interpolation"><span class="token punctuation">&#123;</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string"> [infernal-tblout] [ouf_gff] [RF.txt]"</span></span><span class="token punctuation">)</span>    ouf_lines <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"Input file not exists!"</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"RF-number info not exists!"</span><span class="token punctuation">)</span>    RF_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"Gene;"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> <span class="token string">";"</span> <span class="token keyword">in</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'#'</span><span class="token punctuation">,</span> <span class="token string">'\n'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        tmp <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'='</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        start_end <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span><span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">int</span><span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        t <span class="token operator">=</span> <span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"cmscan"</span><span class="token punctuation">,</span> RF_dic<span class="token punctuation">[</span>tmp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> start_end<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> start_end<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> \            tmp<span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tmp<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">"Description="</span><span class="token operator">+</span>tmp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">":"</span><span class="token operator">+</span><span class="token string">"_"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        ouf_lines<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>    ouf_lines <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>ouf_lines<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> s<span class="token punctuation">:</span><span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token builtin">int</span><span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    t_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token comment"># add_id</span>    <span class="token keyword">for</span> order <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ouf_lines<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> t_dic<span class="token punctuation">:</span>            t_dic<span class="token punctuation">[</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            t_dic<span class="token punctuation">[</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>        ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"ID="</span><span class="token operator">+</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"_"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>t_dic<span class="token punctuation">[</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>zfill<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">+</span>\            <span class="token string">"; "</span><span class="token operator">+</span>ouf_lines<span class="token punctuation">[</span>order<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"\t"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>t_l<span class="token punctuation">)</span> <span class="token keyword">for</span> t_l <span class="token keyword">in</span> ouf_lines<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp;&ensp;如发现任何问题，恳请联系我纠正。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> ncRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>manual_genome</title>
      <link href="2023/08/25/manual-genome/"/>
      <url>2023/08/25/manual-genome/</url>
      
        <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1.引言"></a>1.引言</h2><p>&ensp;&ensp;&ensp;&ensp;我们在基因组的组装过程中可能需要手动检查的情况，直接对初始的组装结果进行手动矫正，而这个脚本就是用来做这个的。<br>这些都是在原序列的基础上操作的，我检查了几个例子是没问题的，但是用的时候还是要注意隐藏的 BUG。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Usage: python removeDNA_fromBED.py [raw_contig] [dispose.bed] [disposed_contig]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-输入输出"><a href="#2-输入输出" class="headerlink" title="2.输入输出"></a>2.输入输出</h2><p>输入的 bed 文件根据操作的不同，有不同的列数，每个操作都是一行。<br>一共有 4 大类:</p><ul><li>‘D’: Deletion 删除;</li><li>‘RC’: Reverse_Complement 反向互补;</li><li>‘I’: Insertion 插入序列，这个操作行有五列，除 le 和<code>D</code>和<code>RC</code>类似的 4 列外，<br>多了第五列用来存放要插入的序列，而且这一行的第二列和第三列应该是一样的。<br>你是插入一个点，比如在 11 位置插入，就是在前 10 个碱基后插入一段序列。</li><li>‘M’: Move 挪动序列，这个操作行有 7 列: Chr start1 end1 M start2 end2 [+|-]<br>你是移动，就会有两个位置嘛，如果第七列为 + 符号，代表把 start1 到 end1 的序列<br>挪动到 start2 和 end2 的位置，这种情况下 start2 是等于 end2 的。这个操作等价与在<br>start1 到 end 的一个删除和在 start2 的一个插入。 如果第七列为 - 符号，则方向<br>相反，把 start2-end2 的序列插入到 start1(=end1)的位置。</li></ul><p>输入 <code>bed</code> 文件示例：</p><pre class="line-numbers language-none"><code class="language-none">contig1110RCcontig11111IZCF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入 <code>fasta</code>文件：</p><pre class="line-numbers language-none"><code class="language-none">&gt;contig1AAAAAAAAAATTTTTTTTTTCCCCCCCCCCGGGGGGGGGG<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输出结果：</p><pre class="line-numbers language-none"><code class="language-none">&gt;contig1TTTTTTTTTTZCFTTTTTTTTTTCCCCCCCCCCGGGGGGGGGG<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-脚本"><a href="#3-脚本" class="headerlink" title="3.脚本"></a>3.脚本</h2><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>manual_genome.py</span></div><code class="language-python"><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">def</span> <span class="token function">reverse_complement</span><span class="token punctuation">(</span>sequence<span class="token punctuation">)</span><span class="token punctuation">:</span>    complement_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token string">'T'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">:</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token string">'C'</span><span class="token punctuation">:</span> <span class="token string">'G'</span><span class="token punctuation">,</span> <span class="token string">'G'</span><span class="token punctuation">:</span> <span class="token string">'C'</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">:</span> <span class="token string">'t'</span><span class="token punctuation">,</span> <span class="token string">'t'</span><span class="token punctuation">:</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">:</span><span class="token string">'g'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">:</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'N'</span><span class="token punctuation">:</span><span class="token string">'N'</span><span class="token punctuation">,</span> <span class="token string">'n'</span><span class="token punctuation">:</span> <span class="token string">'n'</span><span class="token punctuation">&#125;</span>    reverse_complement_sequence <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>complement_dict<span class="token punctuation">[</span>base<span class="token punctuation">]</span> <span class="token keyword">for</span> base <span class="token keyword">in</span> sequence<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> reverse_complement_sequence<span class="token keyword">def</span> <span class="token function">read_fasta_file</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    fasta_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    current_sequence <span class="token operator">=</span> <span class="token string">""</span>    current_id <span class="token operator">=</span> <span class="token boolean">None</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 处理标识符行</span>                <span class="token keyword">if</span> current_id <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                    fasta_dict<span class="token punctuation">[</span>current_id<span class="token punctuation">]</span> <span class="token operator">=</span> current_sequence                current_id <span class="token operator">=</span> line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>                current_sequence <span class="token operator">=</span> <span class="token string">""</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># 处理序列行</span>                current_sequence <span class="token operator">+=</span> line        <span class="token keyword">if</span> current_id <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            fasta_dict<span class="token punctuation">[</span>current_id<span class="token punctuation">]</span> <span class="token operator">=</span> current_sequence    <span class="token keyword">return</span> fasta_dict<span class="token keyword">def</span> <span class="token function">read_tsv_file</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> fa_dic<span class="token punctuation">)</span><span class="token punctuation">:</span>    tsv_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>            line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> line<span class="token punctuation">:</span>  <span class="token comment"># 跳过空行</span>                columns <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>                key <span class="token operator">=</span> columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                <span class="token keyword">if</span> key <span class="token keyword">not</span> <span class="token keyword">in</span> tsv_dict<span class="token punctuation">:</span>                    tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                <span class="token keyword">if</span> columns<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">"M"</span><span class="token punctuation">:</span>                    tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token comment"># move order</span>                    <span class="token comment"># M = insertion + deletion</span>                    <span class="token keyword">if</span> columns<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'+'</span><span class="token punctuation">:</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> \                            fa_dic<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        tsv_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> \                            fa_dic<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>columns<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment">#</span>    <span class="token keyword">for</span> ctg <span class="token keyword">in</span> tsv_dict<span class="token punctuation">:</span>        tsv_dict<span class="token punctuation">[</span>ctg<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>tsv_dict<span class="token punctuation">[</span>ctg<span class="token punctuation">]</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> tsv_dict<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"Usage: python manual_genome.py [raw_contig] [dispose.bed] [disposed_contig]\n\n\n"</span> <span class="token operator">+</span> \            <span class="token string">"Like BED format [1_index]: \nChr\tstart\tEND\tkeyword\nkeyword: 'D': deletion; 'RC' : reverse_complement; "</span> <span class="token operator">+</span> \            <span class="token string">"'M': move seqs from one pos to another pos(in same contig)."</span> <span class="token operator">+</span> <span class="token string">"\n"</span> <span class="token operator">+</span> \            <span class="token string">"If keyword = 'I', the line with 5 columns: Chr start end I [insertion_seq].\n"</span><span class="token operator">+</span> \            <span class="token string">"If keyword = 'M', the line with 7 columns: Chr start1 end1 M start2 end2 [+|-].\n"</span><span class="token operator">+</span> \            <span class="token string">"If 7thcol in M lines = '+', means move seqs from start1 to start2, else move seqs from start2 to start1\n"</span><span class="token punctuation">)</span>    fa_dic <span class="token operator">=</span> read_fasta_file<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    dispose_dic <span class="token operator">=</span> read_tsv_file<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> fa_dic<span class="token punctuation">)</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> contig <span class="token keyword">in</span> fa_dic<span class="token punctuation">:</span>        raw_Seq <span class="token operator">=</span> fa_dic<span class="token punctuation">[</span>contig<span class="token punctuation">]</span>        gap_bp <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> items <span class="token keyword">in</span> dispose_dic<span class="token punctuation">[</span>contig<span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># Deletion</span>            <span class="token keyword">if</span> items<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"D"</span><span class="token punctuation">:</span>                raw_Seq <span class="token operator">=</span> raw_Seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span> <span class="token operator">+</span> raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token punctuation">]</span>                gap_bp <span class="token operator">+=</span>  <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">print</span><span class="token punctuation">(</span>gap_bp<span class="token punctuation">)</span>            <span class="token comment"># reverse_complement</span>            <span class="token keyword">if</span> items<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"RC"</span><span class="token punctuation">:</span>                raw_Seq <span class="token operator">=</span> raw_Seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span> <span class="token operator">+</span> \                    reverse_complement<span class="token punctuation">(</span>raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                    raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> items<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"I"</span><span class="token punctuation">:</span>                raw_Seq <span class="token operator">=</span> raw_Seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">]</span> <span class="token operator">+</span> \                    items<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">+</span> \                    raw_Seq<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span>gap_bp<span class="token punctuation">:</span><span class="token punctuation">]</span>                gap_bp <span class="token operator">-=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">">"</span><span class="token operator">+</span>contig<span class="token operator">+</span><span class="token string">"\n"</span><span class="token operator">+</span>raw_Seq<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp;&ensp;如发现任何问题，恳请联系我纠正。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Install R-packages from github</title>
      <link href="2023/08/14/install-r-packages-from-github/"/>
      <url>2023/08/14/install-r-packages-from-github/</url>
      
        <content type="html"><![CDATA[<p>一些常用的从 github 上安装 R 包的方法:</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 1. devtoolsinstall.packages(&quot;devtools&quot;, dep&#x3D;TRUE)library(devtools)install_github(&quot;caitiecollins&#x2F;treeWAS&quot;, build_vignettes &#x3D; TRUE)# 2. githubinstalllibrary(githubinstall)install_github(&#39;hadlley&#x2F;dplyr&#39;)# 3. remotesinstall.packages(&#39;remotes&#39;)remotes::install_git(&quot;https:&#x2F;&#x2F;hub.fastgit.xyz&#x2F;yzhlinscau&#x2F;AFEchidna.git&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>本人经常用第三种方法。</p>]]></content>
      
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fungiMatingType</title>
      <link href="2023/07/10/fungimatingtype/"/>
      <url>2023/07/10/fungimatingtype/</url>
      
        <content type="html"><![CDATA[<h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0.前言"></a>0.前言</h2><p>&emsp;&emsp;在做真菌的一些生信分析中，可能需要真菌的繁殖方式的信息。真菌的繁殖方式主要有两种：<code>同宗配合</code>与<code>异宗配合</code>，自然界中绝大多数的情况下都是<code>异宗配合</code>。控制真菌交配型的基因主要有两种： MAT1-1 和 MAT1-2，<code>异宗配合</code>指的是繁殖时必须需要这两种不同的交配型，<code>同宗配合</code>则没有这个限制<sup><a href="#ref1">1</a></sup>。<br><a href="https://imgse.com/i/pC7tp6O"><img src="https://s1.ax1x.com/2023/07/19/pC7tp6O.jpg" alt="pC7tp6O.jpg"></a></p><h2 id="1-NCBI-下载同源序列"><a href="#1-NCBI-下载同源序列" class="headerlink" title="1.NCBI 下载同源序列"></a>1.NCBI 下载同源序列</h2><p>&emsp;&emsp;通过上面的知识，我们了解到<em>Alternaria</em>属于<em>Dothideomycetes</em>，主要有两种交配型基因<code>MAT 1-1-1</code>与<code>MAT 1-2-1</code>。然后我们使用 NCBI 进行检索，关键字为<code>((Alternaria) AND mating-type) NOT partial</code>,发现搜索结果也主要的分为了<code>MAT 1-1-1</code>与<code>MAT 1-2-1</code>这两种。<br><a href="https://imgse.com/i/pC7tUjU"><img src="https://s1.ax1x.com/2023/07/19/pC7tUjU.png" alt="pC7tUjU.png"></a><br>&emsp;&emsp;我们两种交配型分别挑选 6~7 条 items，然后按顺序点击下图标签，这里第四步可以选择下载 DNA 还是 protein 序列，我们直接选择 DNA 序列。<br><a href="https://imgse.com/i/pC7tDE9"><img src="https://s1.ax1x.com/2023/07/19/pC7tDE9.png" alt="pC7tDE9.png"></a><br>交配型 MAT1-1 与 MAT1-2 的序列差异非常的大，不管是 DNA 还是 protein，你也可以自己试试。</p><h2 id="2-前处理"><a href="#2-前处理" class="headerlink" title="2.前处理"></a>2.前处理</h2><p>&emsp;&emsp;主要使用 blastn 来鉴定，输入数据包括上一步下载的 DNA 序列和组装好的基因组，如果你的物种基因组很小，就几十 Mb，然后你的二代数据用<a href="https://github.com/ablab/spades">SPADEs</a>能组装的非常好。用<a href="https://github.com/ablab/spades">SPADEs</a>怎么组装基因组之前写过，这里就不详细讲了。</p><p>&emsp;&emsp;上一步下载的 fasta 格式的 DNA 序列的 ID 信息有点乱：</p><blockquote><p>&gt;lcl|AB444193.1_cds_BAJ10530.1_1 [gene=MAT1-1-1] [protein=mating type protein MAT1-1-1] [protein_id=BAJ10530.1] [location=join(&lt;1..142,190..&gt;631)] [gbkey=CDS]</p></blockquote><p>最好修改下 ID，方便后续处理，我的话会改成:</p><pre class="line-numbers language-none"><code class="language-none">&gt;ADE44136.1__MAT1-1-1&gt;ADE44135.1__MAT1-1-1&gt;ADE44134.1__MAT1-1-1&gt;ADE44132.1__MAT1-1-1&gt;ADE44131.1__MAT1-1-1&gt;ADE44128.1__MAT1-1-1&gt;ADE44126.1__MAT1-2-1&gt;ADE44125.1__MAT1-2-1&gt;ADE44124.1__MAT1-2-1&gt;ADE44123.1__MAT1-2-1&gt;ADE44120.1__MAT1-2-1&gt;ADE44118.1__MAT1-2-1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-交配型的鉴定"><a href="#3-交配型的鉴定" class="headerlink" title="3.交配型的鉴定"></a>3.交配型的鉴定</h2><h3 id="3-1-blast-建库"><a href="#3-1-blast-建库" class="headerlink" title="3.1 blast 建库"></a>3.1 blast 建库</h3><p>&emsp;&emsp;怎么安装 blast 什么的这里也不讲了，自己百度。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">makeblastdb -dbtype nucl -in Alternaria_sp.nr.re.cds -out Alternaria_sp.nr.re.cds<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-blastn-比对"><a href="#3-2-blastn-比对" class="headerlink" title="3.2 blastn 比对"></a>3.2 blastn 比对</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">blastn -query sample1.geno.fa -db Alternaria_sp.nr.re.cds -outfmt 6 -evalue 1e-10 -max_target_seqs 12 -num_threads 10 -out sample1.MAT.blasn<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果就两行：</p><blockquote><p>NODE_11_length_1128118_cov_18.265760 ADE44132.1<strong>MAT1-1-1 99.784 925 2 0 698132 699056 1170 246 0.0 1698<br>NODE_11_length_1128118_cov_18.265760 ADE44132.1</strong>MAT1-1-1 99.592 245 1 0 699104 699348 241.99e-125 448</p></blockquote><p>因为我们使用的是 mRNA 剪切过后的 CDS 序列，所以比上的区域有个大的 GAP。这里最好将<code>-max_target_seqs</code>设为你之前从 NCBI 上下载的总序列数，有可能会鉴定到两种交配型的情况，这种很罕见，但有，处理的时候注意。</p><p><strong>References</strong>:</p><p name = "ref1">https://wswxtb.ijournals.cn/html/wswxtbcn/2020/5/tb20051572.htm</p>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> Fungi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MSMC2-Tutorial</title>
      <link href="2023/06/29/msmc2-tutorial/"/>
      <url>2023/06/29/msmc2-tutorial/</url>
      
        <content type="html"><![CDATA[<h2 id="0-环境配置"><a href="#0-环境配置" class="headerlink" title="0. 环境配置"></a>0. 环境配置</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;git clone https:&#x2F;&#x2F;github.com&#x2F;stschiff&#x2F;msmc2.gitcd msmc2# dmdwget http:&#x2F;&#x2F;downloads.dlang.org&#x2F;releases&#x2F;2.x&#x2F;2.094.2&#x2F;dmd.2.094.2.linux.tar.xzxz -d dmd.2.094.2.linux.tar.xz ; tar -xvf dmd.2.094.2.linux.tarecho  &#39;export PATH&#x3D;&quot;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;dmd2&#x2F;linux&#x2F;bin64:$PATH&quot;&#39; &gt;&gt; ~&#x2F;.bashrcsource ~&#x2F;.bashrc# gslwget http:&#x2F;&#x2F;mirror.rit.edu&#x2F;gnu&#x2F;gsl&#x2F;gsl-2.6.tar.gztar -pzxvf gsl-2.6.tar.gzcd gsl-2.6.&#x2F;configure --prefix&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;gslmakemake installcd ..# make msmc2## 修改原始的SLDIR, 改成你安装的vi Makefile&#39;SLDIR&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;gsl&#x2F;lib&#39;make<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如出现错误:</p><blockquote><p>x86_64-conda-linux-gnu/lib/../lib64/libgcc_s.so.1: undefined reference to <code>memcpy@GLIBC_2.14&#39; collect2: error: ld returned 1 exit status Error: linker exited with status 1 make: *** [Makefile:20：build/release/msmc2] error1    退出conda环境再</code>make`</p></blockquote><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda deactivatemake# 下载配套工具git clone https:&#x2F;&#x2F;github.com&#x2F;stschiff&#x2F;msmc-tools.gitgit clone https:&#x2F;&#x2F;github.com&#x2F;jessicarick&#x2F;msmc2_scripts.git# mask filewget http:&#x2F;&#x2F;lh3lh3.users.sourceforge.net&#x2F;download&#x2F;seqbility-20091110.tar.bz2tar jxfv seqbility-20091110.tar.bz2cd seqbility-20091110makecd ..# 下载测试数据  手动下载&quot;https:&#x2F;&#x2F;share.eva.mpg.de&#x2F;index.php&#x2F;s&#x2F;swpTM4mNK7gG7nw&#x2F;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-测试-MSMC2"><a href="#1-测试-MSMC2" class="headerlink" title="1. 测试 MSMC2"></a>1. 测试 MSMC2</h2><h3 id="1-1-Generating-consensus-sequences-for-each-sample"><a href="#1-1-Generating-consensus-sequences-for-each-sample" class="headerlink" title="1.1 Generating consensus sequences for each sample"></a>1.1 Generating consensus sequences for each sample</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 把网页下载的数据拖到这里cd &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2 ; mkdir TEST_data ; cd TEST_dataunzip MSMC-tutorial-files.zip ; cd MSMC-tutorial-files<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>现在开始测试，一共 6 个样本。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p .&#x2F;CF_TRY&#x2F;consensus_callsMASTERVARDIR&#x3D;.&#x2F;cg_dataOUTDIR&#x3D;.&#x2F;CF_TRY&#x2F;consensus_callsCHR&#x3D;chr1for IND in NA19238 NA19239 NA19240 NA12878 NA12891 NA12892; do    MASTERVAR&#x3D;$(ls $MASTERVARDIR&#x2F;masterVarBeta-$IND-*.tsv.chr1.bz2)    OUT_MASK&#x3D;$OUTDIR&#x2F;$IND.$CHR.mask.bed.gz    OUT_VCF&#x3D;$OUTDIR&#x2F;$IND.$CHR.vcf.gz    &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools&#x2F;cgCaller.py $CHR $IND $OUT_MASK $MASTERVAR | gzip -c &gt; $OUT_VCFdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-2-Combining-samples"><a href="#1-2-Combining-samples" class="headerlink" title="1.2 Combining samples"></a>1.2 Combining samples</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p .&#x2F;CF_TRY&#x2F;msmc2_inputINDIR&#x3D;.&#x2F;CF_TRY&#x2F;consensus_callsOUTDIR&#x3D;.&#x2F;CF_TRY&#x2F;msmc2_inputMAPDIR&#x3D;.&#x2F;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools&#x2F;generate_multihetsep.py --chr 1 \    --mask $INDIR&#x2F;NA12878.chr1.mask.bed.gz --mask $INDIR&#x2F;NA12891.chr1.mask.bed.gz --mask $INDIR&#x2F;NA12892.chr1.mask.bed.gz \    --mask $INDIR&#x2F;NA19240.chr1.mask.bed.gz --mask $INDIR&#x2F;NA19238.chr1.mask.bed.gz --mask $INDIR&#x2F;NA19239.chr1.mask.bed.gz \    --mask $MAPDIR&#x2F;hs37d5_chr1.mask.bed --trio 0,1,2 --trio 3,4,5 \    $INDIR&#x2F;NA12878.chr1.vcf.gz $INDIR&#x2F;NA12891.chr1.vcf.gz $INDIR&#x2F;NA12892.chr1.vcf.gz \    $INDIR&#x2F;NA19240.chr1.vcf.gz $INDIR&#x2F;NA19238.chr1.vcf.gz $INDIR&#x2F;NA19239.chr1.vcf.gz \    &gt; $OUTDIR&#x2F;EUR_AFR.chr1.multihetsep.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-Estimating-the-effective-population-size"><a href="#1-3-Estimating-the-effective-population-size" class="headerlink" title="1.3 Estimating the effective population size"></a>1.3 Estimating the effective population size</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">INPUTDIR&#x3D;.&#x2F;CF_TRY&#x2F;msmc2_inputOUTDIR&#x3D;.&#x2F;CF_TRY&#x2F;msmc2_input&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;build&#x2F;release&#x2F;msmc2 -t 6 -p 1*2+15*1+1*2 -o $OUTDIR&#x2F;EUR.msmc2 -I 0,1,2,3 $INPUTDIR&#x2F;EUR_AFR.chr1.multihetsep.txt&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;build&#x2F;release&#x2F;msmc2 -t 6 -p 1*2+15*1+1*2 -o $OUTDIR&#x2F;AFR.msmc2 -I 4,5,6,7 $INPUTDIR&#x2F;EUR_AFR.chr1.multihetsep.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-4-结果可视化"><a href="#1-4-结果可视化" class="headerlink" title="1.4 结果可视化"></a>1.4 结果可视化</h3><p>结果是和官方文档一样的，这里只是简单记录下运行步骤和检查<code>msmc2</code>是否安装成功，具体步骤参阅官方文档。</p><pre class="line-numbers language-R" data-language="R"><code class="language-R">mu &lt;- 1.25e-8gen &lt;- 30afrDat&lt;-read.table(&quot;CF_TRY&#x2F;msmc2_input&#x2F;AFR.msmc2.final.txt&quot;, header&#x3D;TRUE)eurDat&lt;-read.table(&quot;CF_TRY&#x2F;msmc2_input&#x2F;EUR.msmc2.final.txt&quot;, header&#x3D;TRUE)plot(afrDat$left_time_boundary&#x2F;mu*gen, (1&#x2F;afrDat$lambda)&#x2F;(2*mu), log&#x3D;&quot;x&quot;,ylim&#x3D;c(0,100000),     type&#x3D;&quot;n&quot;, xlab&#x3D;&quot;Years ago&quot;, ylab&#x3D;&quot;effective population size&quot;)lines(afrDat$left_time_boundary&#x2F;mu*gen, (1&#x2F;afrDat$lambda)&#x2F;(2*mu), type&#x3D;&quot;s&quot;, col&#x3D;&quot;red&quot;)lines(eurDat$left_time_boundary&#x2F;mu*gen, (1&#x2F;eurDat$lambda)&#x2F;(2*mu), type&#x3D;&quot;s&quot;, col&#x3D;&quot;blue&quot;)legend(&quot;topright&quot;,legend&#x3D;c(&quot;African&quot;, &quot;European&quot;), col&#x3D;c(&quot;red&quot;, &quot;blue&quot;), lty&#x3D;c(1,1))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-实例"><a href="#2-实例" class="headerlink" title="2. 实例"></a>2. 实例</h2><h3 id="2-1-Generate-masked-file"><a href="#2-1-Generate-masked-file" class="headerlink" title="2.1 Generate masked-file"></a>2.1 Generate masked-file</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># work dircd &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;05.add_data&#x2F;02.GATK_pipeline&#x2F;07.population&#x2F;03.clean_sample&#x2F;00.population_structure&#x2F;03.MSMCmkdir TESTcd TEST<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过 snpable 生成 masked_genome, 主要使用 msmc2_scripts 的脚本<sup><a href="#ref3">3</a></sup>。<br>对原始的<code>run_snpable2.sh</code>文件稍微进行调整。<br>确保已经安装以下软件(且在 PATH 里):</p><ul><li>gcc</li><li>samtools</li><li>bcftools</li><li>vcftools</li><li>bwa</li><li>python</li></ul><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>00.make_masked.sh</span></div><code class="language-shell">#!&#x2F;bin&#x2F;shMSMCTOOLS&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools # folder with msmc-tools binariesPATH&#x3D;$PATH:$MSMCTOOLSOUTDIR&#x3D;&#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;05.add_data&#x2F;02.GATK_pipeline&#x2F;07.population&#x2F;03.clean_sample&#x2F;00.population_structure&#x2F;03.MSMC&#x2F;TEST&#x2F;00.Masked_geno # main directory for output files# for msmc_1_call.shGENOME&#x3D;&#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;02.vcf_anno&#x2F;Alternaria_Alternata_Z7_genomic.fna # reference genome fastaprefix&#x3D;Z7_Masked # prefix of genome masksk&#x3D;35scriptdir&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc2_scriptssnpable_script_path&#x3D;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;seqbility-20091110 # directory with snpable scriptsPATH&#x3D;$PATH:$snpable_script_pathmkdir $&#123;OUTDIR&#125;&#x2F;snpablecd $&#123;OUTDIR&#125;&#x2F;snpableecho &quot;Starting extraction of overlapping $&#123;k&#125;-mer subsequences&quot;splitfa $GENOME $k | split -l 20000000cat x* &gt;&gt; $&#123;prefix&#125;_split.$k# if it can&#39;t find splitfa, try adding seqbility to the path using &#39;PATH&#x3D;$PATH:&#x2F;project&#x2F;WagnerLab&#x2F;jrick&#x2F;msmc_Sept2017&#x2F;snpable&#x2F;scripts&#39;echo &quot;Aligning $&#123;k&#125;-mer reads to the genome with BWA, then converting to sam file&quot;# the genome needs to be indexed prior to this step-- if it has not already been indexed, run:if [ -f &quot;$&#123;GENOME&#125;.bwt&quot; ]; thenecho &quot;$GENOME already indexed&quot;elseecho &quot;indexing $GENOME&quot;bwa index $GENOMEfiecho &quot;aligning reads to genome with BWA and converting to sam&quot;bwa aln -t 8 -R 1000000 -O 3 -E 3 $&#123;GENOME&#125; $&#123;prefix&#125;_split.$&#123;k&#125; &gt; $&#123;prefix&#125;_split.$&#123;k&#125;.saibwa samse -f $&#123;prefix&#125;_split.$&#123;k&#125;.sam $GENOME $&#123;prefix&#125;_split.$&#123;k&#125;.sai $&#123;prefix&#125;_split.$&#123;k&#125;echo &quot;reads aligned, starting to generate rawMask&quot;gen_raw_mask.pl $&#123;prefix&#125;_split.$&#123;k&#125;.sam &gt; $&#123;prefix&#125;_rawMask.$&#123;k&#125;.faecho &quot;raw mask created as $&#123;prefix&#125;_rawMask.35.fa, now generating final mask with stringency r&#x3D;50%&quot;gen_mask -l $&#123;k&#125; -r 0.5 $&#123;prefix&#125;_rawMask.$&#123;k&#125;.fa &gt; $&#123;prefix&#125;_mask.$&#123;k&#125;.50.faecho &quot;all done! final mask saved as $&#123;prefix&#125;_mask.$&#123;k&#125;.50.fa&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>成功运行后使用<code>makeMappabilityMask.py</code>得到每条染色体最终的 mask 文件。可能是 gzip 的版本不对，我在运行脚本的时候报错，这个时候直接去掉 gzip 的相关操作，最后对结果文件进行 gzip 压缩就行。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 修改makeMappabilityMask.py默认的输入输出vi &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools&#x2F;makeMappabilityMask.pypython &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools&#x2F;makeMappabilityMask.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="2-2-make-vcf-file-of-each-chr-of-each-sample"><a href="#2-2-make-vcf-file-of-each-chr-of-each-sample" class="headerlink" title="2.2 make vcf-file of each chr of each sample"></a>2.2 make vcf-file of each chr of each sample</h3><p>准备工作：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir 01.vcf_bed# 只保留常染色体less &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;02.vcf_anno&#x2F;Alternaria_Alternata_Z7_genomic.fna | grep \&gt; | cut -d &#39; &#39; -f 1 | cut -d &#39;&gt;&#39; -f 2 | sort | head -n 10 &gt; Chr.lst<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>我们这里挑选 8 个样本进行分析。手动生成一个<code>sample.lst</code>，每个样本一行。我们小小的修改下<code>bamCaller.py</code>的内容，让它适用于单倍体。并对结果文件<code>*vcf.gz</code>进行基因型的<code>Double</code>。</p><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>bamCaller_sample.sh</span></div><code class="language-shell">sample_ID&#x3D;$1OUD&#x3D;$2if [ -d &quot;$&#123;OUD&#125;&quot; ]; then    echo &quot;&quot;else    mkdir $&#123;OUD&#125;firefs&#x3D;&#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;02.vcf_anno&#x2F;Alternaria_Alternata_Z7_genomic.fnabam_file&#x3D;&#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;05.add_data&#x2F;02.GATK_pipeline&#x2F;01.alignment_bam&#x2F;$&#123;sample_ID&#125;.sorted.marked.bam# 这里我用的是平均测序深度depth&#x3D;30# build index for bamif [ -f &quot;$&#123;bam_file&#125;.bai&quot; ]; thenecho &quot;$bam_file already indexed&quot;elseecho &quot;indexing $bam_file&quot;samtools index $&#123;bam_file&#125;fi# bamCaller.py 只能处理单条染色体[ -e &#x2F;tmp&#x2F;zwy ] || mkfifo &#x2F;tmp&#x2F;zwyexec 3&lt;&gt;&#x2F;tmp&#x2F;zwyrm -rf &#x2F;tmp&#x2F;zwyfor ((i&#x3D;1;i&lt;&#x3D;5;i++))do echo &gt;&amp;3donecat &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;05.add_data&#x2F;02.GATK_pipeline&#x2F;07.population&#x2F;03.clean_sample&#x2F;00.population_structure&#x2F;03.MSMC&#x2F;TEST&#x2F;Chr.lst | while read chrdoread -u3&#123;    samtools mpileup -q 20 -Q 20 -C 50 -u  -r $&#123;chr&#125; -f $&#123;refs&#125; $&#123;bam_file&#125; | bcftools call -c -V indels --ploidy 1 | &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools&#x2F;bamCaller.py $&#123;depth&#125; $&#123;OUD&#125;&#x2F;$&#123;sample_ID&#125;.$&#123;chr&#125;.mask.bed.gz | gzip -c &gt; $&#123;OUD&#125;&#x2F;$&#123;sample_ID&#125;.$&#123;chr&#125;.vcf.gz    python &#x2F;data&#x2F;chaofan&#x2F;projects&#x2F;06.daily&#x2F;06.yelu&#x2F;05.add_data&#x2F;02.GATK_pipeline&#x2F;07.population&#x2F;03.clean_sample&#x2F;00.population_structure&#x2F;03.MSMC&#x2F;TEST&#x2F;00.double_haploid_vcf.py $&#123;OUD&#125;&#x2F;$&#123;sample_ID&#125;.$&#123;chr&#125;.vcf.gz | bgzip -c &gt; $&#123;OUD&#125;&#x2F;$&#123;sample_ID&#125;.$&#123;chr&#125;.d.vcf.gz echo &gt;&amp;3&#125;&amp;donewait<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-Combining-samples"><a href="#2-3-Combining-samples" class="headerlink" title="2.3 Combining samples"></a>2.3 Combining samples</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># mkdir 02.merge_resINDIR&#x3D;.&#x2F;01.vcf_bedOUTDIR&#x3D;.&#x2F;02.merge_resMAPDIR&#x3D;.&#x2F;01.vcf_bedcat Chr.lst | while read Chrdo&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;msmc-tools&#x2F;generate_multihetsep.py --chr $&#123;Chr&#125; \    --mask $INDIR&#x2F;CCA047.$&#123;Chr&#125;.mask.bed.gz --mask $INDIR&#x2F;CCA133.$&#123;Chr&#125;.mask.bed.gz --mask $INDIR&#x2F;CCA205.$&#123;Chr&#125;.mask.bed.gz \    --mask $INDIR&#x2F;CCA206.$&#123;Chr&#125;.mask.bed.gz --mask $INDIR&#x2F;CCA210.$&#123;Chr&#125;.mask.bed.gz --mask $INDIR&#x2F;CCA215.$&#123;Chr&#125;.mask.bed.gz \    --mask $INDIR&#x2F;CCA298.$&#123;Chr&#125;.mask.bed.gz --mask $INDIR&#x2F;CCA560.$&#123;Chr&#125;.mask.bed.gz --mask 00.Masked_geno&#x2F;Z7_$&#123;Chr&#125;.mask.bed.gz \    &#96;ls $&#123;MAPDIR&#125;&#x2F;*.$&#123;Chr&#125;.d.vcf.gz&#96; &gt; $OUTDIR&#x2F;Clade3.$&#123;Chr&#125;.multihetsep.txt &amp;done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-4-running-MSMC2"><a href="#2-4-running-MSMC2" class="headerlink" title="2.4 running MSMC2"></a>2.4 running MSMC2</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;msmc2&#x2F;build&#x2F;release&#x2F;msmc2 -t 30 -p 1*2+15*1+1*2 -o 02.merge_res&#x2F;Clade3.msmc2 02.merge_res&#x2F;Clade3.*.multihetsep.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>References</strong>:</p><p name = "ref1">https://blog.csdn.net/weixin_45694863/article/details/126812038</p><p name = "ref2">https://github.com/stschiff/msmc-tools/blob/master/msmc-tutorial/guide.md</p><p name = "ref3">https://github.com/jessicarick/msmc2_scripts/blob/master/run_snpable2.sh</p>]]></content>
      
      
      
        <tags>
            
            <tag> population genetics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Genomic Evolutionary Rate Profiling(GERP)</title>
      <link href="2023/06/11/genomic-evolutionary-rate-profiling-gerp/"/>
      <url>2023/06/11/genomic-evolutionary-rate-profiling-gerp/</url>
      
        <content type="html"><![CDATA[<p>用来简单记录下GERP的过程，方便后续再次使用。</p><h3 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 下载cactus## 一般在自己本地的soft文件夹下进行wget https:&#x2F;&#x2F;github.com&#x2F;ComparativeGenomicsToolkit&#x2F;cactus&#x2F;releases&#x2F;download&#x2F;v2.5.2&#x2F;cactus-bin-v2.5.2.tar.gztar -xzf cactus-bin-v2.5.2.tar.gzcd cactus-bin-v2.5.2pip install virtualenvvirtualenv -p python3 cactus_envecho &quot;export PATH&#x3D;$(pwd)&#x2F;bin:\$PATH&quot; &gt;&gt; cactus_env&#x2F;bin&#x2F;activateecho &quot;export PYTHONPATH&#x3D;$(pwd)&#x2F;lib:\$PYTHONPATH&quot; &gt;&gt; cactus_env&#x2F;bin&#x2F;activatesource cactus_env&#x2F;bin&#x2F;activatepython3 -m pip install -U setuptools pippython3 -m pip install -U .python3 -m pip install -U -r .&#x2F;toil-requirement.txtcd bin &amp;&amp; for i in wigToBigWig faToTwoBit bedToBigBed bigBedToBed axtChain pslPosTarget bedSort hgGcPercent mafToBigMaf hgLoadMafSummary; do wget -q http:&#x2F;&#x2F;hgdownload.cse.ucsc.edu&#x2F;admin&#x2F;exe&#x2F;linux.x86_64&#x2F;$&#123;i&#125;; chmod +x $&#123;i&#125;; done## 按照上面的流程下载 cactus一般是不太会有其他问题的# 下载 mashtreegit clone https:&#x2F;&#x2F;github.com&#x2F;lskatz&#x2F;mashtree.git# 下载UCSC工具包## 把这个页面http:&#x2F;&#x2F;hgdownload.cse.ucsc.edu&#x2F;admin&#x2F;exe&#x2F;linux.x86_64&#x2F;上所有的文件下下来，后面有些要用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-获得物种树"><a href="#2-获得物种树" class="headerlink" title="2. 获得物种树"></a>2. 获得物种树</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mashtree --mindepth 0 --numcpus 12 *.fa &gt; mashtree.dnd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-全基因组比对"><a href="#3-全基因组比对" class="headerlink" title="3. 全基因组比对"></a>3. 全基因组比对</h3><p>这个主要使用<a href="https://github.com/ComparativeGenomicsToolkit/cactus/blob/master/doc/progressive.md">Progressive Cactus</a>做。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 构建 cactus的输入文件## species.cacuts.txt第一行则为上一步构建的mashtree。## 后面的行分为两列，用空格隔开，第一列为基因组名称(可以是物种名或自己取的名字)## 第二列则基因组序列地址(基因组序列必须是softmasked的) # 这里一定一定要注意 你的基因组文件名称必须和物种树的名称一致，比如物种树里是 Camellia_sinensis， 那么最好基因组文件名称是 Camellia_sinensis.facactus .&#x2F;js species.cacuts.txt species.hal# hal2maf## refname则是你选择的一个参考基因组，名称必须与 species.cacuts.txt 内的一致$refname&#x3D;&quot;refname&quot;cactus-hal2maf .&#x2F;js species.hal species.maf.gz --refGenome $refname --chunkSize 1000000 --noAncestors --dupeMode single# 可以过滤一下，我们这里是cactus的结果，先不过滤## filter mafs so all blocks have refs and are at least 20 bp longgzip -d species.maf.gzmafFilter -minCol&#x3D;20 -needComp&#x3D;&quot;$refname&quot; species.maf &gt; species.filter.maf## maf文件格式: https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;963e3c5dcc80<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-1-获得MSA-全基因组范围-文件"><a href="#3-1-获得MSA-全基因组范围-文件" class="headerlink" title="3.1 获得MSA(全基因组范围)文件"></a>3.1 获得MSA(全基因组范围)文件</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 生成一个空的dummy.bed文件touch dummy.bed # 将maf文件按染色体拆分mafSplit -byTarget dummy.bed .&#x2F; species.maf -useFullSequenceNamepython maf2fasta.mutil.py -i $each_chr_maf --order species.order -r refs.genome.fa -o $ouf_prefix -c cup_nums<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-2-提取4DTV位点"><a href="#3-2-提取4DTV位点" class="headerlink" title="3.2 提取4DTV位点"></a>3.2 提取4DTV位点</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 提取refs 4DTV位点iTools Gfftools getCdsPep -Ref ref.genome.fa -Gff ref.gff -OutPut ouf_name -4DSite<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这里我们有两种处理顺序，一种是利用上面的whole genome alignment[maf -&gt; fasta])，再根据这个比对结果提取4DTV位点(如果MSA文件是非必须的，推荐第二种方法)。 另外一种更为直接，直接从maf结果中提取4DTV位点序列。<br>我们直接用后面的方法。脚本写了一上午，检查了一下午，就不放出来了(也可以使用玉米NAM群体<sup><a href="#ref3">3</a></sup>的R脚本)。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">gzip -d ouf_name.4Dsite.gz# maf24DTV 这里生成各染色体文件.&#x2F;maf24DTV.py -i species.maf --order species.order -s ouf_name.4Dsite -o ouf_prefix -r ref.genome.fa# 将上一步提取各染色体的4DTV位点合并到一起.&#x2F;fasta_merge_chr.py -i ouf_prefix* -o species.merge.4DTV.fa# 构建中性进化树iqtree -s species.merge.4DTV.fa -st DNA -T 60 -mem 200G  -bb 1000 --prefix species.merge.4DTV.fa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-计算GERP数值"><a href="#4-计算GERP数值" class="headerlink" title="4. 计算GERP数值"></a>4. 计算GERP数值</h3><p>GERP的范围和你进化树的枝长与比较的物种数量都是有关系的，注意。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 这里msa的header和 $&#123;REF&#125;都要和系统发育树中的ID 对应，这里我分染色体跑gerpcol -t species.merge.4DTV.fa.treefile -f $&#123;msa_fasta&#125; -a -e $&#123;REF&#125; -j -v -z -x .gerp.ratesgerpelem -f $&#123;msa_fasta&#125;.gerp.rates<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>References</strong>:</p><p name = "ref1">https://doi.org/10.1016/j.cell.2023.04.008</p><p name = "ref2">https://github.com/ComparativeGenomicsToolkit/cactus</p><p name = "ref3">https://github.com/HuffordLab/NAM-genomes/tree/master/gerp</p>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>population_items</title>
      <link href="2023/05/24/population-items/"/>
      <url>2023/05/24/population-items/</url>
      
        <content type="html"><![CDATA[<h1 id="群体遗传学概念"><a href="#群体遗传学概念" class="headerlink" title="群体遗传学概念"></a>群体遗传学概念</h1><p>我的记忆力实在是太差了(金鱼?.?)，为了更深一步的巩固自己的记忆，加深一些概念的理解，固有此。<br><font color="red">本人能力有限，如理解有问题恳请及时纠正！</font></p><h3 id="1-π-pi-核苷酸多样性"><a href="#1-π-pi-核苷酸多样性" class="headerlink" title="1. π (pi) 核苷酸多样性"></a>1. π (pi) 核苷酸多样性</h3><p>用来衡量核苷酸多样性的大小，越大，说明群体多样性越高。目前主要有两种计算π的方法(只考虑biallelic sites： 群体在这个位点只存在两种核苷酸)：</p><p>1.分离位点(群体在这个位点存在&gt;=两个核苷酸)的位点杂合度之和：</p><blockquote><p>$$ π = \sum_{1}^Sh_j  $$<br>其中S为分离位点的个数，而$h_j$则是不同位点杂合度:<br>$$ h_j = \frac{n}{n-1}(1-\sum p^2_i)$$<br>$p_i$指的是不同核苷酸出现概率，二等分位点只存在两种情况。n指的样本数量。</p></blockquote><p>2.任意两条序列之间核苷酸差异的平均位点数:</p><blockquote><p>$$ π = \frac {\sum_{i&lt;k}k_{ij}}{n(n-1)/2}</p></blockquote><p>光看公式没什么感觉，手动算一下吧： </p><p><a href="https://imgse.com/i/p97TxXR"><img src="https://s1.ax1x.com/2023/05/24/p97TxXR.png" alt="p97TxXR.png"></a> </p><p>假设这里包含四个样本，一共15个位点的比对结果。</p><p>如果用<strong>第一种方法</strong>的话，这15个位点中包含6个分离位点： 2 5 8 11 13 15。由$h_j$的计算公式得：<br>$$<br>    π =  h_2 + h_5 + h_8 + h_{11} + h_{13} + h_{15}<br>    \ = \frac {4}{3}(1-\frac{1}{4}^2 - \frac{3}{4}^2) + \frac {4}{3}(1-\frac{1}{2}^2 - \frac{1}{2}^2) + \frac {4}{3}(1-\frac{1}{4}^2 - \frac{3}{4}^2)+  \frac {4}{3}(1-\frac{1}{2}^2 - \frac{1}{2}^2) + \frac {4}{3}(1-\frac{1}{4}^2 - \frac{3}{4}^2) + \frac {4}{3}(1-\frac{1}{4}^2 - \frac{3}{4}^2) \ =0.5 + 0.667 + 0.5 + 0.667 + 0.5 + 0.5 \ = 3.33<br>$$</p><p>如果用<strong>第二种方法</strong>，我们这里一共有4个样本(4条序列)，从这4条序列中抽取2条序列，一共有$C^2_4=6$种情况，这种情况下,这两种方法的π是一致的。<br>$$<br>    π = (3 + 4 + 3 + 5 + 0 + 5) / 6 = 3.33<br>$$<br>在一般的分析中，我们通常算的是每一个窗口(通常5kbp、10kbp和50kbp)的平均π值，所以这里的每核苷酸$π=\frac {3.33}{15}=0.222$。在全基因水平上，通常使用第一种方法计算，第二种方法太耗时($C^2_n*w$ n:样本数 $w$:位点数目)。</p><p>References:</p><blockquote><p>Tajima F. Statistical analysis of DNA polymorphism. Jpn J Genet. 1993 Dec;68(6):567-95. doi: 10.1266/jjg.68.567. PMID: 8031577.</p></blockquote><h3 id="2-搭便车效应-Hitchhiking-Effect"><a href="#2-搭便车效应-Hitchhiking-Effect" class="headerlink" title="2. 搭便车效应(Hitchhiking Effect)"></a>2. 搭便车效应(Hitchhiking Effect)</h3><p>一个有利突变在正向选择的作用下会迅速增加其在群体内的频率，同时因为连锁不平衡，会导致离他物理位置很近的一些基因型的频率也提高了。<br>这会造成所谓的”选择扫荡”，这里简单的考虑两种情况：Hard sweeps和Soft sweeps。</p><ol><li>Hard sweeps:<br>如图A所示，当群体中某个样本突然产生了一个对环境非常有利的突变，因为正向选择作用，这个突变位点+和它连锁的位点在群体内会迅速fixed，形成单一的haplotype。   </li><li>Soft sweeps：如图B所示，可能是由于环境的突然变化，导致群体中已经存在的某个有利基因型被迅速fixed，但因为这个有利基因型已经存在于不同的haplotype block里面了。所以最后这个区域可能只存在具有这个有利基因型的haplotype了(图中2种)。</li></ol><p>选择扫荡会大大降低群体核苷酸的多样性，驯化的人为选择也会导致选择扫荡的产生，我们通过找到这些选择扫荡区域，就有可能找到一些与重要驯化农艺性状相关的基因。<br><a href="https://imgse.com/i/p97L7Jf"><img src="https://s1.ax1x.com/2023/05/24/p97L7Jf.png" alt="p97L7Jf.png"></a></p><h3 id="3-连锁不平衡-Linkage-Disequilibrium"><a href="#3-连锁不平衡-Linkage-Disequilibrium" class="headerlink" title="3. 连锁不平衡(Linkage Disequilibrium)"></a>3. 连锁不平衡(Linkage Disequilibrium)</h3><h3 id="4-重组交换-Recombination"><a href="#4-重组交换-Recombination" class="headerlink" title="4. 重组交换(Recombination)"></a>4. 重组交换(Recombination)</h3><p>References:</p><h3 id="4-ROH-runs-of-homozygosity"><a href="#4-ROH-runs-of-homozygosity" class="headerlink" title="4.ROH (runs of homozygosity)"></a>4.ROH (runs of homozygosity)</h3><h3 id="6-群体分化系数-Fst"><a href="#6-群体分化系数-Fst" class="headerlink" title="6. 群体分化系数(Fst)"></a>6. 群体分化系数(Fst)</h3>]]></content>
      
      
      
        <tags>
            
            <tag> population genetics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>basicMathematicalOperations</title>
      <link href="2023/05/18/basicmathematicaloperations/"/>
      <url>2023/05/18/basicmathematicaloperations/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章-基本数学运算"><a href="#第二章-基本数学运算" class="headerlink" title="第二章 基本数学运算"></a>第二章 基本数学运算</h1><h3 id="第一讲"><a href="#第一讲" class="headerlink" title="第一讲"></a>第一讲</h3><p>简单的介绍了numpy的一些常用的属性和使用matplot绘制曲线图、修改曲线的类型、添加图例lable和更改x|y轴坐标等。<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html">详细参数说明</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> csvplt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"font.sans-serif"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"SimHei"</span><span class="token punctuation">]</span> <span class="token comment"># 中文</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"axes.unicode_minus"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>q0 <span class="token operator">=</span> <span class="token number">10</span>R <span class="token operator">=</span> <span class="token number">60</span>C <span class="token operator">=</span> <span class="token number">0.00005</span>t <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>linestyle <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"-"</span><span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> <span class="token string">"--"</span><span class="token punctuation">,</span> <span class="token string">"-."</span><span class="token punctuation">]</span>qt_Data <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token keyword">for</span> L<span class="token punctuation">,</span>line <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> linestyle<span class="token punctuation">)</span><span class="token punctuation">:</span>    qt <span class="token operator">=</span> q0 <span class="token operator">*</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>R<span class="token operator">*</span>t<span class="token operator">/</span><span class="token number">2</span><span class="token operator">/</span>L<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>L<span class="token operator">/</span>C <span class="token operator">-</span> <span class="token punctuation">(</span>R<span class="token operator">/</span><span class="token number">2</span><span class="token operator">/</span>L<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">*</span>t<span class="token punctuation">)</span>    qt_Data<span class="token punctuation">[</span><span class="token string">"L="</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> qt    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t<span class="token punctuation">,</span> qt<span class="token punctuation">,</span> ls<span class="token operator">=</span>line<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"L = "</span><span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"电量随时间变化的曲线"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"t/s"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"q(t)"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"qt_data.csv"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> newline<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>    writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> qt_Data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        writer<span class="token punctuation">.</span>writerows<span class="token punctuation">(</span><span class="token punctuation">[</span>value<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="第二讲"><a href="#第二讲" class="headerlink" title="第二讲"></a>第二讲</h3><p>这是另外一个类似的例子，绘制概率密度函数，主要是分段函数的写法。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"font.sans-serif"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"SimHei"</span><span class="token punctuation">]</span> <span class="token comment"># 中文</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"axes.unicode_minus"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.04</span><span class="token punctuation">)</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0.04</span><span class="token punctuation">)</span><span class="token comment"># 根据x和y生成网格点</span><span class="token punctuation">[</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>PXY <span class="token operator">=</span> <span class="token number">0.5457</span><span class="token operator">*</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token operator">*</span>Y<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">3.75</span><span class="token operator">*</span>X<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">1.5</span><span class="token operator">*</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>X<span class="token operator">+</span>Y<span class="token operator">></span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> \    <span class="token number">0.7575</span><span class="token operator">*</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>Y<span class="token operator">**</span><span class="token number">2</span><span class="token operator">-</span><span class="token number">6</span><span class="token operator">*</span>X<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span> X<span class="token operator">+</span>Y<span class="token operator">&lt;=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>  <span class="token punctuation">(</span>X<span class="token operator">+</span>Y <span class="token operator">></span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> \    <span class="token number">0.5457</span><span class="token operator">*</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token operator">*</span>Y<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">3.75</span><span class="token operator">*</span>X<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1.5</span><span class="token operator">*</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>X<span class="token operator">+</span>Y <span class="token operator">&lt;=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span>projection <span class="token operator">=</span> <span class="token string">"3d"</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>plot_surface<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> PXY<span class="token punctuation">,</span> cmap<span class="token operator">=</span> <span class="token string">"rainbow"</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"X"</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">"Y"</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_zlabel<span class="token punctuation">(</span><span class="token string">"Z"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> python_advance </tag>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fungiNanoAssemble</title>
      <link href="2023/05/05/funginanoassemble/"/>
      <url>2023/05/05/funginanoassemble/</url>
      
        <content type="html"><![CDATA[<h2 id="这是一个交链孢霉属物种三代Nano数据基因组组装注释流程"><a href="#这是一个交链孢霉属物种三代Nano数据基因组组装注释流程" class="headerlink" title="这是一个交链孢霉属物种三代Nano数据基因组组装注释流程"></a>这是一个交链孢霉属物种三代Nano数据基因组组装注释流程</h2><p>这篇博客基于前面那个二代数据组装注释的博客，所以很多细节直接省略了，这里只是简单记录三代Nano数据的组装过程。</p><h3 id="0-环境准备"><a href="#0-环境准备" class="headerlink" title="0.环境准备"></a>0.环境准备</h3><p>环境准备是最头疼的过程。后面再看有没有时间单独讲一下<a href="https://github.com/CompSynBioLab-KoreaUniv/FunGAP">FunGAP</a>的环境配置。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda install NanoFilt -c biocondagit clone https:&#x2F;&#x2F;github.com&#x2F;Nextomics&#x2F;NextDenovo.gitpip install paralleltaskcd NextDenovo &amp;&amp; makewget https:&#x2F;&#x2F;github.com&#x2F;broadinstitute&#x2F;pilon&#x2F;releases&#x2F;download&#x2F;v1.24&#x2F;pilon-1.24.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-原始数据的质控"><a href="#1-原始数据的质控" class="headerlink" title="1.原始数据的质控"></a>1.原始数据的质控</h3>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> Assemble </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Newton_iterative</title>
      <link href="2023/04/15/newton-iterative/"/>
      <url>2023/04/15/newton-iterative/</url>
      
        <content type="html"><![CDATA[<h3 id="0-背景"><a href="#0-背景" class="headerlink" title="0.背景"></a>0.背景</h3><p>惊讶的发现，在过去的一年里，我的python编程技巧几乎没有进步。为了提高编程能力和拥抱AI时代，有必要加强python在真正的数值分析方面的能力，因此开始学习<a href="https://www.bilibili.com/video/BV1uv411s7Wj/">鸣凤老师的课程</a></p><p>第一节课主要讲解了<a href="https://www.zhihu.com/question/20690553">牛顿迭代法求根</a>的python实现，我们这里把实现的代码记录下来，方便后续的复习(本人记忆太差了)。</p><ul><li>函数在整个定义域内最好是二阶可导的</li><li>起始点对求根计算影响重大，可以增加一些别的判断手段进行试错</li></ul><h3 id="1-代码实现"><a href="#1-代码实现" class="headerlink" title="1. 代码实现"></a>1. 代码实现</h3><pre class="line-numbers language-python" data-language="python"><div class="caption"><span>python_advance_0001.py</span></div><code class="language-python"><span class="token comment">#!/usr/bin/env python</span><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token punctuation">,</span> exit<span class="token keyword">from</span> sympy <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">def</span> <span class="token function">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Equation of expression"""</span>    x <span class="token operator">=</span> symbols<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> x<span class="token operator">*</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token operator">*</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.25</span><span class="token keyword">def</span> <span class="token function">diff_function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""The first derivative"""</span>    <span class="token keyword">return</span> function<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>diff<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">Newton_iterative</span><span class="token punctuation">(</span>x0<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> maxiter<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Newton_iterative"""</span>    x <span class="token operator">=</span> symnols<span class="token punctuation">(</span><span class="token string">"x"</span><span class="token punctuation">)</span>    fh <span class="token operator">=</span> function<span class="token punctuation">(</span><span class="token punctuation">)</span>    dfh <span class="token operator">=</span> diff_function<span class="token punctuation">(</span><span class="token punctuation">)</span>    x_n <span class="token operator">=</span> x0    <span class="token comment"># output header</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%5s %25s %25s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token string">"Iter"</span><span class="token punctuation">,</span> <span class="token string">"Approximate_Solution"</span><span class="token punctuation">,</span> <span class="token string">"Error_Rate"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    k <span class="token operator">=</span> <span class="token number">0</span>    errval <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>maxiter<span class="token punctuation">)</span><span class="token punctuation">:</span>        x_b <span class="token operator">=</span> x_n        fx <span class="token operator">=</span> fh<span class="token punctuation">.</span>evalf<span class="token punctuation">(</span>subs <span class="token operator">=</span> <span class="token punctuation">&#123;</span>x <span class="token punctuation">:</span> x_b<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        dfx <span class="token operator">=</span> dfh<span class="token punctuation">.</span>evalf<span class="token punctuation">(</span>subs <span class="token operator">=</span> <span class="token punctuation">&#123;</span>x <span class="token punctuation">:</span> x_b<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        x_n <span class="token operator">=</span> x_b <span class="token operator">-</span> fx<span class="token operator">/</span>dfx        <span class="token comment"># 这里注意，求根嘛 看当前y值与X轴的差异</span>        errval <span class="token operator">=</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>fh<span class="token punctuation">.</span>evalf<span class="token punctuation">(</span>subs <span class="token operator">=</span> <span class="token punctuation">&#123;</span>x<span class="token punctuation">:</span> x_n<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%5d %25.15f %25.15f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> x_n<span class="token punctuation">,</span> errval<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> errval <span class="token operator">&lt;=</span> eps<span class="token punctuation">:</span>            <span class="token keyword">break</span>        <span class="token keyword">if</span> k<span class="token operator">+</span><span class="token number">1</span> <span class="token operator">&lt;=</span> maxiter<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Under the accuracy:</span><span class="token interpolation"><span class="token punctuation">&#123;</span>eps<span class="token punctuation">&#125;</span></span><span class="token string">, the approximate solution of the equation"</span></span><span class="token operator">+</span>             <span class="token string-interpolation"><span class="token string">f" is </span><span class="token interpolation"><span class="token punctuation">&#123;</span>x_n<span class="token punctuation">&#125;</span></span><span class="token string"> and the error rate is </span><span class="token interpolation"><span class="token punctuation">&#123;</span>errval<span class="token punctuation">&#125;</span></span><span class="token string">."</span></span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"The maximum number of iterations is exceeded, convergence may not occur!"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token boolean">None</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>argv<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">:</span>        exit<span class="token punctuation">(</span><span class="token string">"Usage: python python_advance_0001.py [initial_x] [accuracy_requirement] [iter_count]"</span><span class="token punctuation">)</span>    Newton_iterative<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> python_advance </tag>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fungiGenomeAssembleAnnotataion</title>
      <link href="2023/03/26/fungigenomeassembleannotation/"/>
      <url>2023/03/26/fungigenomeassembleannotation/</url>
      
        <content type="html"><![CDATA[<h2 id="这是一个交链孢霉属物种二代数据基因组组装注释流程"><a href="#这是一个交链孢霉属物种二代数据基因组组装注释流程" class="headerlink" title="这是一个交链孢霉属物种二代数据基因组组装注释流程"></a>这是一个交链孢霉属物种二代数据基因组组装注释流程</h2><h3 id="0-环境准备"><a href="#0-环境准备" class="headerlink" title="0.环境准备"></a>0.环境准备</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n genome_assembleconda activate genome_assembleconda install fastqc fastuniq bwa kmergenie jellyfish quast -y -c bioconda# 进入到自己的软件文件夹，没有就新建一个: mkdir softwarecd softwarewget https:&#x2F;&#x2F;ftp-trace.ncbi.nlm.nih.gov&#x2F;sra&#x2F;sdk&#x2F;3.0.2&#x2F;sratoolkit.2.11.1-centos_linux64.tar.gztar -xvzf sratoolkit.2.11.1-centos_linux64.tar.gzwget http:&#x2F;&#x2F;cab.spbu.ru&#x2F;files&#x2F;release3.15.5&#x2F;SPAdes-3.15.5-Linux.tar.gztar -xvzf SPAdes-3.15.5-Linux.tar.gzwget http:&#x2F;&#x2F;www.usadellab.org&#x2F;cms&#x2F;uploads&#x2F;supplementary&#x2F;Trimmomatic&#x2F;Trimmomatic-0.39.zipunzip Trimmomatic-0.39.zip# 下载interproscanwget https:&#x2F;&#x2F;ftp.ebi.ac.uk&#x2F;pub&#x2F;software&#x2F;unix&#x2F;iprscan&#x2F;5&#x2F;5.61-93.0&#x2F;interproscan-5.61-93.0-64-bit.tar.gztar -zxvf interproscan-5.61-93.0-64-bit.tar.gz# 加入环境变量export PATH&#x3D;&quot;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;sratoolkit.2.11.1-centos_linux64&#x2F;bin:$PATH&quot;export PATH&#x3D;&quot;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;SPAdes-3.15.5-Linux&#x2F;bin:$PATH&quot;export PATH&#x3D;&quot;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;interproscan-5.61-93.0:$PATH&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-下载数据"><a href="#1-下载数据" class="headerlink" title="1.下载数据"></a>1.下载数据</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 设置你自己的工作路径，把数据什么的都放在单独的一个工作路径workdir&#x3D;&#x2F;data&#x2F;pipelines&#x2F;01.Gene_anno&#x2F;01.genome_assemble&#x2F;01.Alternaria_spcd $workdirmkdir 00.raw_data &amp;&amp; cd 00.raw_datanohup prefetch SRR16888499 -O .&#x2F; &amp;  # RNA-seqnohup prefetch SRR16914355 -O .&#x2F; &amp;  # WGS(Whole Genome Sequencing)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-质控"><a href="#2-质控" class="headerlink" title="2.质控"></a>2.质控</h3><h4 id="2-1-sra2fastq"><a href="#2-1-sra2fastq" class="headerlink" title="2.1 sra2fastq"></a>2.1 sra2fastq</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">fastq-dump --split-3 SRR16888499&#x2F;SRR16888499.sra &amp;fastq-dump --split-3 SRR16914355&#x2F;SRR16914355.sra &amp;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="2-2-raw-fastqc"><a href="#2-2-raw-fastqc" class="headerlink" title="2.2 raw_fastqc"></a>2.2 raw_fastqc</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">fastqc  SRR16888499_1.fastq SRR16888499_2.fastq SRR16914355_1.fastq SRR16914355_2.fastq -t 4 -o .&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个是SRR16888499(RNA-seq)的测序质量值和接头报告，我们发现这个质量是非常不错的，但还是使用Trimmomatic对raw_reads进行过滤。<br><a href="https://imgse.com/i/ppCm9te"><img src="https://s1.ax1x.com/2023/02/27/ppCm9te.png" alt="ppCm9te.png"></a><br><a href="https://imgse.com/i/ppCmCfH"><img src="https://s1.ax1x.com/2023/02/27/ppCmCfH.png" alt="ppCmCfH.png"></a><br>SRR16914355的质量也很好，我们按同一标准过滤<br><a href="https://imgse.com/i/ppCmipd"><img src="https://s1.ax1x.com/2023/02/27/ppCmipd.png" alt="ppCmipd.png"></a><br><a href="https://imgse.com/i/ppCmF1A"><img src="https://s1.ax1x.com/2023/02/27/ppCmF1A.png" alt="ppCmF1A.png"></a></p><h4 id="2-3-Trimmomatic-filter"><a href="#2-3-Trimmomatic-filter" class="headerlink" title="2.3 Trimmomatic filter"></a>2.3 Trimmomatic filter</h4><p>注意命令和文件的地址，要换回自己的地址，别傻乎乎的直接用</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 将不同的测序引物序列合并为一个fasta文件，这样可以处理不同的测序文件cat &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;Trimmomatic-0.39&#x2F;adapters&#x2F;*.fa &gt; &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;Trimmomatic-0.39&#x2F;adapters&#x2F;all.fa# cat完之后检查一下 all.fa 是否是标准的fasta格式，有几个adapter文件末端好像没有换行符，导致cat后 fasta的&gt; + ID的那行接到了上一条序列的序列行了# java -jar &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;Trimmomatic-0.39&#x2F;trimmomatic-0.39.jar PE -phred33 SRR16888499_1.fastq SRR16888499_2.fastq  SRR16888499_1.paired.fastq SRR16888499_1.unpaired.fastq SRR16888499_2.paired.fastq SRR16888499_2.unpaired.fastq ILLUMINACLIP:&#x2F;data&#x2F;pipelines&#x2F;00.RNA_seq&#x2F;Trimmomatic-0.39&#x2F;adapters&#x2F;all.fa:2:30:10:1:TRUE SLIDINGWINDOW:4:20 LEADING:3 TRAILING:3 MINLEN:40 -threads 30# SRR10283202_1.paired.fastq SRR10283202_2.paired.fastq就是我们TRANSCRIPTOMIC的clean data# 这里改下名字，不然后面fungap会找不到(只找固定后缀文件)mv SRR16888499_1.paired.fastq SRR16888499_1.fqmv SRR16888499_2.paired.fastq SRR16888499_2.fqjava -jar &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;Trimmomatic-0.39&#x2F;trimmomatic-0.39.jar PE -phred33 SRR16914355_1.fastq SRR16914355_2.fastq  SRR16914355_1.paired.fastq SRR16914355_1.unpaired.fastq SRR16914355_2.paired.fastq SRR16914355_2.unpaired.fastq ILLUMINACLIP:&#x2F;data&#x2F;pipelines&#x2F;00.RNA_seq&#x2F;Trimmomatic-0.39&#x2F;adapters&#x2F;all.fa:2:30:10:1:TRUE SLIDINGWINDOW:4:20 LEADING:3 TRAILING:3 MINLEN:40 -threads 30# SRR22980490_1.paired.fastq SRR22980490_2.paired.fastq就是我们WGS的clean data,但还要去一下重复序列# 参数的具体含义建议去官网上搜索，这里不详细讲述了，参数选择并不唯一<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-4-remove-PCR-duplication"><a href="#2-4-remove-PCR-duplication" class="headerlink" title="2.4 remove PCR duplication"></a>2.4 remove PCR duplication</h4><p>在基因组组装前，需要对WGS的测序数据去除PCR重复，这里使用fastuniq操作。虽然raw_data就已经没什么重复序列了，但我们还是去一遍，转录组数据一般不用去除这些重复序列。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p ..&#x2F;01.clean_data &amp;&amp; mv *.paired.* ..&#x2F;01.clean_datacd ..&#x2F;01.clean_data # Remove exact duplicatesls SRR16914355_1.paired.fastq SRR16914355_2.paired.fastq &gt; sample_lstfastuniq -i sample_lst -o SRR16914355_1.rd.fastq -p SRR16914355_2.rd.fastq <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-5-clean-fastqc"><a href="#2-5-clean-fastqc" class="headerlink" title="2.5 clean_fastqc"></a>2.5 clean_fastqc</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">fastqc SRR16914355_1.rd.fastq SRR16914355_2.rd.fastq SRR16888499_1.fq SRR16888499_2.fq -t 4 -o.&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>&emsp;&emsp;这里就不放图了，不知道上传的是不是就是clean_data，质量很好。</p><h3 id="3-基因组组装"><a href="#3-基因组组装" class="headerlink" title="3.基因组组装"></a>3.基因组组装</h3><h4 id="3-1-genome-survey"><a href="#3-1-genome-survey" class="headerlink" title="3.1 genome survey"></a>3.1 genome survey</h4><p>kmer在生物信息学上有非常广泛的运用，有非常多方法都是基于kmer的，感兴趣的自己去了解下吧。这里主要使用kmergenie来分析。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ls SRR16914355_1.rd.fastq SRR16914355_2.rd.fastq &gt; kmer_lstkmergenie kmer_lst -o kmergenie_result&#x2F;first_kmer -k 127 -l 27 -s 6 -t 40<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>kmergenie log</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">running histogram estimationFile sample_lst starts <span class="token keyword">with</span> character <span class="token string">"S"</span><span class="token punctuation">,</span> hence <span class="token keyword">is</span> interpreted <span class="token keyword">as</span> a <span class="token builtin">list</span> of <span class="token builtin">file</span> namesReading <span class="token number">2</span> read filesLinear estimation<span class="token punctuation">:</span> <span class="token operator">~</span><span class="token number">1910</span> M distinct <span class="token number">74</span><span class="token operator">-</span>mers are <span class="token keyword">in</span> the readsK<span class="token operator">-</span>mer sampling<span class="token punctuation">:</span> <span class="token number">1</span><span class="token operator">/</span><span class="token number">364</span><span class="token operator">|</span> processing  <span class="token operator">|</span><span class="token punctuation">[</span>going to estimate histograms <span class="token keyword">for</span> values of k<span class="token punctuation">:</span> <span class="token number">127</span> <span class="token number">121</span> <span class="token number">115</span> <span class="token number">109</span> <span class="token number">103</span> <span class="token number">97</span> <span class="token number">91</span> <span class="token number">85</span> <span class="token number">79</span> <span class="token number">73</span> <span class="token number">67</span> <span class="token number">61</span> <span class="token number">55</span> <span class="token number">49</span> <span class="token number">43</span> <span class="token number">37</span> <span class="token number">31</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>Total time Wallclock  <span class="token number">1924.2</span> sfitting model to histograms to estimate best kestimation of the best k so far<span class="token punctuation">:</span> <span class="token number">109</span>refining estimation around <span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">;</span> <span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">with</span> a step of <span class="token number">2</span>running histogram estimationFile sample_lst starts <span class="token keyword">with</span> character <span class="token string">"S"</span><span class="token punctuation">,</span> hence <span class="token keyword">is</span> interpreted <span class="token keyword">as</span> a <span class="token builtin">list</span> of <span class="token builtin">file</span> namesReading <span class="token number">2</span> read filesLinear estimation<span class="token punctuation">:</span> <span class="token operator">~</span><span class="token number">2066</span> M distinct <span class="token number">68</span><span class="token operator">-</span>mers are <span class="token keyword">in</span> the readsK<span class="token operator">-</span>mer sampling<span class="token punctuation">:</span> <span class="token number">1</span><span class="token operator">/</span><span class="token number">394</span><span class="token operator">|</span> processing  <span class="token operator">|</span><span class="token punctuation">[</span>going to estimate histograms <span class="token keyword">for</span> values of k<span class="token punctuation">:</span> <span class="token number">115</span> <span class="token number">113</span> <span class="token number">111</span> <span class="token number">109</span> <span class="token number">107</span> <span class="token number">105</span> <span class="token number">103</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>Total time Wallclock  <span class="token number">798.288</span> sfitting model to histograms to estimate best ktable of predicted num<span class="token punctuation">.</span> of genomic k<span class="token operator">-</span>mers<span class="token punctuation">:</span> kmergenie_result<span class="token punctuation">.</span>datrecommended coverage cut<span class="token operator">-</span>off <span class="token keyword">for</span> best k<span class="token punctuation">:</span> <span class="token number">1</span>best k<span class="token punctuation">:</span> <span class="token number">111</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最佳<strong>K=111</strong>，我们再跑一遍kmergenie，这次缩小下范围</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">kmergenie kmer_lst -o kmergenie_result&#x2F;re_kmer -k 115 -l 107 -s 2 -t 40<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这次最佳还是<strong>K=111</strong>，后续我们使用SPAdes组装也要添加这个k值。预估的基因组大约<strong>72,607,905bp</strong>。</p><p><a href="https://imgse.com/i/ppC2ItP"><img src="https://s1.ax1x.com/2023/02/28/ppC2ItP.png" alt="ppC2ItP.png"></a><br>这里是NCBI上公布的基因组序列信息，大小和预估出来的差不太多。<br><a href="https://imgse.com/i/ppfFWgx"><img src="https://s1.ax1x.com/2023/04/02/ppfFWgx.png" alt="ppfFWgx.png"></a></p><h4 id="3-2-SPAdes-assemble"><a href="#3-2-SPAdes-assemble" class="headerlink" title="3.2 SPAdes assemble"></a>3.2 SPAdes assemble</h4><p>主要使用<a href="https://github.com/ablab/spades">spades</a>来进行基因组组装。软件的具体参数还是建议去GitHub上自己看，直接用这个也行。spades要求kmer长度必须为奇数。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nohup &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;SPAdes-3.15.5-Linux&#x2F;bin&#x2F;spades.py -k 21,33,55,77,99,109,111,127 -t 20 --careful --cov-cutoff auto -1 SRR16914355_1.rd.fastq -2 SRR16914355_2.rd.fastq -o ..&#x2F;02.draft_genome &amp;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="3-3-quast评估基因组组装质量"><a href="#3-3-quast评估基因组组装质量" class="headerlink" title="3.3 quast评估基因组组装质量"></a>3.3 quast评估基因组组装质量</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd ..&#x2F;02.draft_genomeconda activate genome_assemble&#x2F;data&#x2F;chaofan&#x2F;miniconda&#x2F;envs&#x2F;genome_assemble&#x2F;bin&#x2F;quast scaffolds.fastaconda deactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这个是单纯的二代测序数据的组装结果，N50 126.245kbp。<br><a href="https://imgse.com/i/ppiZUVf"><img src="https://s1.ax1x.com/2023/03/01/ppiZUVf.png" alt="ppiZUVf.png"></a></p><h4 id="3-4-BUSCO评估组装一致性"><a href="#3-4-BUSCO评估组装一致性" class="headerlink" title="3.4 BUSCO评估组装一致性"></a>3.4 BUSCO评估组装一致性</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 单独新建一个环境配置# busco 5.4.4有一个BUG https:&#x2F;&#x2F;gitlab.com&#x2F;ezlab&#x2F;busco&#x2F;-&#x2F;issues&#x2F;627# 很遗憾 busco 5.4.5运行这个DB:dothideomycetes_odb10也会报错(emmm 只有在对基因组使用这个DB评估的时候才有问题,注释蛋白的评估是没问题的) 请安装较老一点版本的busco(5.2.*)。 这里我们直接换一个DB吧 conda create -n busco.5.4.5 -c conda-forge -c bioconda busco&#x3D;5.4.5conda activate busco.5.4.5busco -c 8 -i scaffolds.fasta -l &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;busco_db&#x2F;fungi_odb10 -m geno -o busco.5.4.5_fungi_odb10conda deactivate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><a href="https://imgse.com/i/ppk19IA"><img src="https://s1.ax1x.com/2023/03/03/ppk19IA.png" alt="ppk19IA.png"></a></p><h3 id="4-基因注释"><a href="#4-基因注释" class="headerlink" title="4.基因注释"></a>4.基因注释</h3><p>基因注释主要使用<a href="https://github.com/CompSynBioLab-KoreaUniv/FunGAP">FunGAP</a>来做，如果不通过docker安装的话，在使用过程中会遇到各种各样的错误，善用google|bing，一般都是可以解决的(<font color=Aqua>这应该是整个过程中最折腾的</font>)。我这里新建了一个conda环境用来基因注释，所以这里我们先切换下环境：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda activate fungap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>FunGAP的安装请遵循<a href="https://github.com/CompSynBioLab-KoreaUniv/FunGAP/blob/master/INSTALL.md">Github</a>，这里就不展开讲了</p><p><strong>基因注释主要需要三个输入</strong>:</p><ol><li>组装好的基因组文件;</li><li>近源物种的蛋白序列;</li><li>August预测 物种模型的选择;</li><li>最好测个转录组, FunGAP强制必须加上RNA-seq数据，无论是clean_data还是比对后的bam文件(这个可以修改，但是大部分的脚本文件都需要相应的调整，也可以从NCBI上下载RNA-seq数据)。</li></ol><h4 id="4-1-获取近源物种的蛋白"><a href="#4-1-获取近源物种的蛋白" class="headerlink" title="4.1 获取近源物种的蛋白"></a>4.1 获取近源物种的蛋白</h4><p>FunGAP提供了脚本，可以直接从ncbi下载近源物种的蛋白序列。你可以在你的FunGAP文件夹下面找到<code>download_sister_orgs.py</code>，这里我们通过全局路径调用。如果可以的话，尽量下载同属或者同科的所有蛋白序列。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd $workdirmkdir 03.gene_anno &amp;&amp; cd 03.gene_annopython &#x2F;data&#x2F;pipelines&#x2F;01.Gene_anno&#x2F;00.FunGAP&#x2F;FunGAP&#x2F;download_sister_orgs.py \    --download_dir sister_orgs \    --taxon &quot;Alternaria&quot; \    --num_sisters 4 \    --email_address 2439555626@qq.com zcat sister_orgs&#x2F;*faa.gz &gt; prot_db.faa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>–taxon 物种名或属名 它会通过ncbi的Taxonomy遍历近源物种的Assembly_data去下载已公布基因组的蛋白数据;</li><li>–num_sisters 下载的近源物种的数量,一般来说越多越好;</li><li>–email_address 邮箱地址，随便填.</li></ul><h4 id="4-2-挑选August预测的物种模型"><a href="#4-2-挑选August预测的物种模型" class="headerlink" title="4.2 挑选August预测的物种模型"></a>4.2 挑选August预测的物种模型</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python &#x2F;data&#x2F;pipelines&#x2F;01.Gene_anno&#x2F;00.FunGAP&#x2F;FunGAP&#x2F;get_augustus_species.py \    --genus_name &quot;Alternaria&quot; \    --email_address 2439555626@qq.com # --genus_name 物种名或属名 依然通过ncbi的Taxonomy找到 # 已有的近源物种的augustus模型，可以直接用<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">Suggestions:We found them in subphylum level: Pezizomycotinaaspergillus_fumigatusaspergillus_nidulansaspergillus_oryzaeaspergillus_terreusbotrytis_cinereachaetomium_globosumcoccidioides_immitisfusarium_graminearumhistoplasma_capsulatummagnaporthe_griseaneurospora_crassa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里我就简单的选了第一个直接用了。</p><h4 id="4-3-FunGAP进行基因注释"><a href="#4-3-FunGAP进行基因注释" class="headerlink" title="4.3 FunGAP进行基因注释"></a>4.3 FunGAP进行基因注释</h4><p> emmmmmm，有一个隐藏的问题，<code>maker train</code>的过程中会用到TRF对序列进行处理，<code>TRF</code>应该设置了一个256个字符长度的数组来储存输入文件的全局路径，如果你的输入文件路径大于256，TRF就会<code>buffer overflow detected</code>，老倒霉蛋了。这个问题好像还是第一次发现的，特别是通过mpirun并行maker，会给输入文件加上一堆特殊含义的后缀什么的(这也和我改了maker的默认TMPDIR有关，我把它设置为当前运行路径下，可能当前全局路径本身就很长了)。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&#x2F;data&#x2F;pipelines&#x2F;01.Gene_anno&#x2F;00.FunGAP&#x2F;FunGAP&#x2F;fungap.py \  --genome_assembly ..&#x2F;02.draft_genome&#x2F;scaffolds.fasta \  --trans_read_1 SRR22973808_1.fastq \  --trans_read_2 SRR22973808_2.fastq \  --augustus_species aspergillus_fumigatus \  --busco_dataset &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;busco_db&#x2F;dothideomycetes_odb10 \  --sister_proteome prot_db.faa \  --num_cores 32 \  --output_dir Alternaria<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-4-BUSCO评估基因注释结果-这里用的dothideomycetes-odb10"><a href="#4-4-BUSCO评估基因注释结果-这里用的dothideomycetes-odb10" class="headerlink" title="4.4 BUSCO评估基因注释结果(这里用的dothideomycetes_odb10)"></a>4.4 BUSCO评估基因注释结果(这里用的dothideomycetes_odb10)</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 检查使用二代数据组装基因组基因注释的busco值busco -c 8 -i Alternaria&#x2F;fungap_out&#x2F;fungap_out_prot.faa -l &#x2F;data&#x2F;chaofan&#x2F;source&#x2F;busco_db&#x2F;dothideomycetes_odb10 -m prot -o Alternaria_dothideomycetes_odb10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>要是植物有这么高就好了。增加prot_db.faa里面同源物种的蛋白数量会适当的提高busco值，可能会加个百分之零点几吧。<br><a href="https://imgse.com/i/ppMRuGV"><img src="https://s1.ax1x.com/2023/03/12/ppMRuGV.png" alt="ppMRuGV.png"></a></p><h4 id="4-5-检查gff文件"><a href="#4-5-检查gff文件" class="headerlink" title="4.5 检查gff文件"></a>4.5 检查gff文件</h4><p>前段时间被gff文件中的CDS phase搞了一波，以后如果我做完基因注释，绝对检查一遍。使用<a href="https://github.com/NAL-i5K/GFF3toolkit">GFF3toolkit</a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">gff3_QC -g ..&#x2F;03.gene_anno&#x2F;Alternaria&#x2F;fungap_out&#x2F;fungap_out.gff3 -f scaffolds.fasta -o error.txt -s statistic.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们这里可能有一个小问题:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">[</span><span class="token string">'Line 3'</span><span class="token punctuation">]</span>      Esf0003 Error   <span class="token punctuation">[</span>Strand information missing<span class="token punctuation">:</span> legal chacracter<span class="token punctuation">,</span> <span class="token string">"."</span><span class="token punctuation">,</span> found at the strand field<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个是由于我们的gff文件中还包含了序列长度信息行，这个可以不用管。假设你的gff确实有别的问题(注意看error.txt)，则用gff3_fix进行矫正，gff3_fix也是属于<code>GFF3toolkit</code>的一个工具</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">gff3_fix -qc_r error.txt -g ..&#x2F;03.gene_anno&#x2F;Alternaria&#x2F;fungap_out&#x2F;fungap_out.gff3 -og ..&#x2F;03.gene_anno&#x2F;Alternaria&#x2F;fungap_out&#x2F;corrected.gff3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-6-对注释蛋白进行功能注释"><a href="#4-6-对注释蛋白进行功能注释" class="headerlink" title="4.6 对注释蛋白进行功能注释"></a>4.6 对注释蛋白进行功能注释</h4><p>这里我们使用interproscan.sh来对注释的蛋白进行功能注释，并添加到gff文件中。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 删除序列末尾的 * 号sed -i  &#39;s&#x2F;\*$&#x2F;&#x2F;g&#39; fungap_out_prot.faa&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;interproscan-5.61-93.0&#x2F;interproscan.sh -i fungap_out_prot.faa -f tsv -appl Pfam --goterms -pa --iprlookup -b  Alternaria --tempdir &#x2F;data&#x2F;pipelines&#x2F;01.Gene_anno&#x2F;maker_tmp&#x2F;# 将interproscan注释加到gff文件内&#x2F;data&#x2F;pipelines&#x2F;01.Gene_anno&#x2F;00.FunGAP&#x2F;FunGAP&#x2F;gff3_add_pfam.py --input_gff3 fungap_out.gff3 --pfam_file Alternaria.tsv# 默认注释是加在mRNA 第一个CDS行的第9列(key 列)，你也可以直接修改这个脚本，把他加在mRNA的后面。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如有任何问题，恳请联系我修正。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Genome </tag>
            
            <tag> Assemble </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mitogenomeAssembleAnnotataion</title>
      <link href="2023/03/26/mitogenomeassembleannotation/"/>
      <url>2023/03/26/mitogenomeassembleannotation/</url>
      
        <content type="html"><![CDATA[<h1 id="真菌线粒体基因组的组装及注释"><a href="#真菌线粒体基因组的组装及注释" class="headerlink" title="真菌线粒体基因组的组装及注释"></a>真菌线粒体基因组的组装及注释</h1><p>最近在做真菌基因组的组装注释工作，发现之前组装的线粒体基因组有点问题(基因注释只注释出来 rRNA，长度也不太对)，然后重新组装注释一下。主要还是利用<code>NCBI</code>上已有的<code>Alternaria mitochondrion</code>做为参考序列进行组装。<br><a href="https://imgse.com/i/ppsnBSf"><img src="https://s1.ax1x.com/2023/03/26/ppsnBSf.png" alt="ppsnBSf.png"></a></p><h3 id="0-环境的配置"><a href="#0-环境的配置" class="headerlink" title="0.环境的配置"></a>0.环境的配置</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n mitogenome sra-tools fastp -y -c biocondaconad activate mitogenome# MITGARD 用来有参拼接线粒体基因组# MITGARD： https:&#x2F;&#x2F;github.com&#x2F;pedronachtigall&#x2F;MITGARDcd &#x2F;data&#x2F;chaofan&#x2F;software&#x2F;git clone https:&#x2F;&#x2F;github.com&#x2F;pedronachtigall&#x2F;MITGARD.gitcd MITGARD&#x2F;bin# 加入PATH 运行过程中需要依赖到一些脚本文件，不放入PATH会报错export PATH&#x3D;&quot;&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;MITGARD&#x2F;bin:$PATH&quot;# MITGARD有好几个软件依赖 不装用不了# 依赖的软件自行配置，都能通过conda安装<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>特别注意，<font color="red"> MITGARD.py、msa2consensus.py、sam2msa.py、RearrangementCheck.py </font>这几个脚本的解释器地址要改成当前环境的python解释器，不然会报错。 把脚本文件的第一行从<code>/usr/bin/python</code> 改成<code>/usr/bin/env python</code>。</p><h3 id="1-数据的下载及预处理"><a href="#1-数据的下载及预处理" class="headerlink" title="1.数据的下载及预处理"></a>1.数据的下载及预处理</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># prefetch 和 fastq-dump都属于sra-tools工具包，直接conda安装就好了prefetch SRR12578435 -O .&#x2F;# 解压sra文件为fastqfastq-dump --split-3 SRR12578435&#x2F;SRR12578435.sra# fastp 去除接头及低质量碱基fastp -i SRR12578435_1.fastq -o SRR12578435_f1.fastq -I SRR12578435_2.fastq -O SRR12578435_r2.fastq --thread&#x3D;4 --length_required&#x3D;40 -j SRR12578435.json# ncbi上线粒体基因组就自己手动下载了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-MITGARD-组装线粒体基因组"><a href="#2-MITGARD-组装线粒体基因组" class="headerlink" title="2.MITGARD 组装线粒体基因组"></a>2.MITGARD 组装线粒体基因组</h3><p>软件运行很简单，前面的注意事项弄完一般就不太会报错了。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&#x2F;data&#x2F;chaofan&#x2F;software&#x2F;MITGARD&#x2F;bin&#x2F;MITGARD.py -s Z7 -1 SRR12578435_f1.fastq -2 SRR12578435_r2.fastq -R PN2.fa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>Z7_mitogenome.fa</code>就是我们的结果文件了，简单的less查看一下，看看是否有大量的N，有大量N就不行了，可能是你选的参考线粒体基因组不对。</p><h3 id="3-MITOS在线注释线粒体基因组"><a href="#3-MITOS在线注释线粒体基因组" class="headerlink" title="3.MITOS在线注释线粒体基因组"></a>3.MITOS在线注释线粒体基因组</h3><p><a href="http://mitos2.bioinf.uni-leipzig.de/index.py">MITOS</a>的使用非常简单，这里选择真菌，密码子表选择4就好了。速度也非常快，毕竟线粒体基因组才50Kbp长，基因也非常保守。<br><a href="https://imgse.com/i/ppsotk6"><img src="https://s1.ax1x.com/2023/03/27/ppsotk6.png" alt="ppsotk6.png"></a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Assemble </tag>
            
            <tag> mitogenome </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SIFT4G的使用</title>
      <link href="2021/12/09/sift4g-de-shi-yong/"/>
      <url>2021/12/09/sift4g-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="SIFT4G的安装与使用"><a href="#SIFT4G的安装与使用" class="headerlink" title="SIFT4G的安装与使用"></a>SIFT4G的安装与使用</h1><p>&emsp;&emsp;最近一个月状态有点不太对，有点控制不住自己的情绪。以后要是心情烦躁就写写博客吧！还能巩固知识。</p><p>&emsp;&emsp;<a href="https://github.com/rvaser/sift4g">SIFT4G</a>的前身是<a href="http://blocks.fhcrc.org/sift/SIFT.html">sift</a>，都是同一个东西，用来评估基因突变的有害程度，基于氨基酸序列的同源性和物理性质来预测氨基酸的替换对蛋白质功能是否影响。sift在网站上使用，它提供少量物种的在线查询，包括人类等。而SIFT4G则是本地版，当然windows和linux都有对应的工具可以运行，这里我们只讲述linux上SIFT4G的使用。</p><h2 id="一、SIFT4G的安装"><a href="#一、SIFT4G的安装" class="headerlink" title="一、SIFT4G的安装"></a>一、SIFT4G的安装</h2><h3 id="1-1本地编译安装"><a href="#1-1本地编译安装" class="headerlink" title="1.1本地编译安装"></a>1.1本地编译安装</h3><p>&emsp;&emsp;SIFT4G基于C++，软件编译需要4.9+版本的g++编译器，很不凑巧，我们服务器上只有4.8.5版本的g++编译器。</p><p><a href="https://imgtu.com/i/o4ymtO"><img src="https://s1.ax1x.com/2021/12/09/o4ymtO.png" alt="o4ymtO.png"></a></p><p>&emsp;&emsp;我们可以通过conda安装4.9+以上版本的g++，我们这里选择了5.4.0版本的编译器。如果你是直接通过conda在线安装，建议选一个新的环境，不然可能会有库文件依赖问题（下图所示）。我当时是通过conda本地安装在dcfpy3环境下，现在忘了细节了，不过google肯定能解决问题的。</p><p><a href="https://imgtu.com/i/o4cgl4"><img src="https://s1.ax1x.com/2021/12/10/o4cgl4.png" alt="o4cgl4.png"></a></p><p>&emsp;&emsp;在编译中发现一个问题，不知道安装还是什么其他原因，虽然dcfpy3这个子环境的g++是5.4.0版本。但是我直接编译还是会提示找不到库文件的问题，后来发现直接添加动态链接库可解决。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 这些文件的地址需要按照自己的安装目录去更改，是不能直接套的export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;public&#x2F;home&#x2F;chaofan&#x2F;anaconda3&#x2F;envs&#x2F;dcfpy3&#x2F;lib<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>&emsp;&emsp;出现下图这个就代表你安装好了，如果还报错可以去作者的github上问问，作者还是挺热情的。</p><p><a href="https://imgtu.com/i/o4gYAx"><img src="https://s1.ax1x.com/2021/12/10/o4gYAx.png" alt="o4gYAx.png"></a></p><h3 id="1-2-conda安装"><a href="#1-2-conda安装" class="headerlink" title="1.2 conda安装"></a>1.2 conda安装</h3><p>&emsp;&emsp;当然，你也可以直接通过conda在线安装，省时省事。(强烈建议新建一个环境来整)</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda install sift4g -c bioconda<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="https://imgtu.com/i/o4yg4U"><img src="https://s1.ax1x.com/2021/12/10/o4yg4U.png" alt="o4yg4U.png"></a></p><h2 id="二、SIFT4G的使用"><a href="#二、SIFT4G的使用" class="headerlink" title="二、SIFT4G的使用"></a>二、SIFT4G的使用</h2><p>&emsp;&emsp;SIFT4G的使用非常简单，他的输入主要有两个，一个是针对特定物种的数据库，和该物种的蛋白组有关，另外一个则是VCF文件了，这里指的是SNP的，包含indel信息的应该也可以。特定物种的数据库可以去官网下载<a href="https://sift.bii.a-star.edu.sg/sift4g/index.php">SIFT4G</a>下载，然后直接使用<a href="https://github.com/pauline-ng/SIFT4G_Annotator">SIFT4G Annotator</a>进行注释就好了，没有的话就需要自己构建了。我选用的物种刚好没有，所以下面我们开始自己构建小麦的注释数据库。</p><h3 id="2-1-SIFT4G注释数据库的生成"><a href="#2-1-SIFT4G注释数据库的生成" class="headerlink" title="2.1 SIFT4G注释数据库的生成"></a>2.1 SIFT4G注释数据库的生成</h3><p>&emsp;&emsp;软件作者提供生成注释数据库的脚本，当然，你也可以直接联系软件作者帮你弄，需要将提供帮助构建数据库的人加入到你的论文作者中。注释脚本我们直接从<a href="https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB">Github</a>上下载。主要是一个perl脚本，运行起来非常简单，直接用一行shell运行就行了。</p><p>&emsp;&emsp;生成这个注释数据库需要三个东西，包括注释物种的基因组序列fa和对应的gff文件，还需要一个非冗余的蛋白质数据库，你可以使用NCBI的nr蛋白质数据库或者Uniport的nr蛋白数据库。强烈建议构建这个注释数据库的时候拆分为不同的染色体来运行，可以并行化，速度提升非常的大。这个软件在构建过程中有一步需要根据gff和基因组的DNA序列来提取蛋白质，这一步非常非常的卡时间，有一个过程会一直往内存中加东西，但CPU的占用非常低，我之前整整个小麦的，结果运行了两天感觉没啥变化，后来分染色体体运行就非常快了。</p><p>&emsp;&emsp;非冗余数据库下载非常慢，这个文件非常大，下载过程中要注意下载不成功的情况。我们服务器上刚好有师兄弄好的，那我们直接用了。</p><p>&emsp;&emsp;构建注释数据库的命令非常简单，以染色体7D为例：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">perl make-SIFT-db-all.pl -config .&#x2F;wheat&#x2F;chr7D.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>&emsp;&emsp;我们这里讲一下这个./wheat/chr7D.txt配置文件(一个#开头代表原来的注释)：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">## 氨基酸编码表格 这里使用标准的 当然也有线粒体什么的可以选</span>GENETIC_CODE_TABLE<span class="token operator">=</span><span class="token number">1</span>GENETIC_CODE_TABLENAME<span class="token operator">=</span>Standard<span class="token comment">## 构建注释数据库的输入文件地址，里面需要包含特定的文件结构</span>PARENT_DIR<span class="token operator">=</span><span class="token punctuation">.</span><span class="token operator">/</span>wheat<span class="token operator">/</span>Chr7DORG<span class="token operator">=</span>wheat<span class="token comment">## 最后输出的结果文件前缀  *.gz *.regions</span>ORG_VERSION<span class="token operator">=</span>chr7D<span class="token comment">#Running SIFT 4G</span><span class="token comment">## sift4g软件的地址path，这里我们已经加入到PATH，不用加全局路径</span>SIFT4G_PATH<span class="token operator">=</span>sift4g<span class="token comment">## 非冗余蛋白库，比对的时候要用</span>PROTEIN_DB<span class="token operator">=</span><span class="token operator">/</span>vol3<span class="token operator">/</span>agis<span class="token operator">/</span>TMP_group<span class="token operator">/</span>chaofan<span class="token operator">/</span><span class="token number">00</span><span class="token punctuation">.</span>wenwen<span class="token operator">/</span><span class="token number">02</span><span class="token punctuation">.</span>database<span class="token operator">/</span>ncbiNR<span class="token operator">/</span>nr<span class="token punctuation">.</span>fa<span class="token comment">## 这里用默认的就好了，不用改</span><span class="token comment"># Sub-directories, don't need to change</span>GENE_DOWNLOAD_DEST<span class="token operator">=</span>gene<span class="token operator">-</span>annotation<span class="token operator">-</span>srcCHR_DOWNLOAD_DEST<span class="token operator">=</span><span class="token builtin">chr</span><span class="token operator">-</span>srcLOGFILE<span class="token operator">=</span>Log<span class="token punctuation">.</span>txtZLOGFILE<span class="token operator">=</span>Log2<span class="token punctuation">.</span>txtFASTA_DIR<span class="token operator">=</span>fastaSUBST_DIR<span class="token operator">=</span>substALIGN_DIR<span class="token operator">=</span>SIFT_alignmentsSIFT_SCORE_DIR<span class="token operator">=</span>SIFT_predictionsSINGLE_REC_BY_CHR_DIR<span class="token operator">=</span>singleRecordsSINGLE_REC_WITH_SIFTSCORE_DIR<span class="token operator">=</span>singleRecords_with_scores<span class="token comment">## 这里用默认的就好了，不用改</span><span class="token comment"># Doesn't need to change</span>FASTA_LOG<span class="token operator">=</span>fasta<span class="token punctuation">.</span>logINVALID_LOG<span class="token operator">=</span>invalid<span class="token punctuation">.</span>logPEPTIDE_LOG<span class="token operator">=</span>peptide<span class="token punctuation">.</span>log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;我们来讲一下PARENT_DIR=./wheat/Chr7D类似的文件结构：</p><p><a href="https://imgtu.com/i/TYrC0P"><img src="https://s4.ax1x.com/2021/12/24/TYrC0P.png" alt="TYrC0P.png"></a></p><p>&emsp;&emsp;你需要在每一个“Chr7D”目录下放两个文件夹，名字应该和上图一样。chr-src放基因组序列，fasta格式，gene-annotation-src下面放对于的gz压缩的gtf文件，好像如果不是gz文件，后面有一步会报错，我也忘了具体的了，gz格式准没错。</p><p>&emsp;&emsp;这些都整好之后我们就可以用之前下载的注释脚本<a href="https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB">Github</a>来构建我们的数据库了。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;public&#x2F;home&#x2F;chaofan&#x2F;anaconda3&#x2F;envs&#x2F;dcfpy3&#x2F;lib# 这个make-SIFT-db-all.pl 可以放到PATH里，也可以直接上全局路径perl make-SIFT-db-all.pl -config .&#x2F;wheat&#x2F;chr7D.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>&emsp;&emsp;拆分为单个染色体后注释的时间很快的，我们成功结束的话目录下应该有下图这些东西。我们最后需要用的文件就在chr7D里面，chr7D.gz和chr7D.regions。</p><p><a href="https://imgtu.com/i/TYyPJS"><img src="https://s4.ax1x.com/2021/12/24/TYyPJS.png" alt="TYyPJS.png"></a></p><h3 id="2-2-给vcf文件注释，获得有害变异"><a href="#2-2-给vcf文件注释，获得有害变异" class="headerlink" title="2.2 给vcf文件注释，获得有害变异"></a>2.2 给vcf文件注释，获得有害变异</h3><p>&emsp;&emsp;我们在构建完我们的注释数据库后，可以直接对vcf文件进行注释了。使用的软件为<a href="https://github.com/pauline-ng/SIFT4G_Annotator">SIFT4G Annotator</a>，这个软件有一个我非常理解不了的东西，为什么这个软件不能直接对gz文件进行操作？还得把原来压缩好的文件解压出来，再注释，再压缩。还有一个，这个软件会强制修改你vcf文件的染色体名称，它会去掉chr*前面的chr字符，比如你开始是chr7D，它后面操作的时候就变成了7D。这个会导致什么呢，这个的设计本来是为了多条染色体的，它会通过这个修改名称后的染色体名字去注释数据库找染色体对应的注释文件。所以上一步获得的chr7D.gz和chr7D.regions得修改成7D.gz和7D.regions才行哦。</p><p>&emsp;&emsp;这个问题我之前问过作者了，他当时也忘了，以为我vcf文件的染色体名称混入了其他的名称。后来我翻他源码才找到了，头疼。第174到177步就是删除染色体名称中“chr”(得是chr开头的哦)的操作代码。</p><p><a href="https://imgtu.com/i/TYcrVI"><img src="https://s4.ax1x.com/2021/12/24/TYcrVI.png" alt="TYcrVI.png"></a></p><p>&emsp;&emsp;在整完前面这些步骤后，我们开始注释了：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">java -jar &#x2F;vol3&#x2F;agis&#x2F;TMP_group&#x2F;chaofan&#x2F;09.SIFT&#x2F;sift4g&#x2F;bin&#x2F;SIFT4G_Annotator.jar -c -i chr7D.vcf -d &#x2F;vol3&#x2F;agis&#x2F;TMP_group&#x2F;chaofan&#x2F;09.SIFT&#x2F;scripts_to_build_SIFT_db&#x2F;wheat&#x2F;Chr7D&#x2F;chr7D -r . -t<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>&emsp;&emsp;我们已经整完了所有的步骤了，-i 待注释的vcf文件， -c 命令行运行模式， -d 之前生成的注释数据库文件夹地址，-r 输出文件地址 -t 提取多个转录本的注释(可选)。下一次更新jcvi的使用，这几天刚好在学习这个，做共线性分析的。</p><p><a href="https://imgtu.com/i/TYTPHS"><img src="https://s4.ax1x.com/2021/12/24/TYTPHS.png" alt="TYTPHS.png"></a></p>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> SIFT4G </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从FASTA文件中提取特定ID序列</title>
      <link href="2021/10/10/cong-fasta-wen-jian-zhong-ti-qu-te-ding-id-xu-lie/"/>
      <url>2021/10/10/cong-fasta-wen-jian-zhong-ti-qu-te-ding-id-xu-lie/</url>
      
        <content type="html"><![CDATA[<h1 id="从-FASTA-文件中提取特定-ID-的序列"><a href="#从-FASTA-文件中提取特定-ID-的序列" class="headerlink" title="从 FASTA 文件中提取特定 ID 的序列"></a>从 FASTA 文件中提取特定 ID 的序列</h1><h3 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h3><p>&ensp;&ensp;在日常的工作中，我们经常会遇到：从某个物种总的 cds 序列或者 pep 序列中提取我们感兴趣特定 ID 序列这样的问题。比如我知道某个基因家族所有序列的 ID 名称，现在我想提取这些 ID 的序列，方便下一步的分析。这个时候就可以使用我今天写的东西了。</p><h3 id="二、具体细节"><a href="#二、具体细节" class="headerlink" title="二、具体细节"></a>二、具体细节</h3><p>&ensp;&ensp;下图这是大豆 pep 文件中的一部分，我们看下大概的格式就行了，具体的细节自己找个类似的文件去看下。每条序列由两部分组成，一部分是&gt;开头的一行，包括这条序列的 ID 和相应的描述性东西，另一部分则是由对应的序列组成(DNA 序列或氨基酸序列，这个由你自己的文件的类别决定)。</p><p><a href="https://imgtu.com/i/5E51Yt"><img src="https://z3.ax1x.com/2021/10/10/5E51Yt.png" alt="5E51Yt.png"></a></p><p>&ensp;&ensp;大体的思路是这样的，常规的操作是先读取总的 FASTA 文件，将相应的信息提取出来，然后我们根据待提取的基因 ID 再来操作。在读取总的 FASTA 文件的时候，我们可以根据 FASTA 格式开头的&gt;，来判断是否读取到新的序列。</p><p>&ensp;&ensp;脚本的输入是两个，一个是总的 FASTA 文件，一个是待提取的 ID 列表文件，输出的话就是我们想要 ID</p><p>对应的序列了。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#! Usage: python get_seq_from_lst.py [fasta_file] [seq_lst] [ouf_file]</span><span class="token keyword">from</span> sys <span class="token keyword">import</span> argv<span class="token keyword">def</span> <span class="token function">read_fa</span><span class="token punctuation">(</span>fa_file<span class="token punctuation">)</span><span class="token punctuation">:</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fa_file<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'\n'</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token keyword">if</span> line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'>'</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            tmp_dic<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>    tmp_dic <span class="token operator">=</span> <span class="token punctuation">&#123;</span>t_lst<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>t_lst<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> t_lst <span class="token keyword">in</span> tmp_dic<span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> tmp_dic<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    seq_ids <span class="token operator">=</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    fa_dic <span class="token operator">=</span> read_fa<span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    ouf_w <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> seq_id <span class="token keyword">in</span> seq_ids<span class="token punctuation">:</span>        <span class="token keyword">if</span> seq_id <span class="token keyword">in</span> fa_dic<span class="token punctuation">:</span>            ouf_w<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token operator">+</span>seq_id<span class="token operator">+</span><span class="token string">"\n"</span><span class="token operator">+</span>fa_dic<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%s not in %s file"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>seq_id<span class="token punctuation">,</span> argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ouf_w<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;条条大路通罗马，为了实现某一个目的，可以有非常多的方式，特别是 python 和 perl 这些脚本语言。我们可以用不同的数据结构去实现，然而就是使用相同的数据结构，每个人的思考方式也是不同的。最好的代码就是还没写出来的代码！我们这里并没有使用字典这样非常直观的数据结构，只是用了字符串和列表的方式，下面的是使用哈希表实现的 C++代码，C++还没学多久，所以看起来不是很妙。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"># include &lt;iostream&gt;# include &lt;fstream&gt;# include &lt;string&gt;# include &lt;cstdlib&gt;# include &lt;map&gt;using namespace std;int main(int argc, char * argv[])&#123;    if (argc !&#x3D; 4)&#123;        cerr &lt;&lt; &quot;Usage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot; fasta_file[f] gene_lst[l] ouf_[o] \n&quot;;        exit(EXIT_FAILURE);    &#125;    &#x2F;&#x2F; get fa content    ifstream fin;    map&lt;string, string&gt; fa_dict;    fin.open(argv[1]);    string line;    string header;    string seqence;    seqence &#x3D; &quot;&quot;;    while (getline(fin, line))&#123;        if(line[0] &#x3D;&#x3D; &#39;&gt;&#39;)&#123;            if (seqence.length() &gt; 0)&#123;                fa_dict[header] &#x3D; seqence;                seqence &#x3D; &quot;&quot;;            &#125;            header &#x3D; line;        &#125;else&#123;            seqence +&#x3D; line;            seqence +&#x3D; &#39;\n&#39;;        &#125;    &#125;    &#x2F;&#x2F; last one    fa_dict[header] &#x3D; seqence;    fin.clear();    fin.close();    &#x2F;&#x2F; ok    &#x2F;&#x2F; for(auto it : fa_dict)&#123;        &#x2F;&#x2F;     cout &lt;&lt; it.first &lt;&lt;&quot; &quot;&lt;&lt; it.second &lt;&lt;endl;    &#x2F;&#x2F; &#125;    &#x2F;&#x2F; get gene lst    fin.open(argv[2]);    ofstream ouf(argv[3]);    while(getline(fin, line))    &#123;        for(auto it : fa_dict)&#123;            if(it &#x3D;&#x3D; line)&#123;                ouf &lt;&lt; it.first &lt;&lt; &quot;\n&quot; &lt;&lt; it.second;            &#125;        &#125;    &#125;    fin.clear();    fin.close();    ouf.clear();    ouf.close();    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;我现在写的代码，都比较糟糕，并没有运用每种语言的特性，偏面对过程，也就是 c 语言的实现方式。后面要慢慢的转变到面对对象，这才是 C++和 python 比较妙的地方。</p><p>&ensp;&ensp;今天先码到这了，以后更新其他的东西，比如用 biopython 得到更好的实现。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Bioinformatics </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROSALIND-多条序列连续公共子串</title>
      <link href="2021/03/10/rosalind-duo-tiao-xu-lie-gong-gong-zi-xu-lie/"/>
      <url>2021/03/10/rosalind-duo-tiao-xu-lie-gong-gong-zi-xu-lie/</url>
      
        <content type="html"><![CDATA[<h1 id="多条序列连续公共子串"><a href="#多条序列连续公共子串" class="headerlink" title="多条序列连续公共子串"></a>多条序列连续公共子串</h1><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>&ensp;&ensp;&ensp;这道题是<a href="http://rosalind.info/problems/lcsm/">ROSALIND</a>上的一道题，感觉挺有趣的，就整整。题目放下面了：</p><p><a href="https://imgtu.com/i/6YlHmj"><img src="https://s3.ax1x.com/2021/03/10/6YlHmj.png" alt="6YlHmj.png"></a></p><p>&ensp;&ensp;&ensp;在整这道题之前，先来点预备知识，在寻找多序列的公共子串之前，先了解一下两条序列的最长公共子序列，这个是基础知识。在Leetcode上有这样的一道题：<a href="https://leetcode-cn.com/problems/longest-common-subsequence/">1143. 最长公共子序列</a>，可以先解出一下这道题，再来看我们的这个问题。</p><h3 id="1-1最长公共子序列"><a href="#1-1最长公共子序列" class="headerlink" title="1.1最长公共子序列"></a>1.1最长公共子序列</h3><p>&ensp;&ensp;&ensp;大噶可以先去B站看下别人的解题思路，比如这个<a href="https://www.bilibili.com/video/BV1iE411Y7fy?from=search&seid=3665822260836410502">小姐姐的</a>，题目如下：<a href="https://imgtu.com/i/6YgD9f"><img src="https://s3.ax1x.com/2021/03/11/6YgD9f.png" alt="6YgD9f.png"></a></p><p>&ensp;&ensp;&ensp;大概来说是这样的一个数学表达式：<a href="https://imgtu.com/i/6YWnBQ"><img src="https://s3.ax1x.com/2021/03/11/6YWnBQ.png" alt="6YWnBQ.png"></a></p><p>先放上小姐姐的 java 代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">longestCommonSubsequence</span><span class="token punctuation">(</span><span class="token class-name">String</span> text1<span class="token punctuation">,</span> <span class="token class-name">String</span> text2<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">int</span> m <span class="token operator">=</span> text1<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n <span class="token operator">=</span> text2<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">]</span> dp <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">int</span><span class="token punctuation">[</span>m <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>n <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> m<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j<span class="token operator">&lt;</span> n<span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>            <span class="token keyword">char</span> c1 <span class="token operator">=</span> text1<span class="token punctuation">.</span><span class="token function">charAt</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> c2 <span class="token operator">=</span> text2<span class="token punctuation">.</span><span class="token function">charAt</span><span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>c1 <span class="token operator">==</span> c2<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>                dp<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>                dp<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>dp<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">&#125;</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> dp<span class="token punctuation">[</span>m<span class="token punctuation">]</span><span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp; 在放上对应的 python3 代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">longestCommonSubsequence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text1<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> text2<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span><span class="token punctuation">:</span>    m<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text2<span class="token punctuation">)</span>    dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> text1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> text2<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>                dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> dp<span class="token punctuation">[</span>m<span class="token punctuation">]</span><span class="token punctuation">[</span>n<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp;再看一下两种语言的速度差距（所以该学什么语言不用我多说了吧！+ 。+）：</p><p><a href="https://imgtu.com/i/6NkzOx"><img src="https://s3.ax1x.com/2021/03/11/6NkzOx.png" alt="6NkzOx.png"></a></p><h3 id="1-2最长公共子串"><a href="#1-2最长公共子串" class="headerlink" title="1.2最长公共子串"></a>1.2最长公共子串</h3><p>&ensp;&ensp;&ensp;子串和子序列是有差别的，子串指的是字符串中连续的一段字符，而子序列的话是没有这个要求的，其实这两种的解题思路是一样的。子串的数学表达式为：<a href="https://imgtu.com/i/6Yotu6"><img src="https://s3.ax1x.com/2021/03/11/6Yotu6.png" alt="6Yotu6.png"></a></p><p>&ensp;&ensp;在有前面的基础上，我们直接放代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Find_Lcsubstr</span><span class="token punctuation">(</span>s1<span class="token punctuation">,</span> s2<span class="token punctuation">)</span><span class="token punctuation">:</span>    m<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text2<span class="token punctuation">)</span>    dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    max1 <span class="token operator">=</span> <span class="token number">0</span>    state <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> text1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> text2<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>            dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token keyword">if</span> dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> max1<span class="token punctuation">:</span>                    max1 <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>                    state <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token keyword">return</span> s1<span class="token punctuation">[</span>state<span class="token operator">-</span>max1<span class="token punctuation">:</span>state<span class="token punctuation">]</span><span class="token punctuation">,</span> max1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​        &ensp;下面我们尝试寻找两条DNA序列的最长公共子串：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> <span class="token triple-quoted-string string">""">Rosalind_2556ATGTGAGGGATGTTAGCTTAGTCCGGAGATGCGATGCGGATAGCGTCCAAAGGACATCGTGGGAAGTAACATCTGTGCTGAGTGAGTTCAACATGCAGGAAGCCCTGGTTATAGCCTACAAACGCACGCCTTGTATCTACCGCTCACGGCGTTAGGAGTTTATGACCATGACTGGTCCTCTGGACCTGGCCTGCGTGTGGGGTTCCGTCCGAGCAGAGGATCTTCATCTAGTCCTAATCGCCGACTGCTTAGTCTGATGTTATCGAATGACTTAAACCGCTTTGGGGTTAGGCGGCGTCTACTCATGAGGTACTTACCTTGCTAGGCATGACGTTCTTGATTTAGGCACAGTCGCATTAGTGCCATGGGTTGGGACTAAGATCACTTTCCGTCACATGATAGCACACCTGAACTTTCTAGTCGTAAACCTACTAGAATGGATCACGCCACTCGGCCTCGGGTAAGATCCCAATGCCACTTCCCACTCCTACGAAGCAAGGGTGTACACTCTTTTGCCCTGACATCCGCCCTCTTGCGAACCGCCCGGGGATACTCGCCCCGCCTTCGAGTGGCATGAAGCCAGTTAGATTTACCTGGGTATAAGTGTGTTCTTCGGGGAGCGAGCAGCTTATGAAGGGTCAGGTTGTTCAAAAACCAGGCAGTGGGAGCCACAGGCCACCTGTGCGCTAGAAAAATACCGTGTGCAACAATCTCTATGCGAGACCACTTCTAATTAAAATCGCAAAAGATAACCGTCCGGGATCGGCTGCTGCCTGCGGCGATGTGTGTGCCCCCCATACGATGCTTTCGTATTACATGCTTAAGGAATGACAAGGTGCCCACTGGGTGAAACATTCGTAGTCTCAGCATTTGCGTCGGCTGTTTCTCACTAGGCTGCCAGAAACTGGTACGTGGACAAACTATCCTTTTTTGAGAGGGACACGACTTTACGCCCGGACCCTGCACAGCCGCATGTATCTCCTCCCTTGGGCTATTAGAC>Rosalind_8024ACACATACTCGCTGGCAATGGCTTCTGCTGACACAGATCGCGTTTATTGCCCTGACATCCGCCCTCTTGCGAACCGCCCGGGGATACTCGCCCCGCCTTCGAGTGGCATGAAGCCAGTTAGATTTACCTGGGTATAAGTGTGTTCTTCGGGGAGCGAGCAGCTTATGAAGGGTCAGGTTGTTACAGCGCTCACGTTATATATGTAACGGAATGAACCTTCGTGCGTTCTCACCTCAGATTATAAAGTCCCGTGAACCGGACAATGTGGCCAAAAGTCCTGGGCGTTGCAATGATAGCTCCTCGGCAGTATGCTGAAGGGGAAAAGCTTACCTGTTCTATAGTATCGTACTCAACCGCCGGCCTCAGCGCTTCGTCCAGGGTGCGCCGGGAATCAGTGTCTAAGGGCTCAACTCGCTCATGGAGGTTACGACAACGACTCTGAGGCAATCCCATCGGTTAATGCACAACACCGAGGCGGGGGGGCATGAGTTTGACGATACCCATGTAAGAACAACGTCCGATTGCCCAAGCACCTAGTGGGACTTGGTCTCGCTCCTCCGATAAATAGTACGGCCACTCAATCTTTGGGATCCAGGTCAACGCCTGATCACGGTCCCAGCTGAACGTAGGAGATGGTCGACACTTACGGCTTAATATTACGTTACTTACTATCGGTTGCTAACGTGGACCCCCTATCCCTGAGCCTTTTGGCTCAGTTAAAATAATCCTTGTTACGGTGGGTAACGGCGGTTCATACAACTTCGAGCTCTCGATTCGAGTAGGGCCTGATCTAAAGTGAAATCGACTCGGCATGGGTTGAAACTACCTATAATCAAGTGGCGAATGAAGAGGCAGTTCACATCTGGTGATATTTCAGTTTCATGGGTTCTTAGACGAGGGCGTTCTTATCTTCGCACAGCGCTCCTCCTAGATCATACGTTAGCCCTGGTCTCAGAAACATGGCAAGAAGGCTCCCTCGGACGAGGCGGTCTAATTAAGT"""</span><span class="token keyword">def</span> <span class="token function">Find_Lcsubstr</span><span class="token punctuation">(</span>s1<span class="token punctuation">,</span> s2<span class="token punctuation">)</span><span class="token punctuation">:</span>    m<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s2<span class="token punctuation">)</span>    dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    max1 <span class="token operator">=</span> <span class="token number">0</span>    state <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> s1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> s2<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>                dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">if</span> dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> max1<span class="token punctuation">:</span>                    max1 <span class="token operator">=</span> dp<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>                    state <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>                        <span class="token keyword">return</span> s1<span class="token punctuation">[</span>state<span class="token operator">-</span>max1<span class="token punctuation">:</span>state<span class="token punctuation">]</span><span class="token punctuation">,</span> max1<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    seq_lines <span class="token operator">=</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> seq_lines<span class="token punctuation">:</span>        res <span class="token operator">=</span> i<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>        string_line <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>j <span class="token keyword">for</span> j <span class="token keyword">in</span> res<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>string_line<span class="token punctuation">)</span>         <span class="token keyword">print</span><span class="token punctuation">(</span>Find_Lcsubstr<span class="token punctuation">(</span>seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> seq<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 输出为'TTGCCCTGACATCCGCCCTCTTGCGAACCGCCCGGGGATACTCGCCCCGCCTTCGAGTGGCATGAAGCCAGTTAGATTTACCTGGGTATAAGTGTGTTCTTCGGGGAGCGAGCAGCTTATGAAGGGTCAGGTTGTT', 136</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="二、多条序列的连续公共子串"><a href="#二、多条序列的连续公共子串" class="headerlink" title="二、多条序列的连续公共子串"></a>二、多条序列的连续公共子串</h2><p>&ensp;&ensp;&ensp;好了，我们已经会两条序列的寻找呢，在进行多条序列的公共子串分析之前，我们应该有这样的一个概念：两条序列的公共最长子串直接一比较就行了，那么如果是多条呢？是不是需要多条序列之间的两两比较呢？那这个该有多复杂呢？</p><p>&ensp;&ensp;&ensp;其实有个简单的想法，那就是先随便的挑出两条出来，把这两条比较一下，因为不知道最后结果序列会有多长，可能你在这两条序列中找到的最长的子串，可能在别的序列中就没有那么长了，所以应该在挑出来比较的两条序列中把一定长度的所有公共子串都拿出来，最后想要的多条序列的最长公共子串一定在前面两条公共子串的子集中，可能是子集，也可能是某一个子集的子串（不知道这里搞明白没有）。</p><p>&ensp;&ensp;&ensp;举个简单的例子：假设啊，假设，你在挑出的两条序列的比较中得到了符合一定长度的两个公共子串:[‘TTGCCCTGACATCCGCCCTCTTGCGAACCGCCCGGGGATACTCGCCCCGCCTT’, ‘CTTCGGGGAGCGAGCAGCTTATGAAGGGTCAGGTTGTT’],然后你用这两条序列去分别的和除这两条序列以外的所有序列比较，运气好可能都是其他DNA序列的子串，这个时候我们就可以选择最长的那条，运气不好的情况下是什么样的呢？假设str1 = ‘TTGCCCTGACATCCGCCCTCTTGCGAACCGCCCGGGGATACTCGCCCCGCCTT’这条子串在和第三条DNA序列比较的时候只有前面20个字符是<strong>公共</strong>且<strong>最长</strong>的，那么我们在这个时候就应该把原来的全长子串，变成它的前二十个字符，str1 = str1[:20]，然后再用这个改变后的str1去和第四条DNA序列去比，如果后面所得长度又发生变化了，再改变str1的值，一直这样迭代下去，这样我们得到的就是所有DNA序列的公共子串了，然后我们把前面两条序列和其他DNA序列都比较一下，会得到一些子串，选出最长的就是我们想要的结果了。</p><p>&ensp;&ensp;&ensp;不多BB，我们直接整这道题：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># N个字符串的所有公共子串长度大于阈值的子串</span><span class="token comment"># 设置阈值</span>MIN_NUM <span class="token operator">=</span> <span class="token number">8</span><span class="token keyword">def</span> <span class="token function">get_maxstr</span><span class="token punctuation">(</span>str1<span class="token punctuation">,</span> str2<span class="token punctuation">)</span><span class="token punctuation">:</span>    total_str <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    lstr1 <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>str1<span class="token punctuation">)</span>    lstr2 <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>str2<span class="token punctuation">)</span>    record <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>lstr2<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>lstr1<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># 构建打分矩阵</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>lstr1<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>lstr2<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> str1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> str2<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>                record<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> record<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span><span class="token comment"># 遍历打分矩阵，获取相应的子串</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>lstr1<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>lstr2<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> record<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">>=</span> MIN_NUM <span class="token keyword">and</span> <span class="token operator">+</span>            <span class="token punctuation">(</span><span class="token punctuation">(</span>i <span class="token operator">==</span> lstr1 <span class="token keyword">or</span> j <span class="token operator">==</span> lstr2<span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token punctuation">(</span>record<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                len1 <span class="token operator">=</span> record<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span>                total_str<span class="token punctuation">.</span>append<span class="token punctuation">(</span>str1<span class="token punctuation">[</span>i<span class="token operator">-</span>len1<span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> total_str    <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f1 <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'13.input.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    seq_lines <span class="token operator">=</span> f1<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> seq_lines<span class="token punctuation">:</span>        res <span class="token operator">=</span> i<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>        string_line <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> res<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">if</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>        seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>string_line<span class="token punctuation">)</span>        <span class="token comment"># 获取开始两条DNA序列的公共子串 len > MIN_NUM</span>    res_lst <span class="token operator">=</span> getmaxstr<span class="token punctuation">(</span>seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> seq<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    finall_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment"># 将前面获取的子串分别与其他的DNA序列比对，获取最长子串</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> res_lst<span class="token punctuation">:</span>        state <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seq_lines<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            one_ouf <span class="token operator">=</span> getmaxstr<span class="token punctuation">(</span>i<span class="token punctuation">,</span> seq_lines<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token keyword">not</span> one_ouf<span class="token punctuation">:</span>                state <span class="token operator">=</span> <span class="token boolean">False</span>                <span class="token keyword">break</span>            <span class="token comment"># 得到最长的子串</span>            Long_return <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>one_ouf<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>Long_return<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>                i <span class="token operator">=</span> Long_return        <span class="token keyword">if</span> state<span class="token punctuation">:</span>            finall_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>finall_lst<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>               <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>&ensp;&ensp;&ensp;这段代码是年前写的，现在看的话有非常大的提升空间，感兴趣的话可以自己尝试下怎么加快速度！！</p>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> ROSALIND </tag>
            
            <tag> LCS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bilibili弹幕词云</title>
      <link href="2021/01/30/bilibili-dan-mu-ci-yun/"/>
      <url>2021/01/30/bilibili-dan-mu-ci-yun/</url>
      
        <content type="html"><![CDATA[<h1 id="bilibili弹幕词云"><a href="#bilibili弹幕词云" class="headerlink" title="bilibili弹幕词云"></a>bilibili弹幕词云</h1><h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><p>​        1.到B站获取cid</p><p>​        2.根据cid获取弹幕数据</p><p>​        3.用python获得数据</p><p>​        4.数据的清洗</p><p>​        5.生成词云</p><h2 id="一、获取视频的cid"><a href="#一、获取视频的cid" class="headerlink" title="一、获取视频的cid"></a>一、获取视频的cid</h2><p>​        因为一个视频的弹幕是和加载时的heartbeat的XHR的脚本是有关的，获取它的cid名称就行了，浏览器F12打开检测器，点击网络，F5刷新一下就可以了。</p><p><img src="https://i.loli.net/2021/01/30/iq1Jry7pT48SYcZ.png" alt="image-20210130184712846.png"></p><h2 id="二、根据cid获取弹幕数据"><a href="#二、根据cid获取弹幕数据" class="headerlink" title="二、根据cid获取弹幕数据"></a>二、根据cid获取弹幕数据</h2><p>​        如上图所示，目标视频的cid为 264124，目标数据位于：**<em><a href="https://comment.bilibili.com/%E8%A7%86%E9%A2%91%E7%9A%84cid.xml">https://comment.bilibili.com/视频的cid.xml</a>**</em>， <a href="https://comment.bilibili.com/264124.xml">https://comment.bilibili.com/264124.xml</a> 这个页面就是我们cid的数据页面了。</p><p><img src="https://i.loli.net/2021/01/30/3LM8EDJ4bFZNYiI.png" alt="image-20210130155253878.png"></p><h2 id="三、用python获得数据"><a href="#三、用python获得数据" class="headerlink" title="三、用python获得数据"></a>三、用python获得数据</h2><h6 id="1-得到网页文本数据"><a href="#1-得到网页文本数据" class="headerlink" title="1.得到网页文本数据"></a>1.得到网页文本数据</h6><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoupget_url <span class="token operator">=</span> <span class="token string">'https://comment.bilibili.com/152116553.xml'</span>res <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>get_url<span class="token punctuation">)</span>res<span class="token punctuation">.</span>encoding <span class="token operator">=</span> <span class="token string">"utf-8"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://i.loli.net/2021/01/30/I52te6h3cfNYyFz.png" alt="image-20210130162228368.png"></p><h6 id="2-获得弹幕文本"><a href="#2-获得弹幕文本" class="headerlink" title="2.获得弹幕文本"></a>2.获得弹幕文本</h6><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 可以很明显的发现每一行弹幕都处在网页d标签下</span><span class="token comment"># 直接使用lxml解析</span>soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>res<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">'lxml'</span><span class="token punctuation">)</span>total_d <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'d'</span><span class="token punctuation">)</span><span class="token comment"># 获取d标签的文本</span>comments <span class="token operator">=</span> <span class="token punctuation">[</span>conmment<span class="token punctuation">.</span>text <span class="token keyword">for</span> conmment <span class="token keyword">in</span> total_d<span class="token punctuation">]</span>comments<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://i.loli.net/2021/01/30/VpMO6JYE5w1hB4s.png" alt="image-20210130184827847.png"></p><h1 id="四、数据的清洗"><a href="#四、数据的清洗" class="headerlink" title="四、数据的清洗"></a>四、数据的清洗</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 先把英文转换成大写</span>comments <span class="token operator">=</span> <span class="token punctuation">[</span>i<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> comments<span class="token punctuation">]</span><span class="token comment"># 去掉空格</span>comments_clean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> comment <span class="token keyword">in</span> comments<span class="token punctuation">:</span>    comment <span class="token operator">=</span> comment<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>    comments_clean<span class="token punctuation">.</span>append<span class="token punctuation">(</span>comment<span class="token punctuation">)</span>    comments_clean<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 查看一些各个词的频率</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdcipin <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">'danmu'</span><span class="token punctuation">:</span>comments_clean<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>cipin<span class="token punctuation">[</span><span class="token string">'danmu'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 使用jieba分词，并过滤单个字符</span><span class="token keyword">import</span> jiebatotal_str <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>comments_clean<span class="token punctuation">)</span>words <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>total_str<span class="token punctuation">)</span><span class="token punctuation">)</span>fnl_words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> words <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token operator">></span><span class="token number">1</span><span class="token punctuation">]</span>fnl_words<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="五、生成词云"><a href="#五、生成词云" class="headerlink" title="五、生成词云"></a>五、生成词云</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token keyword">import</span> wordcloud<span class="token comment"># 这里我们把词云生成一个圆的形状</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"yuan.png"</span><span class="token punctuation">)</span>resized <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>img<span class="token punctuation">)</span>wc_1 <span class="token operator">=</span> wordcloud<span class="token punctuation">.</span>WordCloud<span class="token punctuation">(</span>    background_color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span>    width<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>    height<span class="token operator">=</span><span class="token number">800</span><span class="token punctuation">,</span>    mask<span class="token operator">=</span>resized<span class="token punctuation">,</span>    font_path<span class="token operator">=</span><span class="token string">'simfang.ttf'</span><span class="token punctuation">)</span><span class="token comment"># 导入我们的词列表</span>wc_1<span class="token punctuation">.</span>generate_from_text<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>fnl_words<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wc_1<span class="token punctuation">)</span><span class="token comment"># 不显示坐标轴</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 储存为png图片</span>wc_1<span class="token punctuation">.</span>to_file<span class="token punctuation">(</span><span class="token string">'wordcloud-res.png'</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://i.loli.net/2021/01/30/9rJFXwKLg3N7Pzv.png" alt="wordcloud-res.png"></p><div id='refer-anchor-1'> </div>## References<p>[1] <a href="https://blog.csdn.net/m0_50944918/article/details/110747420">python 爬虫 哔哩哔哩弹幕爬取69岁老同志视频弹幕</a></p><p>[2] <a href="https://blog.csdn.net/johnchang0201/article/details/103004229">python爬虫：bilibili弹幕爬取+词云生成</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 词云 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
